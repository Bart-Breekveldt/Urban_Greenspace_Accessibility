{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71639573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system packages\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# non-geo numeric packages\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import product, combinations\n",
    "import pandas as pd\n",
    "\n",
    "# network and OSM packages\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "city_geo = ox.geocoder.geocode_to_gdf\n",
    "\n",
    "# Earth engine packages\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "# General geo-packages\n",
    "import libpysal\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point, MultiLineString, LineString, Polygon, MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f0b2a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>bbox_north</th>\n",
       "      <th>bbox_south</th>\n",
       "      <th>bbox_east</th>\n",
       "      <th>bbox_west</th>\n",
       "      <th>place_id</th>\n",
       "      <th>osm_type</th>\n",
       "      <th>osm_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>display_name</th>\n",
       "      <th>class</th>\n",
       "      <th>type</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((130.02576 32.31688, 130.02594 32.316...</td>\n",
       "      <td>32.32</td>\n",
       "      <td>32.32</td>\n",
       "      <td>130.03</td>\n",
       "      <td>130.03</td>\n",
       "      <td>278956318</td>\n",
       "      <td>way</td>\n",
       "      <td>924413802</td>\n",
       "      <td>32.32</td>\n",
       "      <td>130.03</td>\n",
       "      <td>Amakusa City Hall, Kawaura Tomitsu Branch, Sak...</td>\n",
       "      <td>amenity</td>\n",
       "      <td>townhall</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry           bbox_north  \\\n",
       "0  POLYGON ((130.02576 32.31688, 130.02594 32.316...                32.32   \n",
       "\n",
       "            bbox_south            bbox_east            bbox_west   place_id  \\\n",
       "0                32.32               130.03               130.03  278956318   \n",
       "\n",
       "  osm_type     osm_id                  lat                  lon  \\\n",
       "0      way  924413802                32.32               130.03   \n",
       "\n",
       "                                        display_name    class      type  \\\n",
       "0  Amakusa City Hall, Kawaura Tomitsu Branch, Sak...  amenity  townhall   \n",
       "\n",
       "            importance  \n",
       "0                 0.20  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_geo('Kumamoto City')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23309aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=3PbLqUmBvwdITQxYFqBvhrkv5YLuiyqmTaDLXRIGguE&tc=Np4pwiTJhyqxL6vbtamERM7YoP4FgBKVWmNu_8FnZAQ&cc=VMZq-fMXm4PUb6gYZTrmmWMdbToCuuoXaf7oPfQhOuo>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=3PbLqUmBvwdITQxYFqBvhrkv5YLuiyqmTaDLXRIGguE&tc=Np4pwiTJhyqxL6vbtamERM7YoP4FgBKVWmNu_8FnZAQ&cc=VMZq-fMXm4PUb6gYZTrmmWMdbToCuuoXaf7oPfQhOuo</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AbUR2VPNtosClEEvAYVUM6aovF9ZgWy9FW-Y61YmsBL7yno94EEnbtHAYP4\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and Initialize Google Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aee31f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(ls_in)]\n",
    "cities_adj = cities_adj.sort_values('City').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "006c2558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>OSM_area</th>\n",
       "      <th>City</th>\n",
       "      <th>E2SFCA</th>\n",
       "      <th>Gravity</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>G_adj</th>\n",
       "      <th>E_adj</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Addis Ababa</td>\n",
       "      <td>Addis Ababa</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Baghdad</td>\n",
       "      <td>Baghdad</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Bangalore Urban</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Beograd</td>\n",
       "      <td>Belgrade</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>103</td>\n",
       "      <td>Utsunomiya</td>\n",
       "      <td>Utsunomiya</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>106</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>Washington DC</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>107</td>\n",
       "      <td>Fushan district Yantai, Zhifu district Yantai,...</td>\n",
       "      <td>Yantai</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>108</td>\n",
       "      <td>Yaounde</td>\n",
       "      <td>Yaounde</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>109</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                           OSM_area           City  \\\n",
       "0       0                                            Abidjan        Abidjan   \n",
       "1       1                                        Addis Ababa    Addis Ababa   \n",
       "2       5                                            Baghdad        Baghdad   \n",
       "3       6                                    Bangalore Urban      Bangalore   \n",
       "4       8                                            Beograd       Belgrade   \n",
       "..    ...                                                ...            ...   \n",
       "70    103                                         Utsunomiya     Utsunomiya   \n",
       "71    106                                      Washington DC  Washington DC   \n",
       "72    107  Fushan district Yantai, Zhifu district Yantai,...         Yantai   \n",
       "73    108                                            Yaounde        Yaounde   \n",
       "74    109                                            Yerevan        Yerevan   \n",
       "\n",
       "   E2SFCA Gravity Unnamed: 4           Unnamed: 5 G_adj  E_adj Unnamed: 8  \n",
       "0       X       X          X                 1.00   NaN    NaN        NaN  \n",
       "1       X       X          X                  NaN   NaN    NaN        NaN  \n",
       "2       X       X          X                 1.00   NaN    NaN        NaN  \n",
       "3       X       X          X                  NaN   NaN    NaN        NaN  \n",
       "4       X       X          X                  NaN   NaN    NaN        NaN  \n",
       "..    ...     ...        ...                  ...   ...    ...        ...  \n",
       "70      X       X          X                  NaN   NaN    NaN        NaN  \n",
       "71      X       X          X                  NaN   NaN    NaN        NaN  \n",
       "72      X       X          X                 0.00   NaN    NaN        NaN  \n",
       "73      X       X          X                  NaN   NaN    NaN        NaN  \n",
       "74      X       X          X                  NaN   NaN    NaN        NaN  \n",
       "\n",
       "[75 rows x 10 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "885b9c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Japan']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/6f1a7b1cf67cfcaf3e199e84fc208293-a6b3054675f927bde2e13995aecda08d:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\JPN_Kumamoto_2020.tif\n",
      "get road networks from OSM\n",
      "Kumamoto done 2.94 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Kumamoto done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Kumamoto 2.21 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Kumamoto 0.0 % done 0.0  mns\n",
      "Kumamoto 26.8 % done 0.48  mns\n",
      "Kumamoto 53.6 % done 0.88  mns\n",
      "Kumamoto 80.4 % done 1.28  mns\n",
      "Kumamoto 100 % done 1.57  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "34.18 % 0.38 mns\n",
      "68.35 % 0.81 mns\n",
      "100 % finding combinations done\n",
      "Kumamoto 341618 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Kumamoto\n",
      "0.0 % done 0.78 mns\n",
      "34.18 % done 0.82 mns\n",
      "68.35 % done 1.39 mns\n",
      "100 % done 45.61 mns\n",
      "\n",
      "Kumamoto\n",
      "0.0 % 0.14 mns\n",
      "9.68 % 0.52 mns\n",
      "19.36 % 0.89 mns\n",
      "29.04 % 1.27 mns\n",
      "38.72 % 1.65 mns\n",
      "48.4 % 2.03 mns\n",
      "58.08 % 2.39 mns\n",
      "67.76 % 2.77 mns\n",
      "77.44 % 3.15 mns\n",
      "87.12 % 3.5 mns\n",
      "96.8 % 3.77 mns\n",
      "100 % done 4.03 mns\n",
      "\n",
      "300 Kumamoto\n",
      "600 Kumamoto\n",
      "1000 Kumamoto\n",
      "CPU times: total: 10min 33s\n",
      "Wall time: 58min 23s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Kumamoto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843,427.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>61.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>9.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>29,409.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>45.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>29.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>60.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>59.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>47,604.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>53.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>28.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>58.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>186.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>66,218.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>50.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>27.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                       Kumamoto\n",
       "0                        843,427.00\n",
       "Sc-access 300                 61.42\n",
       "M-dist 300                     9.44\n",
       "M-area 300                29,409.06\n",
       "M-supply 300                  45.37\n",
       "Sc-norm 300                   29.63\n",
       "Sc-access 600                 60.36\n",
       "M-dist 600                    59.47\n",
       "M-area 600                47,604.54\n",
       "M-supply 600                  53.54\n",
       "Sc-norm 600                   28.58\n",
       "Sc-access 1000                58.69\n",
       "M-dist 1000                  186.17\n",
       "M-area 1000               66,218.64\n",
       "M-supply 1000                 50.99\n",
       "Sc-norm 1000                  27.19"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Kumamoto'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext = '_Kumamoto')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f5b9fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Philippines']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/9d4d5da3465c7a87017061ee3117663d-6cb9a446a449eb3e2ddcab5932922f8b:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\PHL_Manila_2020.tif\n",
      "get road networks from OSM\n",
      "Manila done 2.48 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Manila done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Manila 3.06 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Manila 0.0 % done 0.01  mns\n",
      "Manila 8.8 % done 1.14  mns\n",
      "Manila 17.6 % done 2.12  mns\n",
      "Manila 26.4 % done 3.14  mns\n",
      "Manila 35.2 % done 4.31  mns\n",
      "Manila 44.0 % done 5.44  mns\n",
      "Manila 52.8 % done 6.6  mns\n",
      "Manila 61.6 % done 7.79  mns\n",
      "Manila 70.4 % done 8.88  mns\n",
      "Manila 79.2 % done 9.99  mns\n",
      "Manila 88.0 % done 11.1  mns\n",
      "Manila 96.8 % done 12.35  mns\n",
      "Manila 100 % done 12.81  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "13.09 % 0.44 mns\n",
      "26.18 % 0.92 mns\n",
      "39.27 % 1.44 mns\n",
      "52.36 % 1.92 mns\n",
      "65.45 % 2.41 mns\n",
      "78.53 % 2.92 mns\n",
      "91.62 % 3.45 mns\n",
      "100 % finding combinations done\n",
      "Manila 364181 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Manila\n",
      "0.0 % done 5.96 mns\n",
      "13.09 % done 6.22 mns\n",
      "26.18 % done 6.86 mns\n",
      "39.27 % done 7.52 mns\n",
      "52.36 % done 8.18 mns\n",
      "65.45 % done 8.92 mns\n",
      "78.53 % done 9.63 mns\n",
      "91.62 % done 10.38 mns\n",
      "100 % done 11.02 mns\n",
      "\n",
      "Manila\n",
      "0.0 % 0.53 mns\n",
      "8.53 % 1.22 mns\n",
      "17.06 % 1.89 mns\n",
      "25.6 % 2.53 mns\n",
      "34.13 % 3.16 mns\n",
      "42.66 % 3.91 mns\n",
      "51.19 % 4.53 mns\n",
      "59.73 % 5.22 mns\n",
      "68.26 % 6.0 mns\n",
      "76.79 % 6.65 mns\n",
      "85.32 % 7.27 mns\n",
      "93.86 % 7.86 mns\n",
      "100 % done 8.37 mns\n",
      "\n",
      "300 Manila\n",
      "600 Manila\n",
      "1000 Manila\n",
      "CPU times: total: 31min 37s\n",
      "Wall time: 42min 27s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Manila</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13,219,247.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>15.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>600,837.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>12.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>13.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>118.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>807,341.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>11.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>12.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>249.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>970,902.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>9.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                         Manila\n",
       "0                     13,219,247.00\n",
       "Sc-access 300                 15.57\n",
       "M-dist 300                    17.93\n",
       "M-area 300               600,837.24\n",
       "M-supply 300                  12.38\n",
       "Sc-norm 300                    0.86\n",
       "Sc-access 600                 13.29\n",
       "M-dist 600                   118.35\n",
       "M-area 600               807,341.35\n",
       "M-supply 600                  11.36\n",
       "Sc-norm 600                    0.67\n",
       "Sc-access 1000                12.23\n",
       "M-dist 1000                  249.94\n",
       "M-area 1000              970,902.07\n",
       "M-supply 1000                  9.82\n",
       "Sc-norm 1000                   0.57"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Manila'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'],\n",
    "                            time_sleep = 30)\n",
    "\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext = '_Manila')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4a6a203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estonia']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/be9716361ff817c5bb8e89d7e4564bb2-6d98efdef0a210cbb4a376b2ff126a55:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\EST_Tallinn_2020.tif\n",
      "get road networks from OSM\n",
      "Tallinn done 1.72 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Tallinn done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Tallinn 3.69 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Tallinn 0.0 % done 0.01  mns\n",
      "Tallinn 24.0 % done 0.97  mns\n",
      "Tallinn 48.1 % done 1.65  mns\n",
      "Tallinn 72.1 % done 2.28  mns\n",
      "Tallinn 96.2 % done 2.91  mns\n",
      "Tallinn 100 % done 3.16  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "5.84 % 0.25 mns\n",
      "11.68 % 0.55 mns\n",
      "17.52 % 0.89 mns\n",
      "23.36 % 1.28 mns\n",
      "29.21 % 1.71 mns\n",
      "35.05 % 2.19 mns\n",
      "40.89 % 2.69 mns\n",
      "46.73 % 3.24 mns\n",
      "52.57 % 3.84 mns\n",
      "58.41 % 4.49 mns\n",
      "64.25 % 5.17 mns\n",
      "70.09 % 5.95 mns\n",
      "75.93 % 6.79 mns\n",
      "81.78 % 7.6 mns\n",
      "87.62 % 8.45 mns\n",
      "93.46 % 9.33 mns\n",
      "99.3 % 10.24 mns\n",
      "100 % finding combinations done\n",
      "Tallinn 4436294 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Tallinn\n",
      "0.0 % done 5.9 mns\n",
      "5.84 % done 6.21 mns\n",
      "11.68 % done 6.77 mns\n",
      "17.52 % done 7.35 mns\n",
      "23.36 % done 8.06 mns\n",
      "29.21 % done 8.85 mns\n",
      "35.05 % done 9.6 mns\n",
      "40.89 % done 10.57 mns\n",
      "46.73 % done 11.57 mns\n",
      "52.57 % done 12.76 mns\n",
      "58.41 % done 13.99 mns\n",
      "64.25 % done 15.22 mns\n",
      "70.09 % done 16.79 mns\n",
      "75.93 % done 18.25 mns\n",
      "81.78 % done 19.74 mns\n",
      "87.62 % done 21.42 mns\n",
      "93.46 % done 23.03 mns\n",
      "99.3 % done 24.75 mns\n",
      "100 % done 25.11 mns\n",
      "\n",
      "Tallinn\n",
      "0.0 % 1.95 mns\n",
      "0.85 % 2.64 mns\n",
      "1.71 % 3.64 mns\n",
      "2.56 % 3.98 mns\n",
      "3.41 % 4.41 mns\n",
      "4.27 % 4.84 mns\n",
      "5.12 % 5.24 mns\n",
      "5.97 % 5.7 mns\n",
      "6.83 % 6.1 mns\n",
      "7.68 % 6.57 mns\n",
      "8.54 % 6.99 mns\n",
      "9.39 % 7.49 mns\n",
      "10.24 % 7.91 mns\n",
      "11.1 % 8.33 mns\n",
      "11.95 % 8.74 mns\n",
      "12.8 % 9.12 mns\n",
      "13.66 % 9.55 mns\n",
      "14.51 % 9.88 mns\n",
      "15.36 % 10.26 mns\n",
      "16.22 % 10.68 mns\n",
      "17.07 % 11.08 mns\n",
      "17.92 % 11.45 mns\n",
      "18.78 % 11.87 mns\n",
      "19.63 % 12.22 mns\n",
      "20.49 % 12.65 mns\n",
      "21.34 % 13.07 mns\n",
      "22.19 % 13.5 mns\n",
      "23.05 % 13.88 mns\n",
      "23.9 % 14.27 mns\n",
      "24.75 % 14.61 mns\n",
      "25.61 % 15.01 mns\n",
      "26.46 % 15.42 mns\n",
      "27.31 % 15.82 mns\n",
      "28.17 % 16.15 mns\n",
      "29.02 % 16.53 mns\n",
      "29.87 % 16.95 mns\n",
      "30.73 % 17.46 mns\n",
      "31.58 % 17.88 mns\n",
      "32.44 % 18.33 mns\n",
      "33.29 % 18.83 mns\n",
      "34.14 % 19.27 mns\n",
      "35.0 % 19.76 mns\n",
      "35.85 % 20.22 mns\n",
      "36.7 % 20.65 mns\n",
      "37.56 % 21.02 mns\n",
      "38.41 % 21.47 mns\n",
      "39.26 % 21.9 mns\n",
      "40.12 % 22.39 mns\n",
      "40.97 % 22.85 mns\n",
      "41.82 % 23.35 mns\n",
      "42.68 % 23.75 mns\n",
      "43.53 % 24.16 mns\n",
      "44.38 % 24.61 mns\n",
      "45.24 % 25.05 mns\n",
      "46.09 % 25.49 mns\n",
      "46.95 % 25.9 mns\n",
      "47.8 % 26.37 mns\n",
      "48.65 % 26.78 mns\n",
      "49.51 % 27.27 mns\n",
      "50.36 % 27.72 mns\n",
      "51.21 % 28.27 mns\n",
      "52.07 % 28.78 mns\n",
      "52.92 % 29.26 mns\n",
      "53.77 % 29.94 mns\n",
      "54.63 % 36.75 mns\n",
      "55.48 % 38.11 mns\n",
      "56.33 % 39.94 mns\n",
      "57.19 % 47.98 mns\n",
      "58.04 % 48.6 mns\n",
      "58.9 % 49.22 mns\n",
      "59.75 % 49.73 mns\n",
      "60.6 % 50.2 mns\n",
      "61.46 % 50.78 mns\n",
      "62.31 % 51.27 mns\n",
      "63.16 % 51.72 mns\n",
      "64.02 % 52.17 mns\n",
      "64.87 % 52.73 mns\n",
      "65.72 % 53.27 mns\n",
      "66.58 % 53.71 mns\n",
      "67.43 % 54.22 mns\n",
      "68.28 % 54.72 mns\n",
      "69.14 % 55.2 mns\n",
      "69.99 % 55.7 mns\n",
      "70.85 % 56.27 mns\n",
      "71.7 % 56.75 mns\n",
      "72.55 % 57.17 mns\n",
      "73.41 % 57.62 mns\n",
      "74.26 % 58.1 mns\n",
      "75.11 % 58.7 mns\n",
      "75.97 % 59.14 mns\n",
      "76.82 % 59.61 mns\n",
      "77.67 % 60.11 mns\n",
      "78.53 % 60.95 mns\n",
      "79.38 % 61.42 mns\n",
      "80.23 % 61.87 mns\n",
      "81.09 % 62.37 mns\n",
      "81.94 % 62.77 mns\n",
      "82.79 % 63.15 mns\n",
      "83.65 % 63.61 mns\n",
      "84.5 % 63.98 mns\n",
      "85.36 % 64.42 mns\n",
      "86.21 % 64.84 mns\n",
      "87.06 % 65.33 mns\n",
      "87.92 % 65.77 mns\n",
      "88.77 % 66.29 mns\n",
      "89.62 % 66.69 mns\n",
      "90.48 % 67.15 mns\n",
      "91.33 % 67.61 mns\n",
      "92.18 % 68.07 mns\n",
      "93.04 % 68.56 mns\n",
      "93.89 % 69.08 mns\n",
      "94.74 % 69.63 mns\n",
      "95.6 % 70.04 mns\n",
      "96.45 % 70.5 mns\n",
      "97.31 % 71.01 mns\n",
      "98.16 % 71.51 mns\n",
      "99.01 % 72.01 mns\n",
      "99.87 % 72.32 mns\n",
      "100.72 % 72.59 mns\n",
      "100 % done 72.91 mns\n",
      "\n",
      "300 Tallinn\n",
      "600 Tallinn\n",
      "1000 Tallinn\n",
      "CPU times: total: 1h 2min 44s\n",
      "Wall time: 1h 59min 49s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Tallinn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>416,024.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>597.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>52.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>1,200,232.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>246.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>321.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>530.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>194.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>1,639,596.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>248.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>267.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>459.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>399.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>1,642,854.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>176.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>212.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                        Tallinn\n",
       "0                        416,024.00\n",
       "Sc-access 300                597.76\n",
       "M-dist 300                    52.04\n",
       "M-area 300             1,200,232.45\n",
       "M-supply 300                 246.87\n",
       "Sc-norm 300                  321.10\n",
       "Sc-access 600                530.10\n",
       "M-dist 600                   194.96\n",
       "M-area 600             1,639,596.00\n",
       "M-supply 600                 248.46\n",
       "Sc-norm 600                  267.14\n",
       "Sc-access 1000               459.35\n",
       "M-dist 1000                  399.14\n",
       "M-area 1000            1,642,854.49\n",
       "M-supply 1000                176.98\n",
       "Sc-norm 1000                 212.50"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Tallinn'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds,\n",
    "                                time_sleep = 10)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext = '_Tallinn')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4ccf2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Japan']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/c9917c2cc249903607d16a7f0fd1f069-2632706b6b71cd59059b77476ec0442f:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\JPN_Kumamoto_2020.tif\n",
      "get road networks from OSM\n",
      "Kumamoto done 0.91 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Kumamoto done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Kumamoto 3.16 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Kumamoto 0.0 % done 0.0  mns\n",
      "Kumamoto 70.9 % done 0.21  mns\n",
      "Kumamoto 100 % done 0.3  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "88.03 % 0.13 mns\n",
      "100 % finding combinations done\n",
      "Kumamoto 70922 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Kumamoto\n",
      "0.0 % done 0.14 mns\n",
      "88.03 % done 0.18 mns\n",
      "100 % done 0.68 mns\n",
      "\n",
      "Kumamoto\n",
      "0.0 % 0.11 mns\n",
      "56.07 % 0.42 mns\n",
      "100 % done 0.67 mns\n",
      "\n",
      "300 Kumamoto\n",
      "600 Kumamoto\n",
      "1000 Kumamoto\n",
      "CPU times: total: 4min 59s\n",
      "Wall time: 6min 5s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Kumamoto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125,461.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>41.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>6.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>3,225.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>52.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>41.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>46.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>7,866.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>48.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>10.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>43.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>178.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>19,387.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>51.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>11.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                       Kumamoto\n",
       "0                        125,461.00\n",
       "Sc-access 300                 41.62\n",
       "M-dist 300                     6.24\n",
       "M-area 300                 3,225.59\n",
       "M-supply 300                  52.58\n",
       "Sc-norm 300                   10.80\n",
       "Sc-access 600                 41.42\n",
       "M-dist 600                    46.31\n",
       "M-area 600                 7,866.09\n",
       "M-supply 600                  48.14\n",
       "Sc-norm 600                   10.71\n",
       "Sc-access 1000                43.73\n",
       "M-dist 1000                  178.55\n",
       "M-area 1000               19,387.96\n",
       "M-supply 1000                 51.21\n",
       "Sc-norm 1000                  11.58"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Kumamoto'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext = '_Kumamoto')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0943a1c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Australia']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/57b8d4066c68ba61a53b46c6b6cad96a-167571921f1051238dfae484ecc2025f:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\AUS_Perth_2020.tif\n",
      "get road networks from OSM\n",
      "Perth done 5.66 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Perth done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Perth 9.92 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Perth 0.0 % done 0.01  mns\n",
      "Perth 5.0 % done 1.62  mns\n",
      "Perth 9.9 % done 2.73  mns\n",
      "Perth 14.9 % done 3.8  mns\n",
      "Perth 19.8 % done 4.85  mns\n",
      "Perth 24.8 % done 5.97  mns\n",
      "Perth 29.7 % done 7.02  mns\n",
      "Perth 34.7 % done 8.12  mns\n",
      "Perth 39.7 % done 9.16  mns\n",
      "Perth 44.6 % done 10.24  mns\n",
      "Perth 49.6 % done 11.23  mns\n",
      "Perth 54.5 % done 12.37  mns\n",
      "Perth 59.5 % done 13.44  mns\n",
      "Perth 64.5 % done 14.47  mns\n",
      "Perth 69.4 % done 15.51  mns\n",
      "Perth 74.4 % done 16.51  mns\n",
      "Perth 79.3 % done 17.53  mns\n",
      "Perth 84.3 % done 18.53  mns\n",
      "Perth 89.2 % done 19.55  mns\n",
      "Perth 94.2 % done 20.64  mns\n",
      "Perth 99.2 % done 21.69  mns\n",
      "Perth 100 % done 22.29  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "2.62 % 0.39 mns\n",
      "5.24 % 0.78 mns\n",
      "7.86 % 1.19 mns\n",
      "10.49 % 1.61 mns\n",
      "13.11 % 2.03 mns\n",
      "15.73 % 2.47 mns\n",
      "18.35 % 2.93 mns\n",
      "20.97 % 3.39 mns\n",
      "23.59 % 3.86 mns\n",
      "26.21 % 4.34 mns\n",
      "28.84 % 4.83 mns\n",
      "31.46 % 5.33 mns\n",
      "34.08 % 5.84 mns\n",
      "36.7 % 6.35 mns\n",
      "39.32 % 6.87 mns\n",
      "41.94 % 7.41 mns\n",
      "44.56 % 7.96 mns\n",
      "47.18 % 8.52 mns\n",
      "49.81 % 9.09 mns\n",
      "52.43 % 9.67 mns\n",
      "55.05 % 10.25 mns\n",
      "57.67 % 10.86 mns\n",
      "60.29 % 11.47 mns\n",
      "62.91 % 12.08 mns\n",
      "65.53 % 12.71 mns\n",
      "68.16 % 13.35 mns\n",
      "70.78 % 14.0 mns\n",
      "73.4 % 14.66 mns\n",
      "76.02 % 15.34 mns\n",
      "78.64 % 16.03 mns\n",
      "81.26 % 16.72 mns\n",
      "83.88 % 17.42 mns\n",
      "86.51 % 18.14 mns\n",
      "89.13 % 18.86 mns\n",
      "91.75 % 19.6 mns\n",
      "94.37 % 20.34 mns\n",
      "96.99 % 21.09 mns\n",
      "99.61 % 21.85 mns\n",
      "100 % finding combinations done\n",
      "Perth 2347751 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Perth\n",
      "0.0 % done 29.51 mns\n",
      "2.62 % done 30.14 mns\n",
      "5.24 % done 30.56 mns\n",
      "7.86 % done 31.36 mns\n",
      "10.49 % done 31.79 mns\n",
      "13.11 % done 32.33 mns\n",
      "15.73 % done 32.91 mns\n",
      "18.35 % done 33.77 mns\n",
      "20.97 % done 34.41 mns\n",
      "23.59 % done 34.89 mns\n",
      "26.21 % done 35.43 mns\n",
      "28.84 % done 36.26 mns\n",
      "31.46 % done 36.99 mns\n",
      "34.08 % done 39.4 mns\n",
      "36.7 % done 43.12 mns\n",
      "39.32 % done 44.05 mns\n",
      "41.94 % done 45.67 mns\n",
      "44.56 % done 46.92 mns\n",
      "47.18 % done 47.75 mns\n",
      "49.81 % done 48.49 mns\n",
      "52.43 % done 49.26 mns\n",
      "55.05 % done 49.99 mns\n",
      "57.67 % done 50.84 mns\n",
      "60.29 % done 52.23 mns\n",
      "62.91 % done 53.75 mns\n",
      "65.53 % done 55.0 mns\n",
      "68.16 % done 56.08 mns\n",
      "70.78 % done 57.04 mns\n",
      "73.4 % done 57.95 mns\n",
      "76.02 % done 58.96 mns\n",
      "78.64 % done 59.89 mns\n",
      "81.26 % done 61.07 mns\n",
      "83.88 % done 62.18 mns\n",
      "86.51 % done 63.34 mns\n",
      "89.13 % done 65.28 mns\n",
      "91.75 % done 66.35 mns\n",
      "94.37 % done 67.29 mns\n",
      "96.99 % done 68.3 mns\n",
      "99.61 % done 69.33 mns\n",
      "100 % done 69.66 mns\n",
      "\n",
      "Perth\n",
      "0.0 % 0.85 mns\n",
      "1.59 % 1.25 mns\n",
      "3.19 % 1.62 mns\n",
      "4.78 % 1.98 mns\n",
      "6.37 % 2.34 mns\n",
      "7.96 % 2.68 mns\n",
      "9.56 % 3.03 mns\n",
      "11.15 % 3.36 mns\n",
      "12.74 % 3.71 mns\n",
      "14.34 % 4.06 mns\n",
      "15.93 % 4.41 mns\n",
      "17.52 % 4.75 mns\n",
      "19.12 % 5.13 mns\n",
      "20.71 % 5.53 mns\n",
      "22.3 % 5.91 mns\n",
      "23.89 % 6.27 mns\n",
      "25.49 % 6.64 mns\n",
      "27.08 % 7.03 mns\n",
      "28.67 % 7.39 mns\n",
      "30.27 % 7.76 mns\n",
      "31.86 % 8.14 mns\n",
      "33.45 % 8.51 mns\n",
      "35.04 % 8.87 mns\n",
      "36.64 % 9.21 mns\n",
      "38.23 % 9.58 mns\n",
      "39.82 % 9.93 mns\n",
      "41.42 % 10.29 mns\n",
      "43.01 % 10.74 mns\n",
      "44.6 % 11.12 mns\n",
      "46.2 % 11.51 mns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Perth'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds,\n",
    "                                time_sleep = 10)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext = '_Perth')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbea7c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Democratic Republic of the Congo']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/fdba4341e4e0bfa606251d935935dc08-84f0a3c3be1ea2615a3be1375ac35591:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\COD_Lubumbashi_2020.tif\n",
      "get road networks from OSM\n",
      "Lubumbashi done 0.76 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Lubumbashi done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Lubumbashi 0.84 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Lubumbashi 0.0 % done 0.0  mns\n",
      "Lubumbashi 100 % done 0.04  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "100 % finding combinations done\n",
      "Lubumbashi 23550 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Lubumbashi\n",
      "0.0 % done 0.02 mns\n",
      "100 % done 0.03 mns\n",
      "\n",
      "Lubumbashi\n",
      "0.0 % 0.06 mns\n",
      "100 % done 0.31 mns\n",
      "\n",
      "300 Lubumbashi\n",
      "600 Lubumbashi\n",
      "1000 Lubumbashi\n",
      "CPU times: total: 2min 11s\n",
      "Wall time: 2min 30s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Lubumbashi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4,009,290.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>51.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>149.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>16.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>386.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                     Lubumbashi\n",
       "0                      4,009,290.00\n",
       "Sc-access 300                  0.02\n",
       "M-dist 300                     0.39\n",
       "M-area 300                    51.69\n",
       "M-supply 300                   0.02\n",
       "Sc-norm 300                    0.00\n",
       "Sc-access 600                  0.02\n",
       "M-dist 600                     3.57\n",
       "M-area 600                   149.39\n",
       "M-supply 600                   0.03\n",
       "Sc-norm 600                    0.00\n",
       "Sc-access 1000                 0.02\n",
       "M-dist 1000                   16.46\n",
       "M-area 1000                  386.94\n",
       "M-supply 1000                  0.03\n",
       "Sc-norm 1000                   0.00"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Lubumbashi'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext = '_Lubumbashi')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d3da1e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brazil']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/37731b4f60a10a9d51a0642ab3232f0a-861cf52785316e83409830976c0516d4:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\BRA_Curitiba_2020.tif\n",
      "get road networks from OSM\n",
      "Curitiba done 1.6 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Curitiba done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Curitiba 5.19 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Curitiba 0.0 % done 0.04  mns\n",
      "Curitiba 10.8 % done 0.82  mns\n",
      "Curitiba 21.7 % done 1.55  mns\n",
      "Curitiba 32.5 % done 2.25  mns\n",
      "Curitiba 43.3 % done 2.9  mns\n",
      "Curitiba 54.2 % done 3.56  mns\n",
      "Curitiba 65.0 % done 4.27  mns\n",
      "Curitiba 75.8 % done 4.98  mns\n",
      "Curitiba 86.7 % done 5.7  mns\n",
      "Curitiba 97.5 % done 6.42  mns\n",
      "Curitiba 100 % done 6.64  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "9.45 % 0.36 mns\n",
      "18.9 % 0.73 mns\n",
      "28.35 % 1.11 mns\n",
      "37.8 % 1.5 mns\n",
      "47.25 % 1.9 mns\n",
      "56.7 % 2.33 mns\n",
      "66.15 % 2.79 mns\n",
      "75.6 % 3.26 mns\n",
      "85.05 % 3.77 mns\n",
      "94.5 % 4.26 mns\n",
      "100 % finding combinations done\n",
      "Curitiba 1010783 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Curitiba\n",
      "0.0 % done 4.15 mns\n",
      "9.45 % done 4.25 mns\n",
      "18.9 % done 4.34 mns\n",
      "28.35 % done 4.46 mns\n",
      "37.8 % done 4.6 mns\n",
      "47.25 % done 4.76 mns\n",
      "56.7 % done 4.93 mns\n",
      "66.15 % done 5.13 mns\n",
      "75.6 % done 5.36 mns\n",
      "85.05 % done 5.6 mns\n",
      "94.5 % done 5.87 mns\n",
      "100 % done 6.04 mns\n",
      "\n",
      "Curitiba\n",
      "0.0 % 0.16 mns\n",
      "3.09 % 0.5 mns\n",
      "6.18 % 0.84 mns\n",
      "9.27 % 1.21 mns\n",
      "12.35 % 1.57 mns\n",
      "15.44 % 1.93 mns\n",
      "18.53 % 2.29 mns\n",
      "21.62 % 2.66 mns\n",
      "24.71 % 3.02 mns\n",
      "27.8 % 3.38 mns\n",
      "30.89 % 3.73 mns\n",
      "33.98 % 4.08 mns\n",
      "37.06 % 4.42 mns\n",
      "40.15 % 4.77 mns\n",
      "43.24 % 5.12 mns\n",
      "46.33 % 5.48 mns\n",
      "49.42 % 5.85 mns\n",
      "52.51 % 6.2 mns\n",
      "55.6 % 6.56 mns\n",
      "58.68 % 6.92 mns\n",
      "61.77 % 7.27 mns\n",
      "64.86 % 7.63 mns\n",
      "67.95 % 8.0 mns\n",
      "71.04 % 8.37 mns\n",
      "74.13 % 8.75 mns\n",
      "77.22 % 9.11 mns\n",
      "80.31 % 9.46 mns\n",
      "83.39 % 9.91 mns\n",
      "86.48 % 10.29 mns\n",
      "89.57 % 10.7 mns\n",
      "92.66 % 11.15 mns\n",
      "95.75 % 11.54 mns\n",
      "98.84 % 11.86 mns\n",
      "100 % done 12.13 mns\n",
      "\n",
      "300 Curitiba\n",
      "600 Curitiba\n",
      "1000 Curitiba\n",
      "CPU times: total: 28min 4s\n",
      "Wall time: 37min 50s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Curitiba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2,054,010.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>66.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>39.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>91,448.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>45.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>33.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>55.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>197.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>125,504.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>40.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>24.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>50.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>436.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>144,770.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>33.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>20.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                       Curitiba\n",
       "0                      2,054,010.00\n",
       "Sc-access 300                 66.46\n",
       "M-dist 300                    39.39\n",
       "M-area 300                91,448.58\n",
       "M-supply 300                  45.56\n",
       "Sc-norm 300                   33.35\n",
       "Sc-access 600                 55.54\n",
       "M-dist 600                   197.52\n",
       "M-area 600               125,504.12\n",
       "M-supply 600                  40.23\n",
       "Sc-norm 600                   24.66\n",
       "Sc-access 1000                50.03\n",
       "M-dist 1000                  436.28\n",
       "M-area 1000              144,770.66\n",
       "M-supply 1000                 33.80\n",
       "Sc-norm 1000                  20.21"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Curitiba'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext ='_Curitiba')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d51018ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cameroon']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/d5231a49e52f5d6484cfb682336df750-3434d5a769e7c28562aa034bd91a64ec:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\CMR_Yaounde_2020.tif\n",
      "get road networks from OSM\n",
      "Yaounde done 0.71 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Yaounde done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Yaounde 1.92 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Yaounde 0.0 % done 0.01  mns\n",
      "Yaounde 44.6 % done 0.48  mns\n",
      "Yaounde 89.3 % done 0.84  mns\n",
      "Yaounde 100 % done 0.97  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "36.31 % 0.22 mns\n",
      "72.62 % 0.47 mns\n",
      "100 % finding combinations done\n",
      "Yaounde 446602 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Yaounde\n",
      "0.0 % done 0.43 mns\n",
      "36.31 % done 0.48 mns\n",
      "72.62 % done 0.55 mns\n",
      "100 % done 0.62 mns\n",
      "\n",
      "Yaounde\n",
      "0.0 % 0.12 mns\n",
      "8.52 % 0.48 mns\n",
      "17.03 % 0.85 mns\n",
      "25.55 % 1.24 mns\n",
      "34.06 % 1.6 mns\n",
      "42.58 % 1.94 mns\n",
      "51.09 % 2.29 mns\n",
      "59.61 % 2.6 mns\n",
      "68.12 % 2.93 mns\n",
      "76.64 % 3.3 mns\n",
      "85.15 % 3.68 mns\n",
      "93.67 % 4.0 mns\n",
      "100 % done 4.25 mns\n",
      "\n",
      "300 Yaounde\n",
      "600 Yaounde\n",
      "1000 Yaounde\n",
      "CPU times: total: 6min 42s\n",
      "Wall time: 9min 45s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Yaounde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3,265,872.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>3,670.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>12.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>57,797,987.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>3,641.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>2,619.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>3,231.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>78.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>61,225,156.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>3,246.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>2,230.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>2,786.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>267.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>66,873,870.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>2,828.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>1,810.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                        Yaounde\n",
       "0                      3,265,872.00\n",
       "Sc-access 300              3,670.07\n",
       "M-dist 300                    12.61\n",
       "M-area 300            57,797,987.94\n",
       "M-supply 300               3,641.46\n",
       "Sc-norm 300                2,619.49\n",
       "Sc-access 600              3,231.83\n",
       "M-dist 600                    78.85\n",
       "M-area 600            61,225,156.21\n",
       "M-supply 600               3,246.59\n",
       "Sc-norm 600                2,230.26\n",
       "Sc-access 1000             2,786.32\n",
       "M-dist 1000                  267.21\n",
       "M-area 1000           66,873,870.50\n",
       "M-supply 1000              2,828.08\n",
       "Sc-norm 1000               1,810.19"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Yaounde'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext ='_Yaounde')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0518d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Guatemala']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/0e4df133f539bd506383073a7f23eee0-173a95c3e06aa0c52e2e441804762bcd:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\GTM_Guatemala City_2020.tif\n",
      "get road networks from OSM\n",
      "Guatemala City done 1.34 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Guatemala City done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Guatemala City 1.82 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Guatemala City 0.0 % done 0.0  mns\n",
      "Guatemala City 11.5 % done 0.42  mns\n",
      "Guatemala City 23.0 % done 0.87  mns\n",
      "Guatemala City 34.5 % done 1.32  mns\n",
      "Guatemala City 46.0 % done 1.77  mns\n",
      "Guatemala City 57.5 % done 2.22  mns\n",
      "Guatemala City 69.0 % done 2.69  mns\n",
      "Guatemala City 80.6 % done 3.12  mns\n",
      "Guatemala City 92.1 % done 3.55  mns\n",
      "Guatemala City 100 % done 3.87  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "31.85 % 0.3 mns\n",
      "63.69 % 0.59 mns\n",
      "95.54 % 0.9 mns\n",
      "100 % finding combinations done\n",
      "Guatemala City 47007 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Guatemala City\n",
      "0.0 % done 0.85 mns\n",
      "31.85 % done 0.88 mns\n",
      "63.69 % done 0.91 mns\n",
      "95.54 % done 0.95 mns\n",
      "100 % done 0.96 mns\n",
      "\n",
      "Guatemala City\n",
      "0.0 % 0.1 mns\n",
      "100 % done 0.35 mns\n",
      "\n",
      "300 Guatemala City\n",
      "600 Guatemala City\n",
      "1000 Guatemala City\n",
      "CPU times: total: 9min 16s\n",
      "Wall time: 9min 34s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Guatemala City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2,373,141.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>797.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>792,500.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>770.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>70.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>778.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>26.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>901,640.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>788.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>67.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>770.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>39.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>953,478.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>767.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>66.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                 Guatemala City\n",
       "0                      2,373,141.00\n",
       "Sc-access 300                797.06\n",
       "M-dist 300                     4.69\n",
       "M-area 300               792,500.26\n",
       "M-supply 300                 770.71\n",
       "Sc-norm 300                   70.73\n",
       "Sc-access 600                778.97\n",
       "M-dist 600                    26.35\n",
       "M-area 600               901,640.23\n",
       "M-supply 600                 788.54\n",
       "Sc-norm 600                   67.52\n",
       "Sc-access 1000               770.15\n",
       "M-dist 1000                   39.64\n",
       "M-area 1000              953,478.01\n",
       "M-supply 1000                767.95\n",
       "Sc-norm 1000                  66.07"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Guatemala City'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext ='_Guatemala City')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3aabf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/766688c70de6749ca5de295d8d6afac8-47aa9a2e138632b5a3cf9de7ea8f2d0e:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\IND_Pune_2020.tif\n",
      "get road networks from OSM\n",
      "Pune done 1.3 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Pune done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Pune 0.55 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Pune 0.0 % done 0.0  mns\n",
      "Pune 27.5 % done 0.6  mns\n",
      "Pune 55.1 % done 1.18  mns\n",
      "Pune 82.6 % done 1.71  mns\n",
      "Pune 100 % done 2.06  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "51.87 % 0.23 mns\n",
      "100 % finding combinations done\n",
      "Pune 64441 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Pune\n",
      "0.0 % done 0.7 mns\n",
      "51.87 % done 0.75 mns\n",
      "100 % done 0.8 mns\n",
      "\n",
      "Pune\n",
      "0.0 % 0.11 mns\n",
      "46.9 % 0.45 mns\n",
      "93.8 % 0.71 mns\n",
      "100 % done 0.96 mns\n",
      "\n",
      "300 Pune\n",
      "600 Pune\n",
      "1000 Pune\n",
      "CPU times: total: 5min 31s\n",
      "Wall time: 6min 23s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Pune</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5,081,607.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>19.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>10.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>220,643.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>18.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>17.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>78.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>283,859.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>17.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>16.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>144.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>316,408.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>15.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                           Pune\n",
       "0                      5,081,607.00\n",
       "Sc-access 300                 19.92\n",
       "M-dist 300                    10.54\n",
       "M-area 300               220,643.84\n",
       "M-supply 300                  18.30\n",
       "Sc-norm 300                    0.67\n",
       "Sc-access 600                 17.86\n",
       "M-dist 600                    78.36\n",
       "M-area 600               283,859.52\n",
       "M-supply 600                  17.23\n",
       "Sc-norm 600                    0.55\n",
       "Sc-access 1000                16.71\n",
       "M-dist 1000                  144.03\n",
       "M-area 1000              316,408.71\n",
       "M-supply 1000                 15.14\n",
       "Sc-norm 1000                   0.48"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Pune'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext ='_Pune')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fa0a711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['China']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/3613951bc60844db8f55100b0acea339-2afd0e944e30b3cc8dd592566f323919:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\CHN_Chengdu_2020.tif\n",
      "get road networks from OSM\n",
      "Chengdu done 1.29 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Chengdu done\n",
      " \n",
      "100m resolution grids extraction\n",
      "Chengdu 2.19 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "Chengdu 0.0 % done 0.0  mns\n",
      "Chengdu 17.9 % done 0.32  mns\n",
      "Chengdu 35.8 % done 0.66  mns\n",
      "Chengdu 53.8 % done 0.99  mns\n",
      "Chengdu 71.7 % done 1.3  mns\n",
      "Chengdu 89.6 % done 1.6  mns\n",
      "Chengdu 100 % done 1.78  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "32.18 % 0.34 mns\n",
      "64.35 % 0.68 mns\n",
      "96.53 % 1.04 mns\n",
      "100 % finding combinations done\n",
      "Chengdu 143214 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "Chengdu\n",
      "0.0 % done 0.53 mns\n",
      "32.18 % done 0.67 mns\n",
      "64.35 % done 0.82 mns\n",
      "96.53 % done 0.97 mns\n",
      "100 % done 0.99 mns\n",
      "\n",
      "Chengdu\n",
      "0.0 % 0.1 mns\n",
      "42.8 % 0.45 mns\n",
      "85.59 % 0.72 mns\n",
      "100 % done 0.97 mns\n",
      "\n",
      "300 Chengdu\n",
      "600 Chengdu\n",
      "1000 Chengdu\n",
      "CPU times: total: 7min 43s\n",
      "Wall time: 8min 42s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>Chengdu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6,218,911.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>122.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>7.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>256,418.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>116.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>41.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>122.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>61.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>353,290.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>125.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>43.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>134.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>167.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>467,216.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>145.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>54.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                        Chengdu\n",
       "0                      6,218,911.00\n",
       "Sc-access 300                122.64\n",
       "M-dist 300                     7.76\n",
       "M-area 300               256,418.08\n",
       "M-supply 300                 116.18\n",
       "Sc-norm 300                   41.07\n",
       "Sc-access 600                122.61\n",
       "M-dist 600                    61.68\n",
       "M-area 600               353,290.13\n",
       "M-supply 600                 125.59\n",
       "Sc-norm 600                   43.57\n",
       "Sc-access 1000               134.39\n",
       "M-dist 1000                  167.27\n",
       "M-area 1000              467,216.31\n",
       "M-supply 1000                145.11\n",
       "Sc-norm 1000                  54.43"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['Chengdu'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext ='_Chengdu')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82a47c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States']\n",
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/cbced9cb68041f4e09caa8b62895c080-41170d1a48ef13abae89090c03d7301c:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to D:\\Dumps\\GEE_city_grids\\USA_San Antonio_2020.tif\n",
      "get road networks from OSM\n",
      "San Antonio done 3.73 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "San Antonio done\n",
      " \n",
      "100m resolution grids extraction\n",
      "San Antonio 10.41 mns\n",
      "\n",
      "get fake UGS entry points\n",
      "San Antonio 0.0 % done 0.11  mns\n",
      "San Antonio 14.0 % done 1.56  mns\n",
      "San Antonio 28.0 % done 3.01  mns\n",
      "San Antonio 42.0 % done 4.43  mns\n",
      "San Antonio 56.0 % done 5.78  mns\n",
      "San Antonio 70.0 % done 7.26  mns\n",
      "San Antonio 84.0 % done 8.57  mns\n",
      "San Antonio 98.0 % done 9.88  mns\n",
      "San Antonio 100 % done 10.13  mns\n",
      "\n",
      "get (Euclidean) suitible combinations\n",
      "0.0 % 0.0 mns\n",
      "18.83 % 0.94 mns\n",
      "37.65 % 1.89 mns\n",
      "56.48 % 2.85 mns\n",
      "75.3 % 3.8 mns\n",
      "94.13 % 4.77 mns\n",
      "100 % finding combinations done\n",
      "San Antonio 209691 suitible combinations\n",
      "\n",
      "obtain local graphs\n",
      "San Antonio\n",
      "0.0 % done 4.56 mns\n",
      "18.83 % done 4.62 mns\n",
      "37.65 % done 4.69 mns\n",
      "56.48 % done 4.78 mns\n",
      "75.3 % done 4.87 mns\n",
      "94.13 % done 4.97 mns\n",
      "100 % done 5.01 mns\n",
      "\n",
      "San Antonio\n",
      "0.0 % 0.11 mns\n",
      "19.85 % 0.46 mns\n",
      "39.69 % 0.81 mns\n",
      "59.54 % 1.17 mns\n",
      "79.39 % 1.55 mns\n",
      "99.24 % 1.81 mns\n",
      "100 % done 2.07 mns\n",
      "\n",
      "300 San Antonio\n",
      "600 San Antonio\n",
      "1000 San Antonio\n",
      "CPU times: total: 35min 54s\n",
      "Wall time: 37min 30s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>City</th>\n",
       "      <th>San Antonio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2,168,868.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>845.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>4.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>214,639.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>921.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>579.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>689.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>39.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>360,971.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>860.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>441.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>694.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>95.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>525,893.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>870.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>441.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "City                    San Antonio\n",
       "0                      2,168,868.00\n",
       "Sc-access 300                845.87\n",
       "M-dist 300                     4.93\n",
       "M-area 300               214,639.84\n",
       "M-supply 300                 921.52\n",
       "Sc-norm 300                  579.78\n",
       "Sc-access 600                689.16\n",
       "M-dist 600                    39.07\n",
       "M-area 600               360,971.62\n",
       "M-supply 600                 860.53\n",
       "Sc-norm 600                  441.11\n",
       "Sc-access 1000               694.65\n",
       "M-dist 1000                   95.45\n",
       "M-area 1000              525,893.06\n",
       "M-supply 1000                870.82\n",
       "Sc-norm 1000                 441.46"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Thresholds and cities\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m\n",
    "\n",
    "# Extract cities list\n",
    "iso = pd.read_excel('iso_countries.xlsx')\n",
    "cities = pd.read_excel('cities.xlsx')\n",
    "cities_adj = cities[cities['City'].isin(['San Antonio'])]\n",
    "cities_adj = cities_adj.reset_index()\n",
    "\n",
    "# 1. Required preprocess for information extraction\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Predifine in Excel: the (1) city name as \"City\" and (2) the OSM area that needs to be extracted as \"OSM_area\"\n",
    "# i.e. City = \"Los Angeles\" and OSM_area = \"Los Angeles county, Orange county CA\"\n",
    "files = gee_worldpop_extract(cities_adj,iso,'D:/Dumps/GEE_city_grids/')\n",
    "\n",
    "# Files are downloaded automatically to the specified path. Files are also stored in Google with a downloadlink:\n",
    "\n",
    "# 2. Information extraction\n",
    "\n",
    "# Get road networks\n",
    "road_networks = road_network(cities_adj, # Get 'all' (drive,walk,bike) network\n",
    "                              thresholds,\n",
    "                              undirected = True)\n",
    "print(' ')\n",
    "# Extract urban greenspace (UGS)\n",
    "UGS = urban_greenspace(cities_adj, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)\n",
    "\n",
    "print(' ')\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(files,\n",
    "                                     cities_adj['OSM_area'],\n",
    "                                     road_networks['nodes'],\n",
    "                                     UGS,\n",
    "                                     grid_size = 100) # aggregating upwards to i.e. 200m, 300m etc. is possible\n",
    "print('')\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_networks['nodes'], \n",
    "                           road_networks['graphs'],\n",
    "                           cities_adj['City'],\n",
    "                           population_grids,\n",
    "                           thresholds,\n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print('')\n",
    "suitible_enh = suitible_enhanced(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_networks['nodes'], \n",
    "                                 cities_adj['City'], \n",
    "                                 thresholds)\n",
    "print('')\n",
    "subgraphs = obtaining_subgraphs(road_networks['graphs'],\n",
    "                                population_grids,\n",
    "                                UGS_entry,\n",
    "                                road_networks['nodes'],\n",
    "                                cities_adj['City'],\n",
    "                                thresholds)\n",
    "print('')\n",
    "Dir_Routes = direct_routing (suitible_enh,\n",
    "                             subgraphs['graphs'],\n",
    "                             road_networks['edges'],\n",
    "                             cities_adj['City'])\n",
    "print('')\n",
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Dir_Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, \n",
    "                             population_grids, \n",
    "                             thresholds, \n",
    "                             cities_adj['City'], \n",
    "                             save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA_adj/', \n",
    "                             grid_size = 100,\n",
    "                             ext ='_San Antonio')\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0bde4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gee_worldpop_extract (city_file, iso, save_path = None):\n",
    "    \n",
    "    cities = city_file\n",
    "    iso['name'] = np.where(iso['name'] == 'Macedonia','North Macedonia',iso['name'])\n",
    "    \n",
    "    # Get included city areas\n",
    "    OSM_incl = [cities[cities['City'] == city]['OSM_area'].tolist()[0].rsplit(', ') for city in cities['City'].tolist()]\n",
    "\n",
    "    # Get the city geoms\n",
    "    obj = [city_geo(city).dissolve()['geometry'].tolist()[0] for city in OSM_incl]\n",
    "    \n",
    "    # Get the city countries\n",
    "    obj_displ = [city_geo(city).dissolve()['display_name'].tolist()[0].rsplit(', ')[-1]for city in OSM_incl]\n",
    "    print(obj_displ)\n",
    "    obj_displ = np.where(pd.Series(obj_displ).str.contains(\"Ivoire\"),\"CIte dIvoire\",obj_displ)\n",
    "\n",
    "    # Get the country's iso-code\n",
    "    iso_list = [iso[iso['name'] == ob]['alpha3'].tolist()[0] for ob in obj_displ]\n",
    "\n",
    "    # Based on the iso-code return the worldpop 2020\n",
    "    ee_worldpop = [ee.ImageCollection(\"WorldPop/GP/100m/pop\")\\\n",
    "        .filter(ee.Filter.date('2020'))\\\n",
    "        .filter(ee.Filter.inList('country', [io])).first() for io in iso_list]\n",
    "\n",
    "    # Clip the countries with the city geoms.\n",
    "    clipped = [ee_worldpop[i].clip(shapely.geometry.mapping(obj[i])) for i in range(0,len(obj))]\n",
    "\n",
    "    # Create path if non-existent\n",
    "    if save_path == None:\n",
    "        path = ''\n",
    "    else:\n",
    "        path = save_path\n",
    "        if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "\n",
    "    # Export as TIFF file.\n",
    "    # Stored in form path + USA_Los Angeles_2020.tif\n",
    "    filenames = [path+iso_list[i]+'_'+cities['City'][i]+'_2020.tif' for i in range(len(obj))]\n",
    "    [geemap.ee_export_image(clipped[i], filename = filenames[i]) for i in range(0,len(obj))]\n",
    "    return(filenames)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Block 2 Road networks\n",
    "def road_network (cities, thresholds, undirected = False):\n",
    "    print('get road networks from OSM')\n",
    "    start_time = time.time()\n",
    "    graphs = list()\n",
    "    road_nodes = list()\n",
    "    road_edges = list()\n",
    "    road_conn = list()\n",
    "\n",
    "    for i in enumerate(cities['OSM_area']):\n",
    "        # Get graph, road nodes and edges\n",
    "        road_node = pd.DataFrame()\n",
    "        roads = pd.DataFrame()\n",
    "        \n",
    "        # For each included OSM_area get the roads\n",
    "        for district in i[1].rsplit(', '):\n",
    "            graph = ox.graph_from_place(district, network_type = \"all\", buffer_dist = (np.max(thresholds)+1000))\n",
    "            node, edge = ox.graph_to_gdfs(graph)\n",
    "            road_node = pd.concat([road_node, node], axis = 0)\n",
    "            roads = pd.concat([roads, edge], axis = 0)\n",
    "        \n",
    "        # Eliminate lists in the df which prevents drop of duplicate columns\n",
    "        road_edge = pd.DataFrame([[c[0] if isinstance(c,list) else c for c in roads[col]]\\\n",
    "                              for col in roads]).transpose()\n",
    "        road_edge.columns = roads.columns\n",
    "        road_edge.index = roads.index\n",
    "        road_edge = gpd.GeoDataFrame(road_edge, crs = 4326)\n",
    "        \n",
    "        # Return the unique nodes and edges of the (often) adjacent OSM_areas.\n",
    "        road_node = road_node.drop_duplicates()\n",
    "        road_edge = road_edge.drop_duplicates()\n",
    "        \n",
    "        # Road nodes format\n",
    "        road_node = road_node.to_crs(4326)\n",
    "        road_node['geometry_m'] = gpd.GeoSeries(road_node['geometry'], crs = 4326).to_crs(3043)\n",
    "        road_node['osmid_var'] = road_node.index\n",
    "        road_node = gpd.GeoDataFrame(road_node, geometry = 'geometry', crs = 4326)\n",
    "\n",
    "        # format road edges\n",
    "        road_edge['geometry_m'] = gpd.GeoSeries(road_edge['geometry'], crs = 4326).to_crs(3043)\n",
    "        road_edge = road_edge.reset_index()\n",
    "        road_edge.rename(columns={'u':'from', 'v':'to', 'key':'keys'}, inplace=True)\n",
    "        road_edge['key'] = road_edge['from'].astype(str) + '-' + road_edge['to'].astype(str)\n",
    "        \n",
    "        if undirected == True:\n",
    "            # Apply one-directional to both for walking\n",
    "            both = road_edge[road_edge['oneway'] == False]\n",
    "            one = road_edge[road_edge['oneway'] == True]\n",
    "            rev = pd.DataFrame()\n",
    "            rev[['from','to']] = one[['to','from']]\n",
    "            rev = pd.concat([rev,one.iloc[:,2:]],axis = 1)\n",
    "            edge_bidir = pd.concat([both, one, rev])\n",
    "            edge_bidir = edge_bidir.reset_index()\n",
    "            edge_bidir['oneway'] = False\n",
    "        else:\n",
    "            edge_bidir = road_edge\n",
    "\n",
    "        # Exclude highways and ramps on edges    \n",
    "        edge_filter = edge_bidir[(edge_bidir['highway'].str.contains('motorway') | \n",
    "              (edge_bidir['highway'].str.contains('trunk') & \n",
    "               edge_bidir['maxspeed'].astype(str).str.contains(\n",
    "                   '40 mph|45 mph|50 mph|55 mph|60 mph|65|70|75|80|85|90|95|100|110|120|130|140'))) == False]\n",
    "        road_edges.append(edge_filter)\n",
    "\n",
    "        # Exclude isolated nodes\n",
    "        fltrnodes = pd.Series(list(edge_filter['from']) + list(edge_filter['to'])).unique()\n",
    "        newnodes = road_node[road_node['osmid_var'].isin(fltrnodes)]\n",
    "        road_nodes.append(newnodes)\n",
    "\n",
    "        # Get only necessary road connections columns for network performance\n",
    "        road_con = edge_filter[['osmid','key','length','geometry']]\n",
    "        road_con = road_con.set_index('key')\n",
    "\n",
    "        road_conn.append(road_con)\n",
    "\n",
    "        # formatting to graph again.\n",
    "        newnodes = newnodes.loc[:, ~newnodes.columns.isin(['geometry_m', 'osmid_var'])]\n",
    "        edge_filter = edge_filter.set_index(['from','to','keys'])\n",
    "        edge_filter = edge_filter.loc[:, ~edge_filter.columns.isin(['geometry_m', 'key'])]\n",
    "\n",
    "        graph2 = ox.graph_from_gdfs(newnodes, edge_filter)\n",
    "\n",
    "        graphs.append(graph2)\n",
    "        print(cities['City'][i[0]].rsplit(',')[0], 'done', round((time.time() - start_time) / 60,2),'mns')\n",
    "    return({'graphs':graphs,'nodes':road_nodes,'edges':road_conn,'edges long':road_edges})\n",
    "# Block 3 city greenspace\n",
    "def urban_greenspace (cities, thresholds, one_UGS_buf = 25, min_UGS_size = 400):\n",
    "    print('get urban greenspaces from OSM')\n",
    "    parks_in_range = list()\n",
    "    for i in enumerate(cities['OSM_area']):\n",
    "        # Tags seen as Urban Greenspace (UGS) require the following:\n",
    "        # 1. Tag represent an area\n",
    "        # 2. The area is outdoor\n",
    "        # 3. The area is (semi-)publically available\n",
    "        # 4. The area is likely to contain trees, grass and/or greenery\n",
    "        # 5. The area can reasonable be used for walking or recreational activities\n",
    "        tags = {'landuse':['allotments','forest','greenfield','village_green'],\\\n",
    "                'leisure':['garden','fitness_station','nature_reserve','park','playground'],\\\n",
    "                'natural':'grassland'}\n",
    "        gdf = ox.geometries_from_place(i[1].rsplit(', '),tags = tags,buffer_dist = np.max(thresholds))\n",
    "        gdf = gdf[(gdf.geom_type == 'Polygon') | (gdf.geom_type == 'MultiPolygon')]\n",
    "        greenspace = gdf.reset_index()    \n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        green_buffer = gpd.GeoDataFrame(geometry = greenspace.to_crs(3043).buffer(one_UGS_buf).to_crs(4326))\n",
    "        greenspace['geometry_w_buffer'] = green_buffer\n",
    "        greenspace['geometry_w_buffer'] = gpd.GeoSeries(greenspace['geometry_w_buffer'], crs = 4326)\n",
    "        greenspace['geom buffer diff'] = greenspace['geometry_w_buffer'].difference(greenspace['geometry'])\n",
    "\n",
    "        # This function group components in itself that overlap (with the buffer set of 25 metres)\n",
    "        # https://stackoverflow.com/questions/68036051/geopandas-self-intersection-grouping\n",
    "        W = libpysal.weights.fuzzy_contiguity(greenspace['geometry_w_buffer'])\n",
    "        greenspace['components'] = W.component_labels\n",
    "        parks = greenspace.dissolve('components')\n",
    "\n",
    "        # Exclude parks below 0.04 ha.\n",
    "        parks = parks[parks.to_crs(3043).area > min_UGS_size]\n",
    "        print(cities['City'][i[0]], 'done')\n",
    "        parks = parks.reset_index()\n",
    "        parks['geometry_m'] = parks['geometry'].to_crs(3043)\n",
    "        parks['park_area'] = parks['geometry_m'].area\n",
    "        parks_in_range.append(parks)\n",
    "    return(parks_in_range)\n",
    "# Block 4 population grids extraction\n",
    "def city_grids_format(city_grids, cities_area, road_nodes, UGS, grid_size = 100):\n",
    "    start_time = time.time()\n",
    "    grids = []\n",
    "    print(str(grid_size) + 'm resolution grids extraction')\n",
    "    for i in range(len(city_grids)):\n",
    "        \n",
    "        # Open the raster file\n",
    "        with rasterio.open(city_grids[i]) as src:\n",
    "            band= src.read() # the population values\n",
    "            aff = src.transform # the raster bounds and size (affine)\n",
    "        \n",
    "        # Get the rowwise arrays, get a 2D dataframe\n",
    "        grid = pd.DataFrame()\n",
    "        for b in enumerate(band[0]):\n",
    "            grid = pd.concat([grid, pd.Series(b[1],name=b[0])],axis=1)\n",
    "        grid= grid.unstack().reset_index()\n",
    "        \n",
    "        # Unstack df to columns\n",
    "        grid.columns = ['row','col','value']\n",
    "        grid['minx'] = aff[2]+aff[0]*grid['col']\n",
    "        grid['miny'] = aff[5]+aff[4]*grid['row']\n",
    "        grid['maxx'] = aff[2]+aff[0]*grid['col']+aff[0]\n",
    "        grid['maxy'] = aff[5]+aff[4]*grid['row']+aff[4]\n",
    "        \n",
    "        # Create polygon from affine bounds and row/col indices\n",
    "        grid['geometry'] = [Polygon([(grid.minx[i],grid.miny[i]),\n",
    "                                   (grid.maxx[i],grid.miny[i]),\n",
    "                                   (grid.maxx[i],grid.maxy[i]),\n",
    "                                   (grid.minx[i],grid.maxy[i])])\\\n",
    "                          for i in range(len(grid))]\n",
    "        \n",
    "        # Set the df as geo-df\n",
    "        grid = gpd.GeoDataFrame(grid, crs = 4326) \n",
    "\n",
    "        # Get dissolvement_key for dissolvement. \n",
    "        grid['row3'] = np.floor(grid['row']/(grid_size/100)).astype(int)\n",
    "        grid['col3'] = np.floor(grid['col']/(grid_size/100)).astype(int)\n",
    "        grid['dissolve_key'] = grid['row3'].astype(str) +'-'+ grid['col3'].astype(str)\n",
    "        \n",
    "        # Define a city's OSM area as Polygon.\n",
    "        geo_ls = gpd.GeoSeries(city_geo(cities_area[i].split(', ')).dissolve().geometry)\n",
    "        \n",
    "        # Intersect grids with the city boundary Polygon.\n",
    "        insec = grid.intersection(geo_ls.tolist()[0])\n",
    "        \n",
    "        # Exclude grids outside the specified city boundaries\n",
    "        insec = insec[insec.area > 0]\n",
    "        \n",
    "        # Join in other information.\n",
    "        insec = gpd.GeoDataFrame(geometry = insec, crs = 4326).join(grid.loc[:, grid.columns != 'geometry'])\n",
    "        \n",
    "        # Dissolve into block by block grids\n",
    "        popgrid = insec[['dissolve_key','geometry','row3','col3']].dissolve('dissolve_key')\n",
    "        \n",
    "        # Get those grids populations and area. Only blocks with population and full blocks\n",
    "        popgrid['population'] = round(insec.groupby('dissolve_key')['value'].sum()).astype(int)\n",
    "        popgrid['area_m'] = round(gpd.GeoSeries(popgrid['geometry'], crs = 4326).to_crs(3043).area).astype(int)\n",
    "        popgrid = popgrid[popgrid['population'] > 0]\n",
    "        popgrid = popgrid[popgrid['area_m'] / popgrid['area_m'].max() > 0.95]\n",
    "\n",
    "        # Get centroids and coords\n",
    "        popgrid['centroid'] = popgrid['geometry'].centroid\n",
    "        popgrid['centroid_m'] = gpd.GeoSeries(popgrid['centroid'], crs = 4326).to_crs(3043)\n",
    "        popgrid['grid_lon'] = popgrid['centroid_m'].x\n",
    "        popgrid['grid_lat'] = popgrid['centroid_m'].y\n",
    "        popgrid = popgrid.reset_index()\n",
    "\n",
    "        minx = popgrid.bounds['minx']\n",
    "        maxx = popgrid.bounds['maxx']\n",
    "        miny = popgrid.bounds['miny']\n",
    "        maxy = popgrid.bounds['maxy']\n",
    "\n",
    "        # Some geometries result in a multipolygon when dissolving (like i.e. 0.05 meters), coords error.\n",
    "        # Therefore recreate the polygon.\n",
    "        Poly = []\n",
    "        for k in range(len(popgrid)):\n",
    "            Poly.append(Polygon([(minx[k],maxy[k]),(maxx[k],maxy[k]),(maxx[k],miny[k]),(minx[k],miny[k])]))\n",
    "        popgrid['geometry'] = Poly\n",
    "        \n",
    "        try:\n",
    "            entry_index = [int(road_nodes[i]['geometry'].sindex.nearest(grid)[1])\\\n",
    "                                 for grid in popgrid['centroid']]\n",
    "        except:\n",
    "            entry_index = [int(road_nodes[i]['geometry'].sindex.nearest(grid)[1][0])\\\n",
    "                                 for grid in popgrid['centroid']]\n",
    "            \n",
    "        nearest_index = road_nodes[i].iloc[entry_index]\n",
    "        popgrid['grid_osm'] = nearest_index.reset_index(drop = True)['osmid_var']\n",
    "        popgrid['node_geom'] = nearest_index.reset_index(drop = True)['geometry']\n",
    "        popgrid['node_geom_m'] = nearest_index.reset_index(drop = True)['geometry_m']\n",
    "        popgrid['G-entry cost'] = popgrid['node_geom_m'].distance(popgrid['centroid_m'])\n",
    "        \n",
    "        UGS_all = UGS[i].dissolve().geometry[0]\n",
    "        popgrid['in_out_UGS'] = popgrid.intersection(UGS_all).is_empty == False\n",
    "        \n",
    "        grids.append(popgrid)\n",
    "\n",
    "        print(city_grids[i].rsplit('_')[3], round((time.time() - start_time)/60,2),'mns')\n",
    "    return(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59bebc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5 park entry points\n",
    "def UGS_fake_entry(UGS, road_nodes, graphs, cities, pop_grids,\n",
    "                   thresholds, UGS_entry_buf = 25, walk_radius = 500, entry_point_merge = 0):\n",
    "    print('get fake UGS entry points')\n",
    "    start_time = time.time()\n",
    "    ParkRoads = list()\n",
    "    for j in range(len(cities)):\n",
    "        ParkRoad = pd.DataFrame()\n",
    "        mat = list()\n",
    "        # For all\n",
    "        for i in range(len(UGS[j])):\n",
    "            dist = road_nodes[j]['geometry'].to_crs(3043).distance(UGS[j]['geometry'].to_crs(\n",
    "                3043)[i])\n",
    "            buf_nodes = road_nodes[j][(dist < UGS_entry_buf) & (dist > 0)]\n",
    "            mat.append(list(np.repeat(i, len(buf_nodes))))\n",
    "            ParkRoad = pd.concat([ParkRoad, buf_nodes])\n",
    "            if i % 100 == 0: print(cities[j].rsplit(',')[0], round(i/len(UGS[j])*100,1),'% done', \n",
    "                                  round((time.time() - start_time) / 60,2),' mns')\n",
    "        # Park no list conversion\n",
    "        mat_u = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat) for i in b]\n",
    "\n",
    "        # Format\n",
    "        ParkRoad['Park_No'] = mat_u\n",
    "        ParkRoad = ParkRoad.reset_index()\n",
    "        ParkRoad['park_lon'] = ParkRoad['geometry_m'].x\n",
    "        ParkRoad['park_lat'] = ParkRoad['geometry_m'].y\n",
    "        \n",
    "        # Get the road nodes intersecting with the parks' buffer\n",
    "        ParkRoad = pd.merge(ParkRoad, UGS[j][['geometry','park_area']], left_on = 'Park_No', right_index = True)\n",
    "\n",
    "        # Get the walkable park size\n",
    "        ParkRoad['park_size_walkable'] = ParkRoad['geometry_m'].buffer(walk_radius).to_crs(4326).intersection(ParkRoad['geometry_y'].to_crs(4326))\n",
    "        ParkRoad['walk_area'] = ParkRoad['park_size_walkable'].to_crs(3043).area\n",
    "        ParkRoad['park_area'] = ParkRoad['geometry_y'].to_crs(3043).area\n",
    "        ParkRoad['share_walked'] = ParkRoad['walk_area'] / ParkRoad['park_area']\n",
    "                \n",
    "        # Merge fake UGS entry points if within X meters of each other for better system performance\n",
    "        # Standard no merging\n",
    "        ParkRoad = simplify_UGS_entry(ParkRoad, entry_point_merge = 0)\n",
    "                \n",
    "        ParkRoads.append(ParkRoad)\n",
    "\n",
    "        print(cities[j].rsplit(',')[0],'100 % done', \n",
    "                                  round((time.time() - start_time) / 60,2),' mns')\n",
    "        \n",
    "    return(ParkRoads)\n",
    "# Block 5.5 (not in use, buffer is 0, thus retains all the park entry points as is)\n",
    "def simplify_UGS_entry(fake_UGS_entry, entry_point_merge = 0):\n",
    "    # Get buffer of nodes close to each other.\n",
    "    # Get the buffer\n",
    "    ParkComb = fake_UGS_entry\n",
    "    ParkComb['geometry_m_buffer'] = ParkComb['geometry_m'].buffer(entry_point_merge)\n",
    "\n",
    "    # Get and merge components\n",
    "    M = libpysal.weights.fuzzy_contiguity(ParkComb['geometry_m_buffer'])\n",
    "    ParkComb['components'] = M.component_labels\n",
    "\n",
    "    # Take centroid of merged components\n",
    "    centr = gpd.GeoDataFrame(ParkComb, geometry = 'geometry_x', crs = 4326).dissolve('components')['geometry_x'].centroid\n",
    "    centr = gpd.GeoDataFrame(centr)\n",
    "    centr.columns = ['comp_centroid']\n",
    "\n",
    "    # Get node closest to the centroid of all merged nodes, which accesses the road network.\n",
    "    ParkComb = pd.merge(ParkComb, centr, left_on = 'components', right_index = True)\n",
    "    ParkComb['centr_dist'] = ParkComb['geometry_x'].distance(ParkComb['comp_centroid'])\n",
    "    ParkComb = ParkComb.iloc[ParkComb.groupby('components')['centr_dist'].idxmin()]\n",
    "    return(ParkComb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371c0f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suitible_enhanced (UGS_entry, pop_grids, road_nodes, cities, thresholds):\n",
    "    start_time = time.time()\n",
    "    suits_all = []\n",
    "    for j in range(len(cities)):\n",
    "        print('get (Euclidean) suitible combinations')\n",
    "        print('0.0 %', round((time.time() - start_time) / 60,2),'mns')\n",
    "        UGSe = UGS_entry[j]\n",
    "        entry_geoms = UGSe.geometry_m\n",
    "        pop = pop_grids[j]\n",
    "        road_node = road_nodes[j]\n",
    "\n",
    "        suits = pd.DataFrame()\n",
    "        cols = ['osmid','Park_No','park_area']\n",
    "        for i in range(len(entry_geoms)):\n",
    "            suit_df = pop[pop.node_geom_m.distance(entry_geoms.iloc[i]) < np.max(thresholds)]\n",
    "        \n",
    "            suit_df['UGSe_osmid_m'] = entry_geoms.iloc[i]\n",
    "            suit_df['Grid_No'] = suit_df.index\n",
    "            suit_df = suit_df[['Grid_No','grid_osm','G-entry cost','in_out_UGS','node_geom_m','UGSe_osmid_m']].reset_index(drop = True)\n",
    "            suit_df['Park_entry_No'] = UGSe.index[i]\n",
    "            suits = pd.concat([suits,suit_df])\n",
    "            if (i+1) % 500 == 0: print(round((i+1) / len(entry_geoms)*100,2),'%',\n",
    "                                       round((time.time() - start_time) / 60,2),'mns')\n",
    "            \n",
    "        suits = pd.merge(suits, UGSe[cols], left_on = 'Park_entry_No',right_index = True, how = 'left')\n",
    "        suits = suits.reset_index(drop = True)\n",
    "        suits = suits.rename(columns = {'osmid':'Parkroad_osmid','park_area':'park_area_m2'})\n",
    "        suits['gridpark_no'] = suits['Grid_No'].astype(str)+'-'+suits['Park_No'].astype(str)\n",
    "        suits['graph_key'] = suits['grid_osm'].astype(str)+'-'+suits['Parkroad_osmid'].astype(str)\n",
    "        suits_all.append(suits)\n",
    "        print('100 % finding combinations done')\n",
    "        print(cities[j],len(suits),'suitible combinations')\n",
    "    return(suits_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6553bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtaining_subgraphs(graphs, pop_grids, UGS_entry, nodes, cities, thresholds, time_sleep = 30):\n",
    "    print('obtain local graphs')\n",
    "    start_time = time.time()\n",
    "    subgraphs_all = []\n",
    "    suits_all = []\n",
    "    for j in range(len(cities)):\n",
    "        print(cities[j])\n",
    "        Graph = graphs[j]\n",
    "        pop = pop_grids[j]\n",
    "        UGSe = UGS_entry[j].sort_values('osmid')\n",
    "        road_node = nodes[j]\n",
    "        node_geoms = road_node.geometry_m\n",
    "        entry_geoms = UGSe.geometry_m\n",
    "        osmid = UGSe['osmid']\n",
    "\n",
    "        dist = [node_geoms.distance(Point(i)) for i in entry_geoms]\n",
    "\n",
    "        print('0.0 % done',round((time.time() - start_time) / 60,2),'mns')\n",
    "        subgraphs = []\n",
    "        UGSe_ids = []\n",
    "        suits = pd.DataFrame()\n",
    "        for i in range(len(entry_geoms)):      \n",
    "            suit = road_node[['geometry_m']]\n",
    "            suit['UGSe_osmid_m'] = entry_geoms.iloc[i]\n",
    "            suit_df = dist[i]\n",
    "            suit_in = suit_df[suit_df <= max(thresholds)]\n",
    "            UGSe_ids.append(osmid.iloc[i])\n",
    "            suit_in = pd.DataFrame(suit_in).join(node_geoms)\n",
    "            suit_in['Parkroad_osmid'] = osmid.iloc[i]\n",
    "            subgraphs.append(Graph.subgraph(suit_in.index))\n",
    "            suits = pd.concat([suits, suit_in])\n",
    "\n",
    "            if (i+1) % 500 == 0: \n",
    "                print(round((i+1) / len(entry_geoms)*100,2),'% done',\n",
    "                                        round((time.time() - start_time) / 60,2),'mns')\n",
    "                time.sleep(time_sleep)\n",
    "        print('100 % done',round((time.time() - start_time) / 60,2),'mns')\n",
    "        subgraphs_all.append(pd.Series(subgraphs, index = UGSe_ids))\n",
    "        suits_all.append(suits)\n",
    "    return({'graphs':subgraphs_all,'graph nodes':suits_all})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeab83a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_fast (Geo_1, Geo_2):\n",
    "    return((abs(Geo_1.x - Geo_2.x)**2 + abs(Geo_1.y - Geo_2.y)**2).apply(math.sqrt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d879c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direct_routing (suitible_comb, graphs, edges, cities, chunk = 20000, time_sleep = 15):\n",
    "    start_time = time.time()\n",
    "    Routes = []\n",
    "    Lines = []\n",
    "    for j in enumerate(cities):\n",
    "        print(j[1])\n",
    "        \n",
    "        suitible = suitible_comb[j[0]].sort_values('Parkroad_osmid').reset_index()\n",
    "        grouped = suitible[suitible['in_out_UGS'] == False].groupby(['Parkroad_osmid'])['grid_osm'].apply(list)\n",
    "        sets = grouped.apply(np.unique)\n",
    "\n",
    "        Conn = edges[j[0]]\n",
    "        SG = graphs[j[0]]\n",
    "        SG = SG[sets.index]\n",
    "        \n",
    "        SGr = SG.reset_index()\n",
    "        SG = SGr.iloc[pd.Series(SGr['Parkroad_osmid'].drop_duplicates()).index].set_index('Parkroad_osmid')[0]\n",
    "\n",
    "        num = int(np.ceil(chunk / sets.apply(len).mean()))\n",
    "        length = int(np.ceil(len(suitible['Parkroad_osmid'].unique())/num))\n",
    "\n",
    "        Routes_df = pd.DataFrame()\n",
    "        Lines_df = pd.DataFrame()\n",
    "        for l in range(length):\n",
    "            comb = suitible[suitible['Parkroad_osmid'].isin(sets.index[l*num:l*num+num])]\n",
    "            sets2 = sets[l*num:l*num+num]\n",
    "\n",
    "            parknode = list(comb['Parkroad_osmid'])\n",
    "            gridnode = list(comb['grid_osm'])\n",
    "            subgraph = SG[sets2.index]\n",
    "            #sets2 = sets2[subgraph.index]\n",
    "\n",
    "            ls = []\n",
    "            ls2 = []\n",
    "            ls3 = []\n",
    "            lod = []\n",
    "            lgk = []\n",
    "            Routes\n",
    "            for i in range(len(sets2)):\n",
    "                path = nx.single_source_dijkstra(subgraph.iloc[i], sets2.index[i], weight = 'length')\n",
    "\n",
    "                incl = np.isin(list(path[0].keys()),sets2.iloc[i])\n",
    "                incl2 = np.isin(list(path[1].keys()),sets2.iloc[i])\n",
    "\n",
    "                # route cost\n",
    "                orig_c = list(np.repeat(sets2.index[i],sum(incl)))\n",
    "                dest_c = list(np.array(list(path[0].keys()))[incl])\n",
    "                cost = list(np.array(list(path[0].values()))[incl])\n",
    "\n",
    "                ls = ls + orig_c\n",
    "                ls2= ls2+ dest_c\n",
    "                ls3= ls3+ cost\n",
    "\n",
    "                # route steps\n",
    "                orig_s = list(np.repeat(sets2.index[i],sum(incl2)))\n",
    "                dest_s = list(np.array(list(path[1].keys()))[incl2])\n",
    "                steps = list(np.array(list(path[1].values()),dtype=object)[incl2])\n",
    "\n",
    "                fr = []\n",
    "                to = []\n",
    "                og = []\n",
    "                de = []\n",
    "                for j in enumerate(steps):\n",
    "                    if len(j[1]) > 1:\n",
    "                        fr.append(j[1][:-1])\n",
    "                        to.append(j[1][1:])\n",
    "                        og.append(list(np.repeat(orig_s[j[0]], len(j[1][:-1]))))\n",
    "                        de.append(list(np.repeat(dest_s[j[0]], len(j[1][:-1]))))\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                fr = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, fr) for i in b]\n",
    "                to = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, to) for i in b]\n",
    "                og = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, og) for i in b]\n",
    "                de = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, de) for i in b]\n",
    "\n",
    "                gk = [str(fr[k])+'-'+str(to[k]) for k in range(len(to))]\n",
    "                gkr = [str(to[k])+'-'+str(fr[k]) for k in range(len(to))]\n",
    "                od = [str(de[k])+'-'+str(og[k]) for k in range(len(og))]\n",
    "\n",
    "                lgk.append(gk)\n",
    "                lod.append(od)\n",
    "\n",
    "            dist_df = pd.DataFrame({'UGSe_id':ls,'GrE_id':ls2,'route cost':ls3})\n",
    "            dist_df['graph_key'] = dist_df['GrE_id'].astype(str)+'-'+dist_df['UGSe_id'].astype(str)\n",
    "\n",
    "            routes = pd.merge(comb, dist_df, on = 'graph_key', how = 'left')\n",
    "            routes['route cost'] = np.where(routes['in_out_UGS'],0,routes['route cost'])\n",
    "            routes = routes[~routes['route cost'].isna()].reset_index(drop = True)\n",
    "\n",
    "            routes['G-entry cost'] = np.where(routes['in_out_UGS'],0,routes['G-entry cost'])\n",
    "\n",
    "            routes['Tcost'] = routes['route cost']+routes['G-entry cost']\n",
    "\n",
    "            lgk = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, lgk) for i in b]\n",
    "            lod = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, lod) for i in b]\n",
    "            \n",
    "            linestr = pd.DataFrame({'route no':lod,'route step':lgk})\n",
    "            \n",
    "            linestr = pd.merge(linestr, Conn.geometry, left_on = 'route step', right_index = True, how = 'left')\n",
    "            linestr = linestr[['route no','geometry']]\n",
    "            linestr = gpd.GeoDataFrame(linestr[['route no','geometry']], crs = 4326)\n",
    "            \n",
    "            linestr = linestr.dissolve('route no')\n",
    "            routes2 = pd.merge(routes, linestr, left_on = 'graph_key', right_index = True, how = 'left')\n",
    "            \n",
    "            Lines_df = pd.concat([Lines_df, linestr])\n",
    "            Routes_df = pd.concat([Routes_df, routes2])\n",
    "            \n",
    "            print(round(l*num / len(sets)*100,2),'%', \n",
    "                  round((time.time() - start_time) / 60,2),'mns')\n",
    "            time.sleep(time_sleep)\n",
    "        Routes_df = Routes_df.sort_values('index')\n",
    "        Routes_df = Routes_df.set_index('index')\n",
    "        Routes_df = Routes_df.reset_index(drop = True)\n",
    "        \n",
    "        Routes_df = Routes_df[Routes_df.columns[~Routes_df.columns.isin(['UGSe_id', 'GrE_id'])]]\n",
    "        \n",
    "        print('100 % done',round((time.time() - start_time) / 60,2),'mns')\n",
    "        \n",
    "        Routes.append(Routes_df)\n",
    "        Lines.append(Lines_df)\n",
    "    return(Routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50bdbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_gridUGS_comb (routes, grids, UGS):\n",
    "    gp_nearest = []\n",
    "    for i in range(len(routes)):\n",
    "        gp_nn = routes[i][routes[i]['Tcost'] <= max(thresholds)]\n",
    "        gp_nn = pd.merge(gp_nn, grids[i]['population'], left_on='Grid_No', right_index = True)\n",
    "        gp_nn = pd.merge(gp_nn, UGS[i]['park_area'], left_on = 'Park_No', right_index = True)\n",
    "        gp_nn = gp_nn.reset_index()\n",
    "\n",
    "        gp_nn = gp_nn.iloc[gp_nn.groupby('gridpark_no')['Tcost'].idxmin()]\n",
    "        gp_nn.index.name = 'idx'\n",
    "        gp_nn = gp_nn.sort_values('idx')\n",
    "        gp_nn = gp_nn.reset_index()\n",
    "        gp_nearest.append(gp_nn)\n",
    "    gp_nearest[0].sort_values('Grid_No')\n",
    "    return(gp_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93760a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E2SCFA_scores(min_gridUGS_comb, grids, thresholds, cities, \n",
    "                  save_path = 'D:/Dumps/GEE-WP Scores/E2SFCA/', grid_size = 100, ext = ''):\n",
    "    pd.options.display.float_format = '{:20,.2f}'.format\n",
    "    E2SFCA_cities = []\n",
    "    E2SFCA_summary = pd.DataFrame()\n",
    "    for i in range(len(cities)):\n",
    "        E2SFCA_score = grids[i][['population','geometry']]\n",
    "        for j in range(len(thresholds)):\n",
    "            subset = min_gridUGS_comb[i][min_gridUGS_comb[i]['Tcost'] <= thresholds[j]]\n",
    "\n",
    "            # use gussian distribution: let v= 923325, then the weight for 800m is 0.5\n",
    "            v = -thresholds[j]**2/np.log(0.5)\n",
    "\n",
    "            # add a column of weight: apply the decay function on distance\n",
    "            subset['weight'] = np.exp(-(subset['Tcost']**2/v)).astype(float)\n",
    "            subset['pop_weight'] = subset['weight'] * subset['population']\n",
    "\n",
    "            # get the sum of weighted population each green space has to serve.\n",
    "            s_w_p = pd.DataFrame(subset.groupby('Park_No').sum('pop_weight')['pop_weight'])\n",
    "\n",
    "            # delete other columns, because they are useless after groupby\n",
    "            s_w_p = s_w_p.rename({'pop_weight':'pop_weight_sum'},axis = 1)\n",
    "            middle = pd.merge(subset,s_w_p, how = 'left', on = 'Park_No' )\n",
    "\n",
    "            # calculate the supply-demand ratio for each green space\n",
    "            middle['green_supply'] = middle['park_area']/middle['pop_weight_sum']\n",
    "\n",
    "            # caculate the accessbility score for each green space that each population grid cell could reach\n",
    "            middle['Sc-access'] = middle['weight'] * middle['green_supply']\n",
    "            # add the scores for each population grid cell\n",
    "            pop_score_df = pd.DataFrame(middle.groupby('Grid_No').sum('Sc-access')['Sc-access'])\n",
    "\n",
    "            # calculate the mean distance of all the green space each population grid cell could reach\n",
    "            mean_dist = middle.groupby('Grid_No').mean('Tcost')['Tcost']\n",
    "            pop_score_df['M-dist'] = mean_dist\n",
    "\n",
    "            # calculate the mean area of all the green space each population grid cell could reach\n",
    "            mean_area = middle.groupby('Grid_No').mean('park_area')['park_area']\n",
    "            pop_score_df['M-area'] = mean_area\n",
    "\n",
    "            # calculate the mean supply_demand ratio of all the green space each population grid cell could reach\n",
    "            mean_supply = middle.groupby('Grid_No').mean('green_supply')['green_supply']\n",
    "            pop_score_df['M-supply'] = mean_supply\n",
    "\n",
    "            pop_score = pop_score_df\n",
    "\n",
    "            pop_score_df = pop_score_df.join(grids[i]['population'], how = 'right')\n",
    "            pop_score_df['Sc-norm'] = pop_score_df['Sc-access'] / pop_score_df['population']\n",
    "\n",
    "            pop_score_df = pop_score_df.loc[:, pop_score_df.columns != 'population']\n",
    "            pop_score_df = pop_score_df.add_suffix(' '+str(thresholds[j]))\n",
    "            E2SFCA_score = E2SFCA_score.join(pop_score_df, how = 'left')\n",
    "\n",
    "            print(thresholds[j], cities[i])\n",
    "\n",
    "        E2SFCA_score = E2SFCA_score.fillna(0)\n",
    "        \n",
    "        if not os.path.exists(save_path+str(grid_size)+'m grids'+'/grid_geoms/'):\n",
    "            os.makedirs(save_path+str(grid_size)+'m grids'+'/grid_geoms/')\n",
    "        \n",
    "        E2SFCA_score.to_file(save_path+str(grid_size)+'m grids'+'/grid_geoms/'+cities[i]+'.gpkg') # Detailed scores\n",
    "        pop_sum = pd.Series(E2SFCA_score['population'].sum()).astype(int)\n",
    "        mean_metrics = E2SFCA_score.loc[:, ~E2SFCA_score.columns.isin(['population','geometry'])].mean()\n",
    "        E2SFCA_sum = pd.concat([pop_sum, mean_metrics])\n",
    "        E2SFCA_summary = pd.concat([E2SFCA_summary, E2SFCA_sum], axis = 1) # summarized results\n",
    "        E2SFCA_cities.append(E2SFCA_score)\n",
    "        \n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        E2SFCA_score.loc[:, E2SFCA_score.columns != 'geometry'].to_csv(save_path+cities[i]+'.csv')\n",
    "    E2SFCA_summary.columns = cities\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    E2SFCA_summary.to_csv(save_path+str(grid_size)+'m grids'+'all_cities'+ext+'.csv')\n",
    "    E2SFCA_summary\n",
    "    return({'score summary':E2SFCA_summary,'score detail':E2SFCA_cities})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f67806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28d55c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05a4e52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add37f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
