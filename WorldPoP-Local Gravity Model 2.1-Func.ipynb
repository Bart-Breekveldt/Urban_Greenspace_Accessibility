{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "675eb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import libpysal\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import time\n",
    "import os\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point, MultiLineString, LineString, Polygon, MultiPolygon\n",
    "from shapely.ops import nearest_points, polygonize\n",
    "import shapely\n",
    "from itertools import product, combinations\n",
    "import math\n",
    "import warnings\n",
    "import socket\n",
    "from wpgpDownload.utils.dl import wpFtp\n",
    "from wpgpDownload.utils.isos import Countries\n",
    "from wpgpDownload.utils.convenience_functions import download_country_covariates as dl\n",
    "from wpgpDownload.utils.wpcsv import Product\n",
    "import georasters as gr\n",
    "from wpgpDownload.utils.convenience_functions import refresh_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50e92f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 0 cities and assumptions\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "cities = ['Tel Aviv']\n",
    "\n",
    "# idea to convert to dask-pandas and dask-geopandas\n",
    "# https://towardsdatascience.com/pandas-with-dask-for-an-ultra-fast-notebook-e2621c3769f\n",
    "# Or with Koalas (Spark-like pandas)\n",
    "\n",
    "# Assumptions\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d841a73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if prefer dwnl from terminal: \n",
      "wpgpDownload download -i ISR --id 5089\n",
      " \n",
      "downloaded:\n",
      "ISR downloaded 0.01 mns\n"
     ]
    }
   ],
   "source": [
    "# 1. Required preprocess for information extraction\n",
    "\n",
    "# Let's ignore depreciation warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the city boundaries\n",
    "bound_df = ox.geocoder.geocode_to_gdf(cities) # gets city boundaries from OSM\n",
    "\n",
    "# Get unique iso-codes of selected cities (only load country raster once)\n",
    "unique_iso = iso_countries(bound_df, # Finding the country of the bounded city\n",
    "                           cities)\n",
    "print(' ')\n",
    "\n",
    "print('downloaded:')\n",
    "# Get raster of countries (if automatic download is preferred (standard))\n",
    "raster = countries_grids(unique_iso,\n",
    "                         r'D:\\Dumps\\WorldPoP_Grids') # custom path, where grid files can be stored without downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e396ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100m resolution grids extraction\n",
      "Tel Aviv 0.04 mns\n",
      " \n",
      "get road networks from OSM\n",
      "Tel Aviv done 0.52 mns\n",
      "dict_keys(['graphs', 'nodes', 'edges', 'edges long'])\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Tel Aviv done\n"
     ]
    }
   ],
   "source": [
    "# 2. Information extraction\n",
    "\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(bound_df, # city boundaries\n",
    "                                     unique_iso,\n",
    "                                     raster, # country raster\n",
    "                                     cities, \n",
    "                                     grid_size = 100)\n",
    "print(' ')\n",
    "\n",
    "# Get road networks\n",
    "road_network = road_networks(cities, # Get 'all' (drive,walk,bike) network\n",
    "                                 thresholds,\n",
    "                                 undirected = True)\n",
    "\n",
    "# Road network returns a dict of keys consisting of graphs, nodes, edges and edges_full\n",
    "print(road_network.keys())\n",
    "\n",
    "print(' ')\n",
    "# Extracting UGS\n",
    "UGS = urban_greenspace(cities, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb027bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get fake UGS entry points\n",
      "Tel Aviv 0.0 % done 0.0  mns\n",
      "Tel Aviv 23.9 % done 0.33  mns\n",
      "Tel Aviv 47.7 % done 0.61  mns\n",
      "Tel Aviv 71.6 % done 0.82  mns\n",
      "Tel Aviv 95.5 % done 1.0  mns\n",
      "Tel Aviv 100 % done 1.17  mns\n",
      " \n",
      "get potential (Euclidean) suitible combinations\n",
      "Tel Aviv\n",
      "chunk 1 / 5 624085 suitible comb.\n",
      "chunk 2 / 5 432906 suitible comb.\n",
      "chunk 3 / 5 667015 suitible comb.\n",
      "chunk 4 / 5 677025 suitible comb.\n",
      "chunk 5 / 5 588523 suitible comb.\n",
      "total combinations within distance 2989554\n",
      "0.0 % gridentry done 0.0  mns\n",
      "8.4 % gridentry done 0.36  mns\n",
      "16.7 % gridentry done 0.73  mns\n",
      "25.1 % gridentry done 1.09  mns\n",
      "33.4 % gridentry done 1.46  mns\n",
      "41.8 % gridentry done 1.82  mns\n",
      "50.2 % gridentry done 2.18  mns\n",
      "58.5 % gridentry done 2.55  mns\n",
      "66.9 % gridentry done 2.92  mns\n",
      "75.3 % gridentry done 3.29  mns\n",
      "83.6 % gridentry done 3.66  mns\n",
      "92.0 % gridentry done 4.02  mns\n",
      "100 % gridentry done 8.03  mns\n",
      " \n",
      "Check grids within UGS\n",
      "0 0.0  mns\n",
      "100 0.24  mns\n",
      "200 0.38  mns\n",
      "300 0.46  mns\n",
      "400 0.52  mns\n"
     ]
    }
   ],
   "source": [
    "# 3. Preprocess information for route finding\n",
    "\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_network['nodes'], \n",
    "                           cities, \n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print(' ')\n",
    "# Checks all potential suitible combinations (points that fall within max threshold Euclidean distance from the ego)\n",
    "suitible = suitible_combinations(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_network['nodes'], # For finding nearest grid entry points\n",
    "                                 thresholds,\n",
    "                                 cities,\n",
    "                                 chunk_size = 10000000) # calculating per chunk of num UGS entry points * num pop_grids\n",
    "                                                        # Preventing normal PC meltdown, set lower if PC gets stuck\n",
    "print(' ')\n",
    "# Checks if grids are already in a UGS\n",
    "suitible_InOut_UGS = grids_in_UGS (suitible, UGS, population_grids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40c30628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comb. by city\n",
      "Tel Aviv 2989554\n",
      " \n",
      "Tel Aviv 1 / 12 range 0 - 250000\n",
      "0.0 % done 0.02 mns\n",
      "0.34 % done 0.53 mns\n",
      "0.69 % done 1.05 mns\n",
      "1.03 % done 1.61 mns\n",
      "1.38 % done 2.2 mns\n",
      "1.72 % done 2.75 mns\n",
      "2.06 % done 3.36 mns\n",
      "2.41 % done 3.81 mns\n",
      "2.75 % done 4.21 mns\n",
      "3.1 % done 4.72 mns\n",
      "3.44 % done 5.17 mns\n",
      "3.79 % done 5.49 mns\n",
      "4.13 % done 5.78 mns\n",
      "4.47 % done 6.02 mns\n",
      "4.82 % done 6.28 mns\n",
      "5.16 % done 6.58 mns\n",
      "5.51 % done 6.91 mns\n",
      "5.85 % done 7.22 mns\n",
      "6.19 % done 7.58 mns\n",
      "6.54 % done 7.93 mns\n",
      "6.88 % done 8.32 mns\n",
      "7.23 % done 8.66 mns\n",
      "7.57 % done 9.01 mns\n",
      "7.91 % done 9.35 mns\n",
      "8.26 % done 9.62 mns\n",
      "39 nearest nodes found\n",
      "8.6 % pathfinding done 9.89 mns\n",
      "formatting done 11.73 mns\n",
      "dissolving done 13.21 mns\n",
      "Tel Aviv 2 / 12 range 250000 - 500000\n",
      "8.6 % done 13.47 mns\n",
      "8.95 % done 13.75 mns\n",
      "9.29 % done 14.05 mns\n",
      "9.64 % done 14.34 mns\n",
      "9.98 % done 14.67 mns\n",
      "10.32 % done 14.99 mns\n",
      "10.67 % done 15.41 mns\n",
      "11.01 % done 15.78 mns\n",
      "11.36 % done 16.17 mns\n",
      "11.7 % done 16.62 mns\n",
      "12.04 % done 17.17 mns\n",
      "12.39 % done 17.64 mns\n",
      "12.73 % done 18.12 mns\n",
      "13.08 % done 18.79 mns\n",
      "13.42 % done 19.35 mns\n",
      "13.76 % done 19.93 mns\n",
      "14.11 % done 20.48 mns\n",
      "14.45 % done 21.11 mns\n",
      "14.8 % done 21.69 mns\n",
      "15.14 % done 22.13 mns\n",
      "15.49 % done 22.57 mns\n",
      "15.83 % done 22.96 mns\n",
      "16.17 % done 23.42 mns\n",
      "16.52 % done 23.97 mns\n",
      "16.86 % done 24.57 mns\n",
      "0 nearest nodes found\n",
      "17.21 % pathfinding done 25.13 mns\n",
      "formatting done 27.12 mns\n",
      "dissolving done 28.66 mns\n",
      "Tel Aviv 3 / 12 range 500000 - 750000\n",
      "17.21 % done 28.92 mns\n",
      "17.55 % done 29.57 mns\n",
      "17.89 % done 30.01 mns\n",
      "18.24 % done 30.56 mns\n",
      "18.58 % done 31.04 mns\n",
      "18.93 % done 31.46 mns\n",
      "19.27 % done 31.83 mns\n",
      "19.61 % done 32.24 mns\n",
      "19.96 % done 32.65 mns\n",
      "20.3 % done 33.1 mns\n",
      "20.65 % done 33.69 mns\n",
      "20.99 % done 34.13 mns\n",
      "21.33 % done 34.6 mns\n",
      "21.68 % done 37.48 mns\n",
      "22.02 % done 38.59 mns\n",
      "22.37 % done 39.89 mns\n",
      "22.71 % done 40.98 mns\n",
      "23.06 % done 42.1 mns\n",
      "23.4 % done 43.05 mns\n",
      "23.74 % done 43.67 mns\n",
      "24.09 % done 44.28 mns\n",
      "24.43 % done 44.9 mns\n",
      "24.78 % done 45.59 mns\n",
      "25.12 % done 45.99 mns\n",
      "25.46 % done 46.47 mns\n",
      "922 nearest nodes found\n",
      "25.81 % pathfinding done 46.84 mns\n",
      "formatting done 49.05 mns\n",
      "dissolving done 50.62 mns\n",
      "Tel Aviv 4 / 12 range 750000 - 1000000\n",
      "25.81 % done 50.89 mns\n",
      "26.15 % done 51.29 mns\n",
      "26.5 % done 51.74 mns\n",
      "26.84 % done 52.26 mns\n",
      "27.18 % done 52.62 mns\n",
      "27.53 % done 52.99 mns\n",
      "27.87 % done 54.71 mns\n",
      "28.22 % done 55.0 mns\n",
      "28.56 % done 55.32 mns\n",
      "28.91 % done 55.61 mns\n",
      "29.25 % done 55.88 mns\n",
      "29.59 % done 56.15 mns\n",
      "29.94 % done 56.46 mns\n",
      "30.28 % done 56.68 mns\n",
      "30.63 % done 56.88 mns\n",
      "30.97 % done 57.1 mns\n",
      "31.31 % done 57.26 mns\n",
      "31.66 % done 57.44 mns\n",
      "32.0 % done 57.61 mns\n",
      "32.35 % done 57.9 mns\n",
      "32.69 % done 58.18 mns\n",
      "33.03 % done 58.47 mns\n",
      "33.38 % done 58.78 mns\n",
      "33.72 % done 59.11 mns\n",
      "34.07 % done 59.4 mns\n",
      "782 nearest nodes found\n",
      "34.41 % pathfinding done 59.73 mns\n",
      "formatting done 61.57 mns\n",
      "dissolving done 63.07 mns\n",
      "Tel Aviv 5 / 12 range 1000000 - 1250000\n",
      "34.41 % done 63.36 mns\n",
      "34.76 % done 63.78 mns\n",
      "35.1 % done 63.99 mns\n",
      "35.44 % done 64.16 mns\n",
      "35.79 % done 64.35 mns\n",
      "36.13 % done 65.42 mns\n",
      "36.48 % done 66.51 mns\n",
      "36.82 % done 67.68 mns\n",
      "37.16 % done 68.73 mns\n",
      "37.51 % done 69.56 mns\n",
      "37.85 % done 70.28 mns\n",
      "38.2 % done 71.05 mns\n",
      "38.54 % done 71.96 mns\n",
      "38.88 % done 72.73 mns\n",
      "39.23 % done 73.5 mns\n",
      "39.57 % done 74.43 mns\n",
      "39.92 % done 74.96 mns\n",
      "40.26 % done 75.64 mns\n",
      "40.61 % done 76.49 mns\n",
      "40.95 % done 77.52 mns\n",
      "41.29 % done 78.57 mns\n",
      "41.64 % done 79.81 mns\n",
      "41.98 % done 80.88 mns\n",
      "42.33 % done 81.56 mns\n",
      "42.67 % done 82.05 mns\n",
      "14 nearest nodes found\n",
      "43.01 % pathfinding done 82.52 mns\n",
      "formatting done 84.95 mns\n",
      "dissolving done 86.61 mns\n",
      "Tel Aviv 6 / 12 range 1250000 - 1500000\n",
      "43.01 % done 86.91 mns\n",
      "43.36 % done 87.37 mns\n",
      "43.7 % done 87.83 mns\n",
      "44.05 % done 88.32 mns\n",
      "44.39 % done 88.8 mns\n",
      "44.73 % done 89.31 mns\n",
      "45.08 % done 89.76 mns\n",
      "45.42 % done 90.18 mns\n",
      "45.77 % done 90.66 mns\n",
      "46.11 % done 91.04 mns\n",
      "46.46 % done 91.42 mns\n",
      "46.8 % done 91.81 mns\n",
      "47.14 % done 92.14 mns\n",
      "47.49 % done 93.27 mns\n",
      "47.83 % done 94.46 mns\n",
      "48.18 % done 95.52 mns\n",
      "48.52 % done 96.82 mns\n",
      "48.86 % done 97.95 mns\n",
      "49.21 % done 98.98 mns\n",
      "49.55 % done 100.04 mns\n",
      "49.9 % done 101.01 mns\n",
      "50.24 % done 101.91 mns\n",
      "50.58 % done 102.83 mns\n",
      "50.93 % done 103.55 mns\n",
      "51.27 % done 104.16 mns\n",
      "0 nearest nodes found\n",
      "51.62 % pathfinding done 104.78 mns\n",
      "formatting done 107.07 mns\n",
      "dissolving done 108.85 mns\n",
      "Tel Aviv 7 / 12 range 1500000 - 1750000\n",
      "51.62 % done 109.23 mns\n",
      "51.96 % done 110.19 mns\n",
      "52.31 % done 111.14 mns\n",
      "52.65 % done 111.98 mns\n",
      "52.99 % done 112.97 mns\n",
      "53.34 % done 113.68 mns\n",
      "53.68 % done 114.44 mns\n",
      "54.03 % done 114.94 mns\n",
      "54.37 % done 115.33 mns\n",
      "54.71 % done 115.78 mns\n",
      "55.06 % done 116.22 mns\n",
      "55.4 % done 116.59 mns\n",
      "55.75 % done 116.98 mns\n",
      "56.09 % done 117.46 mns\n",
      "56.43 % done 117.95 mns\n",
      "56.78 % done 118.45 mns\n",
      "57.12 % done 118.84 mns\n",
      "57.47 % done 119.24 mns\n",
      "57.81 % done 119.55 mns\n",
      "58.15 % done 119.87 mns\n",
      "58.5 % done 120.15 mns\n",
      "58.84 % done 120.43 mns\n",
      "59.19 % done 121.02 mns\n",
      "59.53 % done 121.55 mns\n",
      "59.88 % done 122.33 mns\n",
      "0 nearest nodes found\n",
      "60.22 % pathfinding done 122.84 mns\n",
      "formatting done 125.07 mns\n",
      "dissolving done 126.71 mns\n",
      "Tel Aviv 8 / 12 range 1750000 - 2000000\n",
      "60.22 % done 127.02 mns\n",
      "60.56 % done 127.59 mns\n",
      "60.91 % done 128.1 mns\n",
      "61.25 % done 128.56 mns\n",
      "61.6 % done 129.08 mns\n",
      "61.94 % done 143.59 mns\n",
      "62.28 % done 151.52 mns\n",
      "62.63 % done 151.88 mns\n",
      "62.97 % done 152.47 mns\n",
      "63.32 % done 153.16 mns\n",
      "63.66 % done 153.64 mns\n",
      "64.0 % done 154.04 mns\n",
      "64.35 % done 154.36 mns\n",
      "64.69 % done 154.75 mns\n",
      "65.04 % done 155.06 mns\n",
      "65.38 % done 155.6 mns\n",
      "65.73 % done 156.2 mns\n",
      "66.07 % done 156.66 mns\n",
      "66.41 % done 157.12 mns\n",
      "66.76 % done 157.5 mns\n",
      "67.1 % done 157.86 mns\n",
      "67.45 % done 158.21 mns\n",
      "67.79 % done 158.51 mns\n",
      "68.13 % done 158.92 mns\n",
      "68.48 % done 159.17 mns\n",
      "1938 nearest nodes found\n",
      "68.82 % pathfinding done 159.59 mns\n",
      "formatting done 161.77 mns\n",
      "dissolving done 163.42 mns\n",
      "Tel Aviv 9 / 12 range 2000000 - 2250000\n",
      "68.82 % done 165.49 mns\n",
      "69.17 % done 165.91 mns\n",
      "69.51 % done 166.33 mns\n",
      "69.85 % done 166.71 mns\n",
      "70.2 % done 167.07 mns\n",
      "70.54 % done 167.47 mns\n",
      "70.89 % done 167.79 mns\n",
      "71.23 % done 168.98 mns\n",
      "71.58 % done 169.41 mns\n",
      "71.92 % done 169.89 mns\n",
      "72.26 % done 170.29 mns\n",
      "72.61 % done 170.78 mns\n",
      "72.95 % done 171.25 mns\n",
      "73.3 % done 171.68 mns\n",
      "73.64 % done 172.21 mns\n",
      "73.98 % done 172.61 mns\n",
      "74.33 % done 173.19 mns\n",
      "74.67 % done 173.64 mns\n",
      "75.02 % done 174.23 mns\n",
      "75.36 % done 174.8 mns\n",
      "75.7 % done 175.42 mns\n",
      "76.05 % done 176.03 mns\n",
      "76.39 % done 176.53 mns\n",
      "76.74 % done 177.11 mns\n",
      "77.08 % done 177.74 mns\n",
      "0 nearest nodes found\n",
      "77.43 % pathfinding done 178.3 mns\n",
      "formatting done 180.4 mns\n",
      "dissolving done 182.46 mns\n",
      "Tel Aviv 10 / 12 range 2250000 - 2500000\n",
      "77.43 % done 189.01 mns\n",
      "77.77 % done 190.33 mns\n",
      "78.11 % done 191.03 mns\n",
      "78.46 % done 191.68 mns\n",
      "78.8 % done 192.07 mns\n",
      "79.15 % done 192.44 mns\n",
      "79.49 % done 192.77 mns\n",
      "79.83 % done 193.05 mns\n",
      "80.18 % done 193.79 mns\n",
      "80.52 % done 194.52 mns\n",
      "80.87 % done 195.24 mns\n",
      "81.21 % done 196.03 mns\n",
      "81.55 % done 196.77 mns\n",
      "81.9 % done 197.6 mns\n",
      "82.24 % done 198.38 mns\n",
      "82.59 % done 199.23 mns\n",
      "82.93 % done 200.0 mns\n",
      "83.28 % done 200.97 mns\n",
      "83.62 % done 201.74 mns\n",
      "83.96 % done 202.68 mns\n",
      "84.31 % done 203.51 mns\n",
      "84.65 % done 204.5 mns\n",
      "85.0 % done 205.44 mns\n",
      "85.34 % done 206.52 mns\n",
      "85.68 % done 207.45 mns\n",
      "115 nearest nodes found\n",
      "86.03 % pathfinding done 208.58 mns\n",
      "formatting done 210.96 mns\n",
      "dissolving done 213.24 mns\n",
      "Tel Aviv 11 / 12 range 2500000 - 2750000\n",
      "86.03 % done 227.44 mns\n",
      "86.37 % done 229.86 mns\n",
      "86.72 % done 231.03 mns\n",
      "87.06 % done 232.11 mns\n",
      "87.4 % done 233.42 mns\n",
      "87.75 % done 234.54 mns\n",
      "88.09 % done 235.88 mns\n",
      "88.44 % done 237.0 mns\n",
      "88.78 % done 238.33 mns\n",
      "89.13 % done 239.44 mns\n",
      "89.47 % done 240.72 mns\n",
      "89.81 % done 242.11 mns\n",
      "90.16 % done 243.3 mns\n",
      "90.5 % done 244.88 mns\n",
      "90.85 % done 246.06 mns\n",
      "91.19 % done 247.32 mns\n",
      "91.53 % done 248.58 mns\n",
      "91.88 % done 249.85 mns\n",
      "92.22 % done 251.03 mns\n",
      "92.57 % done 253.21 mns\n",
      "92.91 % done 254.43 mns\n",
      "93.25 % done 255.36 mns\n",
      "93.6 % done 256.19 mns\n",
      "93.94 % done 256.43 mns\n",
      "94.29 % done 256.72 mns\n",
      "447 nearest nodes found\n",
      "94.63 % pathfinding done 257.03 mns\n",
      "formatting done 259.67 mns\n",
      "dissolving done 262.83 mns\n",
      "Tel Aviv 12 / 12 range 2750000 - 2906028\n",
      "94.63 % done 275.5 mns\n",
      "94.97 % done 276.1 mns\n",
      "95.32 % done 276.43 mns\n",
      "95.66 % done 276.91 mns\n",
      "96.01 % done 277.46 mns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.35 % done 278.48 mns\n",
      "96.7 % done 279.16 mns\n",
      "97.04 % done 279.72 mns\n",
      "97.38 % done 280.54 mns\n",
      "97.73 % done 281.66 mns\n",
      "98.07 % done 282.61 mns\n",
      "98.42 % done 283.29 mns\n",
      "98.76 % done 284.2 mns\n",
      "99.1 % done 284.79 mns\n",
      "99.45 % done 285.48 mns\n",
      "99.79 % done 286.44 mns\n",
      "0 nearest nodes found\n",
      "100.0 % pathfinding done 287.17 mns\n",
      "formatting done 288.7 mns\n",
      "dissolving done 290.75 mns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>way-id</th>\n",
       "      <th>realG_osmid</th>\n",
       "      <th>realP_osmid</th>\n",
       "      <th>way_calc</th>\n",
       "      <th>route_cost</th>\n",
       "      <th>steps</th>\n",
       "      <th>Grid_No</th>\n",
       "      <th>grid_osm</th>\n",
       "      <th>Park_No</th>\n",
       "      <th>...</th>\n",
       "      <th>size_infl_sqr3</th>\n",
       "      <th>size_infl_sqr5</th>\n",
       "      <th>raw euclidean</th>\n",
       "      <th>geometry_m</th>\n",
       "      <th>real_G-entry</th>\n",
       "      <th>raw_Tcost</th>\n",
       "      <th>grav2_Tcost</th>\n",
       "      <th>grav3_Tcost</th>\n",
       "      <th>grav5_Tcost</th>\n",
       "      <th>gridpark_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MULTILINESTRING ((34.79194 32.14605, 34.79193 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131352791</td>\n",
       "      <td>374352727</td>\n",
       "      <td>normal way</td>\n",
       "      <td>388.906</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1131352791</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.056944</td>\n",
       "      <td>1.033787</td>\n",
       "      <td>282.866481</td>\n",
       "      <td>POINT (3562252.192 4039425.023)</td>\n",
       "      <td>39.043</td>\n",
       "      <td>427.949</td>\n",
       "      <td>393.834860</td>\n",
       "      <td>404.892851</td>\n",
       "      <td>413.962377</td>\n",
       "      <td>0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MULTILINESTRING ((34.79194 32.14605, 34.79193 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131352791</td>\n",
       "      <td>374352737</td>\n",
       "      <td>normal way</td>\n",
       "      <td>803.404</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1131352791</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.062068</td>\n",
       "      <td>1.036791</td>\n",
       "      <td>719.185280</td>\n",
       "      <td>POINT (3562252.192 4039425.023)</td>\n",
       "      <td>39.043</td>\n",
       "      <td>842.447</td>\n",
       "      <td>769.687421</td>\n",
       "      <td>793.214154</td>\n",
       "      <td>812.552271</td>\n",
       "      <td>0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MULTILINESTRING ((34.79194 32.14605, 34.79193 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131352791</td>\n",
       "      <td>409474257</td>\n",
       "      <td>normal way</td>\n",
       "      <td>422.629</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1131352791</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033576</td>\n",
       "      <td>1.020012</td>\n",
       "      <td>261.310457</td>\n",
       "      <td>POINT (3562252.192 4039425.023)</td>\n",
       "      <td>39.043</td>\n",
       "      <td>461.672</td>\n",
       "      <td>439.359504</td>\n",
       "      <td>446.674537</td>\n",
       "      <td>452.614155</td>\n",
       "      <td>0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MULTILINESTRING ((34.79194 32.14605, 34.79193 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131352791</td>\n",
       "      <td>679320222</td>\n",
       "      <td>normal way</td>\n",
       "      <td>306.172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1131352791</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065582</td>\n",
       "      <td>1.038848</td>\n",
       "      <td>255.680327</td>\n",
       "      <td>POINT (3562252.192 4039425.023)</td>\n",
       "      <td>39.043</td>\n",
       "      <td>345.215</td>\n",
       "      <td>313.840806</td>\n",
       "      <td>323.968531</td>\n",
       "      <td>332.305523</td>\n",
       "      <td>0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MULTILINESTRING ((34.79194 32.14605, 34.79193 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131352791</td>\n",
       "      <td>679320326</td>\n",
       "      <td>normal way</td>\n",
       "      <td>496.723</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1131352791</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.124982</td>\n",
       "      <td>1.073217</td>\n",
       "      <td>463.043444</td>\n",
       "      <td>POINT (3562252.192 4039425.023)</td>\n",
       "      <td>39.043</td>\n",
       "      <td>535.766</td>\n",
       "      <td>449.010674</td>\n",
       "      <td>476.243974</td>\n",
       "      <td>499.215149</td>\n",
       "      <td>0-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989549</th>\n",
       "      <td>POINT (34.80084 32.06959)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>grid in UGS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7050</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585418</td>\n",
       "      <td>0.725236</td>\n",
       "      <td>51.860250</td>\n",
       "      <td>POINT (3566112.851 4030720.601)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7050-142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989550</th>\n",
       "      <td>POINT (34.80084 32.06959)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2681839837</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>grid in UGS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7050</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585418</td>\n",
       "      <td>0.725236</td>\n",
       "      <td>57.013372</td>\n",
       "      <td>POINT (3566112.851 4030720.601)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7050-142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989551</th>\n",
       "      <td>POINT (34.80084 32.06959)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4317375424</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>grid in UGS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7050</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585418</td>\n",
       "      <td>0.725236</td>\n",
       "      <td>69.641450</td>\n",
       "      <td>POINT (3566112.851 4030720.601)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7050-142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989552</th>\n",
       "      <td>POINT (34.80084 32.06959)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4317375432</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>grid in UGS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7050</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585418</td>\n",
       "      <td>0.725236</td>\n",
       "      <td>72.401143</td>\n",
       "      <td>POINT (3566112.851 4030720.601)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7050-142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989553</th>\n",
       "      <td>POINT (34.80084 32.06959)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5852226402</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>grid in UGS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7050</td>\n",
       "      <td>2088696821</td>\n",
       "      <td>142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585418</td>\n",
       "      <td>0.725236</td>\n",
       "      <td>59.780637</td>\n",
       "      <td>POINT (3566112.851 4030720.601)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7050-142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2989554 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  geometry  way-id  \\\n",
       "0        MULTILINESTRING ((34.79194 32.14605, 34.79193 ...     1.0   \n",
       "1        MULTILINESTRING ((34.79194 32.14605, 34.79193 ...     1.0   \n",
       "2        MULTILINESTRING ((34.79194 32.14605, 34.79193 ...     1.0   \n",
       "3        MULTILINESTRING ((34.79194 32.14605, 34.79193 ...     1.0   \n",
       "4        MULTILINESTRING ((34.79194 32.14605, 34.79193 ...     1.0   \n",
       "...                                                    ...     ...   \n",
       "2989549                          POINT (34.80084 32.06959)     0.0   \n",
       "2989550                          POINT (34.80084 32.06959)     0.0   \n",
       "2989551                          POINT (34.80084 32.06959)     0.0   \n",
       "2989552                          POINT (34.80084 32.06959)     0.0   \n",
       "2989553                          POINT (34.80084 32.06959)     0.0   \n",
       "\n",
       "         realG_osmid  realP_osmid     way_calc  route_cost  steps  Grid_No  \\\n",
       "0         1131352791    374352727   normal way     388.906    3.0        0   \n",
       "1         1131352791    374352737   normal way     803.404    5.0        0   \n",
       "2         1131352791    409474257   normal way     422.629    4.0        0   \n",
       "3         1131352791    679320222   normal way     306.172    2.0        0   \n",
       "4         1131352791    679320326   normal way     496.723    5.0        0   \n",
       "...              ...          ...          ...         ...    ...      ...   \n",
       "2989549   2088696821   2088696821  grid in UGS       0.000    0.0     7050   \n",
       "2989550   2681839837   2088696821  grid in UGS       0.000    0.0     7050   \n",
       "2989551   4317375424   2088696821  grid in UGS       0.000    0.0     7050   \n",
       "2989552   4317375432   2088696821  grid in UGS       0.000    0.0     7050   \n",
       "2989553   5852226402   2088696821  grid in UGS       0.000    0.0     7050   \n",
       "\n",
       "           grid_osm  Park_No  ...  size_infl_sqr3  size_infl_sqr5  \\\n",
       "0        1131352791        0  ...        1.056944        1.033787   \n",
       "1        1131352791        0  ...        1.062068        1.036791   \n",
       "2        1131352791        0  ...        1.033576        1.020012   \n",
       "3        1131352791        0  ...        1.065582        1.038848   \n",
       "4        1131352791        0  ...        1.124982        1.073217   \n",
       "...             ...      ...  ...             ...             ...   \n",
       "2989549  2088696821      142  ...        0.585418        0.725236   \n",
       "2989550  2088696821      142  ...        0.585418        0.725236   \n",
       "2989551  2088696821      142  ...        0.585418        0.725236   \n",
       "2989552  2088696821      142  ...        0.585418        0.725236   \n",
       "2989553  2088696821      142  ...        0.585418        0.725236   \n",
       "\n",
       "        raw euclidean                       geometry_m  real_G-entry  \\\n",
       "0          282.866481  POINT (3562252.192 4039425.023)        39.043   \n",
       "1          719.185280  POINT (3562252.192 4039425.023)        39.043   \n",
       "2          261.310457  POINT (3562252.192 4039425.023)        39.043   \n",
       "3          255.680327  POINT (3562252.192 4039425.023)        39.043   \n",
       "4          463.043444  POINT (3562252.192 4039425.023)        39.043   \n",
       "...               ...                              ...           ...   \n",
       "2989549     51.860250  POINT (3566112.851 4030720.601)         0.000   \n",
       "2989550     57.013372  POINT (3566112.851 4030720.601)         0.000   \n",
       "2989551     69.641450  POINT (3566112.851 4030720.601)         0.000   \n",
       "2989552     72.401143  POINT (3566112.851 4030720.601)         0.000   \n",
       "2989553     59.780637  POINT (3566112.851 4030720.601)         0.000   \n",
       "\n",
       "         raw_Tcost  grav2_Tcost  grav3_Tcost grav5_Tcost  gridpark_no  \n",
       "0          427.949   393.834860   404.892851  413.962377          0-0  \n",
       "1          842.447   769.687421   793.214154  812.552271          0-0  \n",
       "2          461.672   439.359504   446.674537  452.614155          0-0  \n",
       "3          345.215   313.840806   323.968531  332.305523          0-0  \n",
       "4          535.766   449.010674   476.243974  499.215149          0-0  \n",
       "...            ...          ...          ...         ...          ...  \n",
       "2989549      0.000     0.000000     0.000000    0.000000     7050-142  \n",
       "2989550      0.000     0.000000     0.000000    0.000000     7050-142  \n",
       "2989551      0.000     0.000000     0.000000    0.000000     7050-142  \n",
       "2989552      0.000     0.000000     0.000000    0.000000     7050-142  \n",
       "2989553      0.000     0.000000     0.000000    0.000000     7050-142  \n",
       "\n",
       "[2989554 rows x 25 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Finding shortest routes.\n",
    "\n",
    "Routes = route_finding (road_network['graphs'], # graphs of the road networks\n",
    "               suitible_InOut_UGS, # potential suitible routes with grid-UGS comb. separated in or out UGS.\n",
    "               road_network['nodes'], \n",
    "               road_network['edges'], \n",
    "               cities, \n",
    "               block_size = 250000, # Chunk to spread dataload.\n",
    "               nn_iter = 10) # max amount of nearest nodes to be found (both for UGS entry and grid-centroid road entries)\n",
    "Routes['route summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08decce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tel Aviv\n",
      "entrance 0.23 mns\n",
      "grid  300\n",
      "grid  600\n",
      "grid  1000\n",
      "gravity**(1/2) 8.15 mns\n",
      "grid  300\n",
      "grid  600\n",
      "grid  1000\n",
      "gravity**(1/3) 12.47 mns\n",
      "grid  300\n",
      "grid  600\n",
      "grid  1000\n",
      "gravity**(1/5) 13.54 mns\n",
      "grid  300\n",
      "grid  600\n",
      "grid  1000\n",
      "Tel Aviv done 14.32 mns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tel Aviv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">entrance_300</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.625677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.189518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.095115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.089690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">entrance_600</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.885575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.053866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.029646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.030914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">entrance_1000</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.956748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.019325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.013046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.010881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gravity**(1/2)_300</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.495599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.274518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.126476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.103408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gravity**(1/2)_600</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.826397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.108689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.042783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.022131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gravity**(1/2)_1000</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.946801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.030704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.018045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.004451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gravity**(1/3)_300</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.507420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.263043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.123483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.106055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gravity**(1/3)_600</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.828746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.099849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.043336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.028070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gravity**(1/3)_1000</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.942701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.030540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.018441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.008318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gravity**(1/5)_300</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.531678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.248663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.115077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.104582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gravity**(1/5)_600</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.845265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.084322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.037809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.032603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">gravity**(1/5)_1000</th>\n",
       "      <th>1 high</th>\n",
       "      <td>0.942782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 medium</th>\n",
       "      <td>0.030062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 low</th>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 no</th>\n",
       "      <td>0.011056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Tel Aviv\n",
       "entrance_300        1 high    0.625677\n",
       "                    2 medium  0.189518\n",
       "                    3 low     0.095115\n",
       "                    4 no      0.089690\n",
       "entrance_600        1 high    0.885575\n",
       "                    2 medium  0.053866\n",
       "                    3 low     0.029646\n",
       "                    4 no      0.030914\n",
       "entrance_1000       1 high    0.956748\n",
       "                    2 medium  0.019325\n",
       "                    3 low     0.013046\n",
       "                    4 no      0.010881\n",
       "gravity**(1/2)_300  1 high    0.495599\n",
       "                    2 medium  0.274518\n",
       "                    3 low     0.126476\n",
       "                    4 no      0.103408\n",
       "gravity**(1/2)_600  1 high    0.826397\n",
       "                    2 medium  0.108689\n",
       "                    3 low     0.042783\n",
       "                    4 no      0.022131\n",
       "gravity**(1/2)_1000 1 high    0.946801\n",
       "                    2 medium  0.030704\n",
       "                    3 low     0.018045\n",
       "                    4 no      0.004451\n",
       "gravity**(1/3)_300  1 high    0.507420\n",
       "                    2 medium  0.263043\n",
       "                    3 low     0.123483\n",
       "                    4 no      0.106055\n",
       "gravity**(1/3)_600  1 high    0.828746\n",
       "                    2 medium  0.099849\n",
       "                    3 low     0.043336\n",
       "                    4 no      0.028070\n",
       "gravity**(1/3)_1000 1 high    0.942701\n",
       "                    2 medium  0.030540\n",
       "                    3 low     0.018441\n",
       "                    4 no      0.008318\n",
       "gravity**(1/5)_300  1 high    0.531678\n",
       "                    2 medium  0.248663\n",
       "                    3 low     0.115077\n",
       "                    4 no      0.104582\n",
       "gravity**(1/5)_600  1 high    0.845265\n",
       "                    2 medium  0.084322\n",
       "                    3 low     0.037809\n",
       "                    4 no      0.032603\n",
       "gravity**(1/5)_1000 1 high    0.942782\n",
       "                    2 medium  0.030062\n",
       "                    3 low     0.016100\n",
       "                    4 no      0.011056"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. summarize scores\n",
    "grid_scores = grid_score_summary (Routes['route summary'], # Shortest routes by the Dijkstra algorithm, with gravity variant distance adj.\n",
    "                                  cities, \n",
    "                                  population_grids, \n",
    "                                  ext = str(cities), # At multiple runs, the extention prevents the summarized file to be overwritten.\n",
    "                                  grid_size = 100) # Size of the grid in meters\n",
    "grid_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "61fb1deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in_out_UGS\n",
       "False    51252\n",
       "True      1655\n",
       "Name: in_out_UGS, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suitible_InOut_UGS[0].groupby('in_out_UGS')['in_out_UGS'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90c64ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round((time.time() - start) / 60,2),'mns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7c8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iso_countries(bounds, cities):\n",
    "    # bound_df = ox.geocoder.geocode_to_gdf(cities)\n",
    "    # The 'Countries' is a list of iso-countries and descriptions from the package wpgpDownload.utils.isos\n",
    "    C = pd.DataFrame(Countries)\n",
    "    start_time = time.time()\n",
    "    iso_countries = []\n",
    "    print('if prefer dwnl from terminal: ')\n",
    "    \n",
    "    # Check the display name in the city boundaries to get the country name (enabling only specifying city in front)\n",
    "    for i in bounds['display_name']:\n",
    "        country = i.rsplit(',')[-1][1:]\n",
    "        iso = C[C['name'] == country].iloc[0,1]\n",
    "        # Get unique ISO countries, so all country-grids are only loaded once\n",
    "        if iso not in iso_countries:\n",
    "            iso_countries.append(iso)\n",
    "            \n",
    "            # List data and extract raster file download string with 2020 population (if download manually is preferred)\n",
    "            products = Product(iso)\n",
    "            Results = products.description_contains('people per grid-cell 2020')\n",
    "            list1 = []\n",
    "            for p in Results:\n",
    "                prints = '%s/%s\\t%s\\t%s' % (p.idx, p.country_name,p.dataset_name,p.path)\n",
    "                list1.append(prints)\n",
    "            print('wpgpDownload download -i',iso,'--id',list1[0].split(\"\\t\")[0].split('/')[0])\n",
    "    \n",
    "    return(iso_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68fbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countries_grids(iso_countries, download_dir = ' '):\n",
    "    start_time = time.time()\n",
    "    blocks = []\n",
    "    for iso in iso_countries:\n",
    "        # Check if raster files already exist on the system path or a manually specified path\n",
    "        path1 = os.getcwd() +'\\\\'+ iso.lower() + '_ppp_2020.tif'\n",
    "        path2 = download_dir +'\\\\'+ iso.lower() + '_ppp_2020.tif'\n",
    "        # First check the manual path\n",
    "        if os.path.exists(path2): \n",
    "            block = gr.from_file(path2)\n",
    "            blocks.append(block)\n",
    "        else:\n",
    "            # Then the system path\n",
    "            if os.path.exists(path1): \n",
    "                block = gr.from_file(path1)\n",
    "                blocks.append(block)\n",
    "            else:\n",
    "                # Otherwise run a suprocess (spr.run) command to download via the terminal in notebook.\n",
    "                runstr = 'wpgpDownload download -i '+ iso+ ' -f people --datasets'\n",
    "                p1 = spr.run('wpgpDownload download -i '+ iso+ ' -f people --datasets', \n",
    "                                    shell = True, \n",
    "                                    capture_output = True)\n",
    "                # decode the output to a list of available datasets from WorldPoP\n",
    "                datasets = p1.stdout.decode().rsplit('\\n')\n",
    "\n",
    "                # The first population raster grid (id-sorted) is the general one, without specifying to demographic groups\n",
    "                for i in enumerate(datasets):\n",
    "                    if '2020' in i[1]:\n",
    "                        ds = datasets[i[0]].rsplit('\\t')[0]\n",
    "                        print(ds)\n",
    "                        # if we found the file, we can stop the loop (we don't need the demograhically specified files)\n",
    "                        break\n",
    "                # Construct the download string\n",
    "                dwnl = 'wpgpDownload download -i '+iso+' --id '+str(ds)\n",
    "                # Get the specified file (terminal)\n",
    "                spr.run(dwnl, shell = True)\n",
    "                # Extract the file\n",
    "                block = gr.from_file(path1)\n",
    "                blocks.append(block)\n",
    "        print(iso,'downloaded', round((time.time() - start_time)/60,2),'mns')\n",
    "    return(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a44b205a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Block 2 population grids extraction\n",
    "def city_grids_format(bounds, iso_countries, country_grids, cities, grid_size = 100):\n",
    "    start_time = time.time()\n",
    "    grids = []\n",
    "    print(str(grid_size) + 'm resolution grids extraction')\n",
    "    for i in range(len(cities)):\n",
    "        C = pd.DataFrame(Countries)\n",
    "        iso = C[bounds['display_name'][i].rsplit(',')[-1][1:] == C['name']].iloc[0,1]\n",
    "        contains = [j for j, x in enumerate(iso_countries) if x == iso][0]\n",
    "\n",
    "        # Clip the city from the country\n",
    "        clipped = country_grids[contains].clip(bounds['geometry'][i])\n",
    "        clipped = clipped[0].to_geopandas()\n",
    "\n",
    "        # Get dissolvement_key for dissolvement. \n",
    "        clipped['row3'] = np.floor(clipped['row']/(grid_size/100)).astype(int)\n",
    "        clipped['col3'] = np.floor(clipped['col']/(grid_size/100)).astype(int)\n",
    "        clipped['dissolve_key'] = clipped['row3'].astype(str) +'-'+ clipped['col3'].astype(str)\n",
    "\n",
    "        # Dissolve into block by block grids\n",
    "        popgrid = clipped[['dissolve_key','geometry','row3','col3']].dissolve('dissolve_key')\n",
    "\n",
    "        # Get those grids populations and area. Only blocks with population and full blocks\n",
    "        popgrid['population'] = round(clipped.groupby('dissolve_key')['value'].sum()).astype(int)\n",
    "        popgrid['area_m'] = round(gpd.GeoSeries(popgrid['geometry'], crs = 4326).to_crs(3043).area).astype(int)\n",
    "        popgrid = popgrid[popgrid['population'] > 0]\n",
    "        popgrid = popgrid[popgrid['area_m'] / popgrid['area_m'].max() > 0.95]\n",
    "\n",
    "        # Get centroids and coords\n",
    "        popgrid['centroid'] = popgrid['geometry'].centroid\n",
    "        popgrid['centroid_m'] = gpd.GeoSeries(popgrid['centroid'], crs = 4326).to_crs(3043)\n",
    "        popgrid['grid_lon'] = popgrid['centroid_m'].x\n",
    "        popgrid['grid_lat'] = popgrid['centroid_m'].y\n",
    "        popgrid = popgrid.reset_index()\n",
    "\n",
    "        minx = popgrid.bounds['minx']\n",
    "        maxx = popgrid.bounds['maxx']\n",
    "        miny = popgrid.bounds['miny']\n",
    "        maxy = popgrid.bounds['maxy']\n",
    "\n",
    "        # Some geometries result in a multipolygon when dissolving (like i.e. 0.05 meters) which is in my mind an coords error\n",
    "        # I therefore create one polygon\n",
    "        Poly = []\n",
    "        for k in range(len(popgrid)):\n",
    "            Poly.append(Polygon([(minx[k],maxy[k]),(maxx[k],maxy[k]),(maxx[k],miny[k]),(minx[k],miny[k])]))\n",
    "        popgrid['geometry'] = Poly\n",
    "\n",
    "        grids.append(popgrid)\n",
    "\n",
    "        print(cities[i].rsplit(',')[0], round((time.time() - start_time)/60,2),'mns')\n",
    "    return(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc1aa68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Block 3 Road networks\n",
    "def road_networks (cities, thresholds, undirected = False):\n",
    "    print('get road networks from OSM')\n",
    "    start_time = time.time()\n",
    "    graphs = list()\n",
    "    road_nodes = list()\n",
    "    road_edges = list()\n",
    "    road_conn = list()\n",
    "\n",
    "    for i in cities:\n",
    "        # Get graph, road nodes and edges\n",
    "        graph = ox.graph_from_place(i, network_type = \"all\", buffer_dist = (np.max(thresholds)+1000))\n",
    "        #graphs.append(graph)\n",
    "\n",
    "        road_node, road_edge = ox.graph_to_gdfs(graph)\n",
    "\n",
    "        # Road nodes format\n",
    "        road_node = road_node.to_crs(4326)\n",
    "        road_node['geometry_m'] = gpd.GeoSeries(road_node['geometry'], crs = 4326).to_crs(3043)\n",
    "        road_node['osmid_var'] = road_node.index\n",
    "        road_node = gpd.GeoDataFrame(road_node, geometry = 'geometry', crs = 4326)\n",
    "\n",
    "        # format road edges\n",
    "        road_edge = road_edge.to_crs(4326)\n",
    "        road_edge['geometry_m'] = gpd.GeoSeries(road_edge['geometry'], crs = 4326).to_crs(3043)\n",
    "        road_edge = road_edge.reset_index()\n",
    "        road_edge.rename(columns={'u':'from', 'v':'to', 'key':'keys'}, inplace=True)\n",
    "        road_edge['key'] = road_edge['from'].astype(str) + '-' + road_edge['to'].astype(str)\n",
    "        \n",
    "        if undirected == True:\n",
    "            # Apply one-directional to both for walking\n",
    "            both = road_edge[road_edge['oneway'] == False]\n",
    "            one = road_edge[road_edge['oneway'] == True]\n",
    "            rev = pd.DataFrame()\n",
    "            rev[['from','to']] = one[['to','from']]\n",
    "            rev = pd.concat([rev,one.iloc[:,2:]],axis = 1)\n",
    "            edge_bidir = pd.concat([both, one, rev])\n",
    "            edge_bidir = edge_bidir.reset_index()\n",
    "            edge_bidir['oneway'] = False\n",
    "        else:\n",
    "            edge_bidir = road_edge\n",
    "\n",
    "        # Exclude highways and ramps on edges    \n",
    "        edge_filter = edge_bidir[(edge_bidir['highway'].str.contains('motorway') | \n",
    "              (edge_bidir['highway'].str.contains('trunk') & \n",
    "               edge_bidir['maxspeed'].astype(str).str.contains(\n",
    "                   '40 mph|45 mph|50 mph|55 mph|60 mph|65|70|75|80|85|90|95|100|110|120|130|140'))) == False]\n",
    "        road_edges.append(edge_filter)\n",
    "\n",
    "        # Exclude isolated nodes\n",
    "        fltrnodes = pd.Series(list(edge_filter['from']) + list(edge_filter['to'])).unique()\n",
    "        newnodes = road_node[road_node['osmid_var'].isin(fltrnodes)]\n",
    "        road_nodes.append(newnodes)\n",
    "\n",
    "        # Get only necessary road connections columns for network performance\n",
    "        road_con = edge_filter[['osmid','key','length','geometry']]\n",
    "        road_con = road_con.set_index('key')\n",
    "\n",
    "        road_conn.append(road_con)\n",
    "\n",
    "        # formatting to graph again.\n",
    "        newnodes = newnodes.loc[:, ~newnodes.columns.isin(['geometry_m', 'osmid_var'])]\n",
    "        edge_filter = edge_filter.set_index(['from','to','keys'])\n",
    "        edge_filter = edge_filter.loc[:, ~edge_filter.columns.isin(['geometry_m', 'key'])]\n",
    "\n",
    "        graph2 = ox.graph_from_gdfs(newnodes, edge_filter)\n",
    "\n",
    "        graphs.append(graph2)\n",
    "        print(i.rsplit(',')[0], 'done', round((time.time() - start_time) / 60,2),'mns')\n",
    "    return({'graphs':graphs,'nodes':road_nodes,'edges':road_conn,'edges long':road_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d3ceef5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Block 4 city greenspace\n",
    "def urban_greenspace (cities, thresholds, one_UGS_buf = 25, min_UGS_size = 400):\n",
    "    print('get urban greenspaces from OSM')\n",
    "    parks_in_range = list()\n",
    "    for i in cities:\n",
    "        gdf = gpd.read_file('D:/Dumps/Greenspace/' + i.rsplit(',')[0] + '/' + i.rsplit(',')[0] + '_Greenspace.gpkg')\n",
    "        gdf = gdf[(gdf.geom_type == 'Polygon') | (gdf.geom_type == 'MultiPolygon')]\n",
    "        greenspace = gdf.reset_index()    \n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        green_buffer = gpd.GeoDataFrame(geometry = greenspace.to_crs(3043).buffer(one_UGS_buf).to_crs(4326))\n",
    "        greenspace['geometry_w_buffer'] = green_buffer\n",
    "        greenspace['geometry_w_buffer'] = gpd.GeoSeries(greenspace['geometry_w_buffer'], crs = 4326)\n",
    "        greenspace['geom buffer diff'] = greenspace['geometry_w_buffer'].difference(greenspace['geometry'])\n",
    "\n",
    "        # This function group components in itself that overlap (with the buffer set of 25 metres)\n",
    "        # https://stackoverflow.com/questions/68036051/geopandas-self-intersection-grouping\n",
    "        W = libpysal.weights.fuzzy_contiguity(greenspace['geometry_w_buffer'])\n",
    "        greenspace['components'] = W.component_labels\n",
    "        parks = greenspace.dissolve('components')\n",
    "\n",
    "        # Exclude parks below 0.04 ha.\n",
    "        parks = parks[parks.to_crs(3043).area > min_UGS_size]\n",
    "        print(i, 'done')\n",
    "        parks = parks.reset_index()\n",
    "        parks['geometry_m'] = parks['geometry'].to_crs(3043)\n",
    "        parks_in_range.append(parks)\n",
    "    return(parks_in_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdc51e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5 park entry points\n",
    "def UGS_fake_entry(UGS, road_nodes, cities, UGS_entry_buf = 25, walk_radius = 500, entry_point_merge = 0):\n",
    "    print('get fake UGS entry points')\n",
    "    start_time = time.time()\n",
    "    ParkRoads = list()\n",
    "    for j in range(len(cities)):\n",
    "        ParkRoad = pd.DataFrame()\n",
    "        mat = list()\n",
    "        # For all\n",
    "        for i in range(len(UGS[j])):\n",
    "            dist = road_nodes[j]['geometry'].to_crs(3043).distance(UGS[j]['geometry'].to_crs(\n",
    "                3043)[i])\n",
    "            buf_nodes = road_nodes[j][(dist < UGS_entry_buf) & (dist > 0)]\n",
    "            mat.append(list(np.repeat(i, len(buf_nodes))))\n",
    "            ParkRoad = pd.concat([ParkRoad, buf_nodes])\n",
    "            if i % 100 == 0: print(cities[j].rsplit(',')[0], round(i/len(UGS[j])*100,1),'% done', \n",
    "                                  round((time.time() - start_time) / 60,2),' mns')\n",
    "        # Park no list conversion\n",
    "        mat_u = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat) for i in b]\n",
    "\n",
    "        # Format\n",
    "        ParkRoad['Park_No'] = mat_u\n",
    "        ParkRoad = ParkRoad.reset_index()\n",
    "        ParkRoad['park_lon'] = ParkRoad['geometry_m'].x\n",
    "        ParkRoad['park_lat'] = ParkRoad['geometry_m'].y\n",
    "        \n",
    "        # Get the road nodes intersecting with the parks' buffer\n",
    "        ParkRoad = pd.merge(ParkRoad, UGS[j][['geometry']], left_on = 'Park_No', right_index = True)\n",
    "\n",
    "        # Get the walkable park size\n",
    "        ParkRoad['park_size_walkable'] = ParkRoad['geometry_m'].buffer(walk_radius).to_crs(4326).intersection(ParkRoad['geometry_y'].to_crs(4326))\n",
    "        ParkRoad['walk_area'] = ParkRoad['park_size_walkable'].to_crs(3043).area\n",
    "        ParkRoad['park_area'] = ParkRoad['geometry_y'].to_crs(3043).area\n",
    "        ParkRoad['share_walked'] = ParkRoad['walk_area'] / ParkRoad['park_area']\n",
    "        \n",
    "        # Get size inflation factors for the gravity model\n",
    "        ParkRoad['size_infl_factor'] = ParkRoad['walk_area'] / ParkRoad['walk_area'].median()\n",
    "        ParkRoad['size_infl_sqr2'] = ParkRoad['size_infl_factor']**(1/2)\n",
    "        ParkRoad['size_infl_sqr3'] = ParkRoad['size_infl_factor']**(1/3)\n",
    "        ParkRoad['size_infl_sqr5'] = ParkRoad['size_infl_factor']**(1/5)\n",
    "                \n",
    "        # Merge fake UGS entry points if within X meters of each other for better system performance\n",
    "        # Standard no merging\n",
    "        ParkRoad = simplify_UGS_entry(ParkRoad, entry_point_merge = 0)\n",
    "                \n",
    "        ParkRoads.append(ParkRoad)\n",
    "\n",
    "        print(cities[j].rsplit(',')[0],'100 % done', \n",
    "                                  round((time.time() - start_time) / 60,2),' mns')\n",
    "        \n",
    "    return(ParkRoads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af76feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5.5 (not in use, buffer is 0, thus retains all the park entry points as is)\n",
    "def simplify_UGS_entry(fake_UGS_entry, entry_point_merge = 0):\n",
    "    # Get buffer of nodes close to each other.\n",
    "    # Get the buffer\n",
    "    ParkComb = fake_UGS_entry\n",
    "    ParkComb['geometry_m_buffer'] = ParkComb['geometry_m'].buffer(entry_point_merge)\n",
    "\n",
    "    # Get and merge components\n",
    "    M = libpysal.weights.fuzzy_contiguity(ParkComb['geometry_m_buffer'])\n",
    "    ParkComb['components'] = M.component_labels\n",
    "\n",
    "    # Take centroid of merged components\n",
    "    centr = gpd.GeoDataFrame(ParkComb, geometry = 'geometry_x', crs = 4326).dissolve('components')['geometry_x'].centroid\n",
    "    centr = gpd.GeoDataFrame(centr)\n",
    "    centr.columns = ['comp_centroid']\n",
    "\n",
    "    # Get node closest to the centroid of all merged nodes, which accesses the road network.\n",
    "    ParkComb = pd.merge(ParkComb, centr, left_on = 'components', right_index = True)\n",
    "    ParkComb['centr_dist'] = ParkComb['geometry_x'].distance(ParkComb['comp_centroid'])\n",
    "    ParkComb = ParkComb.iloc[ParkComb.groupby('components')['centr_dist'].idxmin()]\n",
    "    return(ParkComb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19711d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6 grid-parkentry combinations within euclidean threshold distance\n",
    "def suitible_combinations(UGS_entry, pop_grids, road_nodes, thresholds, cities, chunk_size = 10000000):\n",
    "    print('get potential (Euclidean) suitible combinations')\n",
    "    start_time = time.time()\n",
    "    RoadComb = list()\n",
    "    for l in range(len(cities)):\n",
    "        #blockA = block_combinations\n",
    "        print(cities[l])\n",
    "        len1 = len(pop_grids[l])\n",
    "        len2 = len(UGS_entry[l])\n",
    "\n",
    "        # Reduce the size of combinations per iteration\n",
    "        len4 = 1\n",
    "        len5 = len1 * len2\n",
    "        blockC = len5\n",
    "        while blockC > chunk_size:\n",
    "            blockC = len5 / len4\n",
    "            #print(blockC, len4)\n",
    "            len4 = len4+1\n",
    "\n",
    "        # Amount of grids taken per iteration block\n",
    "        block = round(len1 / len4)\n",
    "\n",
    "        output = pd.DataFrame()\n",
    "        # Checking all the combinations at once is too performance intensive, it is broken down per 1000 (or what you want)\n",
    "        for i in range(len4):\n",
    "            # Check all grid-park combinations per block\n",
    "            l1, l2 = range(i*block,(i+1)*block), range(0,len2)\n",
    "            listed = pd.DataFrame(list(product(l1, l2)))\n",
    "\n",
    "            # Merge grid and park information\n",
    "            grid_merged = pd.merge(listed, \n",
    "                                   pop_grids[l][['grid_lon','grid_lat','centroid','centroid_m']],\n",
    "                                   left_on = 0, right_index = True)\n",
    "            node_merged = pd.merge(grid_merged, \n",
    "                                   UGS_entry[l][['Park_No','osmid','geometry_x','geometry_y','geometry_m','park_lon','park_lat',\n",
    "                                       'size_infl_sqr2','size_infl_sqr3','size_infl_sqr5','share_walked','park_area','walk_area']], \n",
    "                                   left_on = 1, right_index = True)\n",
    "\n",
    "            # Preset index for merging\n",
    "            node_merged['key'] = range(0,len(node_merged))\n",
    "            node_merged = node_merged.set_index('key')\n",
    "            node_merged = node_merged.loc[:, ~node_merged.columns.isin(['index'])]\n",
    "\n",
    "            # Create lists for better computational performance\n",
    "            glon = list(node_merged['grid_lon'])\n",
    "            glat = list(node_merged['grid_lat'])\n",
    "            plon = list(node_merged['park_lon'])\n",
    "            plat = list(node_merged['park_lat'])\n",
    "            infl2 = list(node_merged['size_infl_sqr2'])\n",
    "            infl3 = list(node_merged['size_infl_sqr3'])\n",
    "            infl5 = list(node_merged['size_infl_sqr5'])\n",
    "\n",
    "            # Get the euclidean distances\n",
    "            mat = list()\n",
    "            mat2 = list()\n",
    "            mat3 = list()\n",
    "            mat4 = list()\n",
    "            for j in range(len(node_merged)):\n",
    "                mat.append(math.sqrt(abs(plon[j] - glon[j])**2 + abs(plat[j] - glat[j])**2))\n",
    "                mat2.append(math.sqrt(abs(plon[j] - glon[j])**2 + abs(plat[j] - glat[j])**2) / infl2[j])\n",
    "                mat3.append(math.sqrt(abs(plon[j] - glon[j])**2 + abs(plat[j] - glat[j])**2) / infl3[j])\n",
    "                mat4.append(math.sqrt(abs(plon[j] - glon[j])**2 + abs(plat[j] - glat[j])**2) / infl5[j])\n",
    "\n",
    "            # Check if distances are within 1000m and join remaining info and concat in master df per 1000.\n",
    "            mat_df = pd.DataFrame(mat3)[(np.array(mat) <= np.max(thresholds)) | \n",
    "                                        (np.array(mat2) <= np.max(thresholds)) | \n",
    "                                        (np.array(mat3) <= np.max(thresholds)) | \n",
    "                                        (np.array(mat4) <= np.max(thresholds))]\n",
    "\n",
    "            # join the other gravity euclidean scores and other information\n",
    "            mat_df = mat_df.join(pd.DataFrame(mat), lsuffix='_infl', rsuffix='_entr', how = 'left')\n",
    "            mat_df = mat_df.join(pd.DataFrame(mat2), lsuffix='_entry', rsuffix='_pwr', how = 'left')\n",
    "            mat_df = mat_df.join(pd.DataFrame(mat4), lsuffix='_pwr', rsuffix='_root', how = 'left')\n",
    "            mat_df.columns = ['size_infl_eucl2','raw euclidean','size_infl_eucl3','size_infl_eucl5']    \n",
    "            mat_df = mat_df.join(node_merged)\n",
    "\n",
    "            output = pd.concat([output, mat_df])\n",
    "\n",
    "            print('chunk',(i+1),'/',len4,len(mat_df),'suitible comb.')\n",
    "        # Renaming columns\n",
    "        print('total combinations within distance',len(output))\n",
    "\n",
    "        output.columns = ['size_infl_eucl3','raw euclidean','size_infl_eucl2','size_infl_eucl5',\n",
    "                          'Grid_No','Park_entry_No','grid_lon','grid_lat','Grid_coords_centroid','Grid_m_centroid',\n",
    "                          'Park_No','Parkroad_osmid','Park_geom','Parkroad_coords_centroid','Parkroad_m_centroid',\n",
    "                          'park_lon','park_lat','size_infl_sqr2','size_infl_sqr3','size_infl_sqr5',\n",
    "                          'parkshare_walked','park_area','walk_area_m2']\n",
    "\n",
    "        output = output[['raw euclidean','size_infl_eucl2','size_infl_eucl3','size_infl_eucl5',\n",
    "                         'Grid_No','Park_entry_No','Grid_coords_centroid','Grid_m_centroid',\n",
    "                          'Park_No','Parkroad_osmid','Park_geom','Parkroad_coords_centroid','Parkroad_m_centroid',\n",
    "                         'walk_area_m2','size_infl_sqr2','size_infl_sqr3','size_infl_sqr5']]\n",
    "\n",
    "        # Reinstate geographic elements\n",
    "        output = gpd.GeoDataFrame(output, geometry = 'Grid_coords_centroid', crs = 4326)\n",
    "        output['Grid_m_centroid'] = gpd.GeoSeries(output['Grid_m_centroid'], crs = 3043)\n",
    "        output['Parkroad_coords_centroid'] = gpd.GeoSeries(output['Parkroad_coords_centroid'], crs = 4326)\n",
    "        output['Parkroad_m_centroid'] = gpd.GeoSeries(output['Parkroad_m_centroid'], crs = 3043)\n",
    "\n",
    "        # Get the nearest entrance point for the grid centroids\n",
    "        output = gridroad_entry(output, road_nodes[l])\n",
    "\n",
    "        print('100 % gridentry done', round((time.time() - start_time) / 60,2),' mns')\n",
    "        RoadComb.append(output)\n",
    "    return (RoadComb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9d2c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridroad_entry (suitible_comb, road_nodes):    \n",
    "    start_time = time.time()\n",
    "    mat5 = list()\n",
    "    for i in range(len(suitible_comb)):\n",
    "        try:\n",
    "            nearest = int(road_nodes['geometry'].sindex.nearest(suitible_comb['Grid_coords_centroid'].iloc[i])[1])\n",
    "            mat5.append(road_nodes['osmid_var'].iloc[nearest])\n",
    "        except: \n",
    "            # sometimes two nodes are the exact same distance, then the first in the list is taken.\n",
    "            nearest = int(road_nodes['geometry'].sindex.nearest(suitible_comb['Grid_coords_centroid'].iloc[i])[1][0])\n",
    "            mat5.append(road_nodes['osmid_var'].iloc[nearest])\n",
    "        if i % 250000 == 0: print(round(i/len(suitible_comb)*100,1),'% gridentry done', round((time.time() - start_time) / 60,2),' mns')\n",
    "    # format resulting dataframe\n",
    "    suitible_comb['grid_osm'] = mat5\n",
    "    suitible_comb = pd.merge(suitible_comb, road_nodes['geometry'], left_on = 'grid_osm', right_index = True)\n",
    "    suitible_comb['geometry_m'] = gpd.GeoSeries(suitible_comb['geometry'], crs = 4326).to_crs(3043)\n",
    "    suitible_comb = suitible_comb.reset_index()\n",
    "    return(suitible_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8f10468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check grids in or out of UGS\n",
    "def grids_in_UGS (suitible_comb, UGS, pop_grid): \n",
    "    start_time = time.time()\n",
    "    RoadInOut = list()\n",
    "    for i in range(len(suitible_comb)):\n",
    "        UGS_geoms = UGS[i]['geometry'].to_crs(4326)\n",
    "        grid = pop_grid[i]['centroid']\n",
    "        lst = list()\n",
    "        print('Check grids within UGS')\n",
    "        for l in enumerate(UGS_geoms):\n",
    "            lst.append(grid.intersection(l[1]).is_empty == False)\n",
    "            if l[0] % 100 == 0: print(l[0], round((time.time() - start_time) / 60,2),' mns')\n",
    "\n",
    "        dfGrUGS = pd.DataFrame(pd.DataFrame(np.array(lst)).unstack())\n",
    "        dfGrUGS.columns = ['in_out_UGS']\n",
    "        merged = pd.merge(suitible_comb[i], dfGrUGS, left_on = ['Grid_No','Park_No'], right_index = True, how = 'left')\n",
    "        RoadInOut.append(merged)\n",
    "    return(RoadInOut)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b96b77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Block 7 calculate route networks of all grid-parkentry combinations within euclidean threshold distance\n",
    "def route_finding (graphs, combinations, road_nodes, road_edges, cities, block_size = 250000, nn_iter = 10):\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print('comb. by city')\n",
    "    for n in enumerate(cities): # Know how much comb. need to be calculcated.\n",
    "        print(n[1], len(combinations[n[0]]))\n",
    "    print(' ')\n",
    "    \n",
    "    Routes = list()\n",
    "    Routes_detail = list()\n",
    "    for j in range(len(cities)):\n",
    "        suit_raw = combinations[j]\n",
    "\n",
    "        In_UGS = suit_raw[suit_raw['in_out_UGS'] == True] # Check if a grid centroid is in an UGS\n",
    "        suitible = suit_raw[suit_raw['in_out_UGS'] == False].reset_index(drop = True) # recreate a subsequential index\n",
    "        \n",
    "        len2 = int(np.ceil(len(suitible)/block_size)) # get number of blocks (chunks)\n",
    "        Route_parts = pd.DataFrame()\n",
    "        Route_dparts = pd.DataFrame()\n",
    "\n",
    "        # Divide in chunks of block for computational load\n",
    "        for k in range(len2):    \n",
    "            suitible_chunk = suitible.iloc[k*block_size:k*block_size+block_size] # Get block ids\n",
    "\n",
    "            parknode = list(suitible_chunk['Parkroad_osmid']) # UGS road entry ids\n",
    "            gridnode = list(suitible_chunk['grid_osm']) # grid centroid road entry ids\n",
    "\n",
    "            s_mat = list([]) # osmid from\n",
    "            s_mat1 = list([]) # osmid to\n",
    "            s_mat2 = list([]) # route id\n",
    "            s_mat3 = list([]) # step id\n",
    "            s_mat4 = list([]) # way calculated\n",
    "            s_mat5 = list([]) # way calculated id\n",
    "            mat_nn = [] # sums number of routes containing nearest nodes.\n",
    "            len1 = len(suitible_chunk)\n",
    "\n",
    "            print(cities[j].rsplit(',')[0], k+1,'/',len2, \n",
    "                  'range',k*block_size,'-',k*block_size+np.where(k*block_size+block_size >= len1,len1,block_size))\n",
    "            \n",
    "            for i in range(len(suitible_chunk)):\n",
    "                try:\n",
    "                    shortest = nx.shortest_path(graphs[j], gridnode[i], parknode[i], 'travel_dist', method = 'dijkstra')\n",
    "                    s_mat.append(shortest)\n",
    "                    shortest_to = list(shortest[1:len(shortest)])\n",
    "                    shortest_to.append(-1)\n",
    "                    s_mat1.append(shortest_to)\n",
    "                    s_mat2.append(list(np.repeat(i+block_size*k, len(shortest))))\n",
    "                    s_mat3.append(list(np.arange(0, len(shortest))))\n",
    "                    s_mat4.append('normal way')\n",
    "                    s_mat5.append(1)\n",
    "                except:\n",
    "                    try:\n",
    "                        # Check the reverse\n",
    "                        shortest = nx.shortest_path(graphs[j], parknode[i], gridnode[i], 'travel_dist', method = 'dijkstra')\n",
    "                        s_mat.append(shortest)\n",
    "                        shortest_to = list(shortest[1:len(shortest)])\n",
    "                        shortest_to.append(-1)\n",
    "                        s_mat1.append(shortest_to)\n",
    "                        s_mat2.append(list(np.repeat(i+block_size*k, len(shortest))))\n",
    "                        s_mat3.append(list(np.arange(0, len(shortest))))\n",
    "                        s_mat4.append('reverse way')\n",
    "                        s_mat5.append(0)\n",
    "                    except:\n",
    "                        # Otherwise the nearest node is taken, which is iterated X times at max, check assumptions, block #0 \n",
    "                        nn_route_finding(graphs[j], suitible_chunk, road_nodes[j],\n",
    "                                   s_mat, s_mat1, s_mat2, s_mat3, s_mat4, s_mat5, mat_nn, # matrice info see above\n",
    "                                   it = i, block = k, block_size = block_size, \n",
    "                                         nn_iter = 10) # max nearest nodes to be found\n",
    "                        \n",
    "                if i % 10000 == 0: print(round((i+block_size*k)/len(suitible)*100,2),'% done',\n",
    "                                         round((time.time() - start_time) / 60,2),'mns')\n",
    "            print(len(mat_nn),'nearest nodes found')\n",
    "\n",
    "            print(round((i+block_size*k)/len(suitible)*100,2),'% pathfinding done', round((time.time() - start_time) / 60,2),'mns')\n",
    "            \n",
    "            # Formats route information by route and step (detailed)\n",
    "            routes = route_formatting(s_mat, s_mat1, s_mat2, s_mat3, road_edges[j])\n",
    "            print('formatting done', round((time.time() - start_time) / 60,2), 'mns')\n",
    "            \n",
    "            # Summarizes information by route\n",
    "            routes2 = route_summarization(routes, suitible_chunk, road_nodes[j], s_mat4, s_mat5)\n",
    "            print('dissolving done', round((time.time() - start_time) / 60,2), 'mns')\n",
    "            \n",
    "            # Concats chunk with others already calculated\n",
    "            Route_parts = pd.concat([Route_parts, routes2])\n",
    "            Route_dparts = pd.concat([Route_dparts, routes])\n",
    "            \n",
    "            time.sleep(15)\n",
    "\n",
    "        # Format grids in UGS to enable smooth df concat\n",
    "        In_UGS = In_UGS.set_geometry(In_UGS['Grid_coords_centroid'])\n",
    "        In_UGS = In_UGS[['geometry','Grid_No','grid_osm','Park_No','Park_entry_No','Parkroad_osmid',\n",
    "                                   'Grid_m_centroid','walk_area_m2','size_infl_sqr2','size_infl_sqr3','size_infl_sqr5',\n",
    "                                   'raw euclidean','geometry_m']]\n",
    "\n",
    "        In_UGS['realG_osmid'] = suit_raw['Parkroad_osmid']\n",
    "        In_UGS['realP_osmid'] = suit_raw['grid_osm']\n",
    "        In_UGS['way_calc'] = 'grid in UGS'\n",
    "\n",
    "        Route_parts = pd.concat([Route_parts,In_UGS])\n",
    "        Route_parts = Route_parts.reset_index(drop = True)\n",
    "\n",
    "        Route_parts['gridpark_no'] = Route_parts['Grid_No'].astype(str) +'-'+ Route_parts['Park_No'].astype(str)\n",
    "\n",
    "        # All fill value 0 because no routes are calculated for grid centroids in UGSs\n",
    "        to_fill = ['way-id','route_cost','steps','real_G-entry','raw_Tcost','grav2_Tcost','grav3_Tcost','grav5_Tcost']                                   \n",
    "        Route_parts[to_fill] = Route_parts[to_fill].fillna(0)  \n",
    "\n",
    "        Routes.append(Route_parts)\n",
    "        Routes_detail.append(Route_dparts)\n",
    "    return({'route summary':Routes,'route detail':Routes_detail})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "460e1c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_route_finding (Graph, comb, nodes, \n",
    "                mat_from, mat_to, mat_route, mat_step, mat_way, mat_wbin, mat_nn, \n",
    "                it, block, block_size = 250000, nn_iter = 10):\n",
    "    # Order in route for nearest node:\n",
    "    # 1. gridnode to nearest to the original failed parknode\n",
    "    # 2. The reverse of 1.\n",
    "    # 3. nearest gridnode to the failed one and route to park\n",
    "    # 4. The reverse of 3.\n",
    "    \n",
    "    len3 = 0\n",
    "    alt_route = list([])\n",
    "    \n",
    "    gosm = comb['grid_osm'] # grid osmids (origin)\n",
    "    posm = comb['Parkroad_osmid'] # UGS osmids (destination)\n",
    "    node = nodes['geometry'] # road node geoms\n",
    "    node_osm = nodes['osmid_var'] # road node osmids\n",
    "    \n",
    "    while len3 < nn_iter and len(alt_route) < 1: # continue if no more than 10 nearest nodes or if a route is found\n",
    "        \n",
    "        len3 = len3 +1\n",
    "        # Finds nearest node per iteration.\n",
    "        nn = nn_finding(gosm, posm, node, node_osm, it, len3)\n",
    "        \n",
    "         # routing within graph and current and found nearest nodes of grids and UGS\n",
    "        nn_routing(Graph, nn['curr_park'], nn['near_park'], nn['curr_grid'], nn['near_grid'],\n",
    "                        mat_way, mat_wbin, alt_route, len3)\n",
    "        \n",
    "    if len(alt_route) == 0:\n",
    "        alt = alt_route \n",
    "    else: \n",
    "        alt = alt_route[0]\n",
    "    len4 = len(alt)\n",
    "    if len4 > 0: # If a route is found append\n",
    "        mat_nn.append(it+block_size*block)\n",
    "        mat_from.append(alt)\n",
    "        shortest_to = list(alt[1:len(alt)])\n",
    "        shortest_to.append(-1)\n",
    "        mat_to.append(shortest_to)\n",
    "        mat_route.append(list(np.repeat(it+block_size*block,len4)))\n",
    "        mat_step.append(list(np.arange(0, len4)))\n",
    "    else: # if no route is found fill values.\n",
    "        mat_from.append(-1)\n",
    "        mat_to.append(-1)\n",
    "        mat_route.append(it+block_size*block)\n",
    "        mat_step.append(-1)\n",
    "        mat_way.append('no way')\n",
    "        mat_wbin.append(2)\n",
    "        print(it+block_size*block,'No route between grid and park-entry and their both',nn_iter,'alternatives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7b34fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_finding (grid_osmid, UGS_osmid, node_geom, node_osmid, it, nn_i):\n",
    "    # Grid nearest\n",
    "    g_geom = node_geom[node_osmid == int(grid_osmid[it:it+1])] # Get current grid road entry geometry\n",
    "    g_nearest = pd.DataFrame((abs(float(g_geom.x) - node_geom.x)**2 # Find nearest.\n",
    "                              +abs(float(g_geom.y) - node_geom.y)**2)**(1/2)\n",
    "                            ).join(node_osmid).sort_values(0)\n",
    "\n",
    "    g_grid = g_nearest.iloc[nn_i,1] # Take '1' because 0 will get the current node with distance 0.\n",
    "    g_park = list(UGS_osmid)[it]\n",
    "\n",
    "    p_geom = node_geom[node_osmid == int(UGS_osmid[it:it+1])] # Get current UGS raod entry geometry\n",
    "    p_nearest = pd.DataFrame((abs(float(p_geom.x) - node_geom.x)**2 # Find nearest\n",
    "                              +abs(float(p_geom.y) - node_geom.y)**2)**(1/2)\n",
    "                            ).join(node_osmid).sort_values(0)\n",
    "\n",
    "    p_grid = list(grid_osmid)[it]\n",
    "    p_park = p_nearest.iloc[nn_i,1] # Take '1' because 0 will get the current node with distance 0.\n",
    "    \n",
    "    return({'curr_park':p_grid, 'near_park':p_park, 'curr_grid':g_park, 'near_grid':g_grid}) # return as dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79bfe490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_routing (Graph, curr_park, near_park, curr_grid, near_grid, mat_way, mat_wbin, found_route, nn_i):\n",
    "    try: # First try from current grid to nearest UGS id.\n",
    "        found_route.append(nx.shortest_path(Graph, curr_park, near_park, \n",
    "                                          'travel_dist', method = 'dijkstra'))\n",
    "        mat_way.append(str(nn_i)+'grid > n-park')\n",
    "        mat_wbin.append(1)\n",
    "    except:\n",
    "        try: # Else try the reverse.\n",
    "            found_route.append(nx.shortest_path(Graph, near_park, curr_park, \n",
    "                                              'travel_dist', method = 'dijkstra'))\n",
    "            mat_way.append(str(nn_i)+'n-park > grid')\n",
    "            mat_wbin.append(0)\n",
    "        except:\n",
    "            try: # If no success try from current UGS id to nearest grid id\n",
    "                found_route.append(nx.shortest_path(Graph, near_grid, curr_grid, \n",
    "                                                  'travel_dist', method = 'dijkstra'))\n",
    "                mat_way.append(str(nn_i)+'n-grid > park')\n",
    "                mat_wbin.append(1)\n",
    "            except:\n",
    "                try: # Else try the reverse\n",
    "                    found_route.append(nx.shortest_path(Graph, curr_grid, near_grid, \n",
    "                                                      'travel_dist', method = 'dijkstra'))\n",
    "                    mat_way.append(str(nn_i)+'park > n-grid')\n",
    "                    mat_wbin.append(0)\n",
    "                except: # if no routes are found pass.\n",
    "                    try:\n",
    "                        found_route.append(nx.shortest_path(graph, near_grid, near_UGS, \n",
    "                                                      'travel_dist', method = 'dijkstra'))\n",
    "                        mat_way.append(str(nn_i)+'park > n-grid') # UGS to nearest grid node\n",
    "                        mat_wbin.append(0)\n",
    "                    except:\n",
    "                        try:\n",
    "                            found_route.append(nx.shortest_path(graph, near_UGS, near_grid, \n",
    "                                                      'travel_dist', method = 'dijkstra'))\n",
    "                            mat_way.append(str(nn_i)+'park > n-grid') # UGS to nearest grid node\n",
    "                            mat_wbin.append(1)\n",
    "                        except:\n",
    "                            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4984b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_formatting(mat_from, mat_to, mat_route, mat_step, road_edges):\n",
    "    # Unpack lists\n",
    "    s_mat_u = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat_from) for i in b]\n",
    "    s_mat_u1 = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat_to) for i in b]\n",
    "    s_mat_u2 = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat_route) for i in b]\n",
    "    s_mat_u3 = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat_step) for i in b]\n",
    "\n",
    "    # Format df\n",
    "    routes = pd.DataFrame([s_mat_u,s_mat_u1,s_mat_u2,s_mat_u3]).transpose()\n",
    "    routes.columns = ['from','to','route','step']\n",
    "    mat_key = list([])\n",
    "    for n in range(len(routes)):\n",
    "        mat_key.append(str(int(s_mat_u[n])) + '-' + str(int(s_mat_u1[n])))\n",
    "    routes['key'] = mat_key\n",
    "    routes = routes.set_index('key')\n",
    "\n",
    "    # Add route information\n",
    "    routes = routes.join(road_edges, how = 'left')\n",
    "    routes = gpd.GeoDataFrame(routes, geometry = 'geometry', crs = 4326)\n",
    "    routes = routes.sort_values(by = ['route','step'])\n",
    "    return(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90524c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_summarization(routes, suitible_comb, road_nodes, mat_way, mat_wbin):\n",
    "    # dissolve route\n",
    "    routes2 = routes[['route','geometry']].dissolve('route')\n",
    "\n",
    "    # get used grid- and parkosm. Differs at NN-route.\n",
    "    route_reset = routes.reset_index()\n",
    "    origin = route_reset['from'].iloc[list(route_reset.groupby('route')['step'].idxmin()),]\n",
    "    origin = origin.reset_index().iloc[:,-1]\n",
    "    dest = route_reset['from'].iloc[list(route_reset.groupby('route')['step'].idxmax()),]\n",
    "    dest = dest.reset_index().iloc[:,-1]\n",
    "\n",
    "    # grid > park = 1, park > grid = 0, no way = 2, detailed way in way_calc.\n",
    "    routes2['way-id'] = mat_wbin\n",
    "    routes2['realG_osmid'] = np.where(routes2['way-id'] == 1, origin, dest)\n",
    "    routes2['realP_osmid'] = np.where(routes2['way-id'] == 1, dest, origin)\n",
    "    routes2['way_calc'] = mat_way\n",
    "\n",
    "    # get route cost, steps, additional information.\n",
    "    routes2['route_cost'] = routes.groupby('route')['length'].sum()\n",
    "    routes2['steps'] = routes.groupby('route')['step'].max()\n",
    "    routes2['index'] = suitible_comb.index\n",
    "    routes2 = routes2.set_index(['index'])\n",
    "    routes2.index = routes2.index.astype(int)\n",
    "    routes2 = pd.merge(routes2, suitible_comb[['Grid_No','grid_osm','Park_No','Park_entry_No','Parkroad_osmid',\n",
    "                                          'Grid_m_centroid','walk_area_m2','size_infl_sqr2','size_infl_sqr3',\n",
    "                                          'size_infl_sqr5','raw euclidean']],\n",
    "                                            left_index = True, right_index = True)\n",
    "    routes2 = pd.merge(routes2, road_nodes['geometry_m'], how = 'left', left_on = 'realG_osmid', right_index = True)\n",
    "    # calculate distance of used road-entry for grid-centroid.\n",
    "    routes2['real_G-entry'] = round(gpd.GeoSeries(routes2['Grid_m_centroid'], crs = 3043).distance(routes2['geometry_m']),3)\n",
    "                                    \n",
    "    # Calculcate total route cost for the four gravity variants\n",
    "    routes2['raw_Tcost'] = routes2['route_cost'] + routes2['real_G-entry']\n",
    "    routes2['grav2_Tcost'] = (routes2['route_cost'] + routes2['real_G-entry']) / routes2['size_infl_sqr2']\n",
    "    routes2['grav3_Tcost'] = (routes2['route_cost'] + routes2['real_G-entry']) / routes2['size_infl_sqr3']\n",
    "    routes2['grav5_Tcost'] = (routes2['route_cost'] + routes2['real_G-entry']) / routes2['size_infl_sqr5']\n",
    "    return(routes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ffd4567",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Block 8 determine best parkentry points from each grid, then calculate grid scores\n",
    "# and finally aggregate city access in categories (high, medium, low and no access)\n",
    "def grid_score_summary (routes, cities, pop_grids, ext = '', grid_size = 100):\n",
    "    start_time = time.time()\n",
    "    popg_acc = pd.DataFrame()\n",
    "    grid_scores = list([])\n",
    "    gridpark = list([])\n",
    "    for n in range(len(cities)):    \n",
    "        print(cities[n])\n",
    "\n",
    "        # For the four distance decay variants regarding park size.\n",
    "        l1 = list(['raw','grav2','grav3','grav5'])\n",
    "        m1 = list(['entrance','gravity**(1/2)','gravity**(1/3)','gravity**(1/5)'])\n",
    "        grid_score = list([])\n",
    "        gridparks = list([])\n",
    "        gridpark.append(gridparks)\n",
    "        popgrid_access = pd.DataFrame()\n",
    "        for i in range(len(l1)):\n",
    "            # Get the lowest indices grouped by a key consisting of grid no and park no (best entry point from a grid to a park)\n",
    "            var_best_routes = best_gridpark_comb (routes[n], l1[i], pop_grids[n])\n",
    "\n",
    "            grdsc = pd.DataFrame()\n",
    "            gridsc = pd.DataFrame()\n",
    "            print(m1[i], round((time.time() - start_time) / 60,2), 'mns')\n",
    "\n",
    "            # For each threshold given, calculate a score\n",
    "            for k in range(len(thresholds)):\n",
    "                \n",
    "                t = thresholds[k]\n",
    "                score = 'tr_'+ str(t)\n",
    "                scores = determine_scores(var_best_routes, pop_grids[n], thresholds[k], l1[i], cities[n], grid_size = 100)\n",
    "                \n",
    "                grdsc = pd.concat([grdsc, scores['score_w_route']], axis = 1)\n",
    "                gridsc = pd.concat([gridsc, scores['grid_score']])\n",
    "                                \n",
    "                # Group according to the categories just created and sum the populations living in those grids\n",
    "                popgacc = pd.DataFrame()\n",
    "                popgacc[m1[i]+'_'+str(t)] = scores['score_w_route'].groupby(score+'_access')['population'].sum()\n",
    "                popgrid_access = pd.concat([popgrid_access, popgacc],axis=1)   \n",
    "\n",
    "                print('grid ',t)\n",
    "\n",
    "            grid_score.append(grdsc)\n",
    "\n",
    "            gridsc = gridsc.join(pop_grids[n]['geometry'])\n",
    "            gridsc = gpd.GeoDataFrame(gridsc, geometry = 'geometry', crs = 4326)\n",
    "\n",
    "            if not os.path.exists('D:Dumps/Scores output WP2-OSM/'+str(grid_size)+'m grids local/Grid_geoms/'):\n",
    "                os.makedirs('D:Dumps/Scores output WP2-OSM/'+str(grid_size)+'m grids local/Grid_geoms/')\n",
    "\n",
    "            gridsc.to_file('D:Dumps/Scores output WP2-OSM/'+str(grid_size)+'m grids local/Grid_geoms/gridscore_'+ l1[i] + '_' + cities[n] + '.gpkg')\n",
    "\n",
    "            # Detailed scores to files number of cities * ways to measure = number of files.\n",
    "            # Different threshold-scores are in the same dataframe\n",
    "            gridsc = gridsc.loc[:, gridsc.columns!='geometry']\n",
    "\n",
    "            if not os.path.exists('D:Dumps/Scores output WP2-OSM/'+str(grid_size)+'m grids local/Grid_csv/'):\n",
    "                os.makedirs('D:Dumps/Scores output WP2-OSM/'+str(grid_size)+'m grids local/Grid_csv/')\n",
    "\n",
    "            gridsc.to_csv('D:/Dumps/Scores output WP2-OSM/'+str(grid_size)+'m grids local/Grid_csv/gridscore_'+ l1[i] + '_' + cities[n] + '.csv')\n",
    "            gridparks.append(var_best_routes)\n",
    "\n",
    "        grid_scores.append(grid_score)\n",
    "\n",
    "        # For each city, divide the population access by group by the total to get its share.\n",
    "        popgrid_access = popgrid_access / popgrid_access.sum()\n",
    "        popgrid_access = pd.DataFrame(popgrid_access.unstack())\n",
    "        popg_acc = pd.concat([popg_acc, popgrid_access], axis = 1)\n",
    "\n",
    "        print(cities[n],'done', round((time.time() - start_time) / 60,2), 'mns')\n",
    "    popg_acc.columns = cities\n",
    "    popg_acc.to_csv('D:/Dumps/Scores output WP2-OSM/'+str(grid_size)+'m grids local/popgrid_access'+ext+'.csv')\n",
    "    return(popg_acc)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c00432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_gridpark_comb (routes, var_abbr, pop_grid):\n",
    "    Rclean = routes[routes['way_calc'] != 'no way'].reset_index()\n",
    "    str1 = 'gridpark_' + var_abbr\n",
    "    locals()[str1] = Rclean.iloc[Rclean.groupby('gridpark_no')[(str(var_abbr) +'_Tcost')].idxmin()]  \n",
    "\n",
    "    # Get grid information\n",
    "    locals()[str1] = pd.merge(locals()[str1], pop_grid[['population','geometry']],\n",
    "                            left_on = 'Grid_No', right_index = True, how = 'outer')\n",
    "    locals()[str1] = locals()[str1].reset_index()\n",
    "\n",
    "    # formatting\n",
    "    locals()[str1]['Park_No'] = locals()[str1]['Park_No'].fillna(-1)\n",
    "    locals()[str1]['Park_No'] = locals()[str1]['Park_No'].astype(int)\n",
    "    locals()[str1]['Park_entry_No'] = locals()[str1]['Park_entry_No'].fillna(-1)\n",
    "    locals()[str1]['Park_entry_No'] = locals()[str1]['Park_entry_No'].astype(int)\n",
    "    return(locals()[str1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3f1ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_scores(var_df, pop_grid, thresholds, var_abbr, city, grid_size = 100):\n",
    "    t = thresholds\n",
    "    str2 = str(t)\n",
    "    score = 'tr_'+ str2\n",
    "\n",
    "    #Only get routes within the threshold given (it loops over every threshold) and calculate the scores\n",
    "    thold = var_df[var_df[var_abbr + '_Tcost'] <= t]\n",
    "    thold[score] = t - thold[var_abbr + '_Tcost']\n",
    "    thold['pop' + score] = thold[score] * thold['population']\n",
    "    thold['walk_area_ha' + str2] = var_df['walk_area_m2'] /10000\n",
    "    thold['walkha_person' + str2] = thold['population'] / thold['walk_area_ha' + str2]\n",
    "\n",
    "    # Join the gridpark information from before.\n",
    "    var_df = var_df.join(thold[[score,'pop' + score,'walk_area_ha' + str2, 'walkha_person' + str2]])\n",
    "    # get the grid_scores\n",
    "    gs = pd.DataFrame()\n",
    "    gs[[score,'pop_' + score,'walkha_' + str2]] = var_df.groupby(\n",
    "            'Grid_No')[score,'pop' + score, 'walk_area_ha' + str2].sum()\n",
    "\n",
    "    gs['walkha_person_' + score] = var_df.groupby('Grid_No')['walkha_person' + str2].mean()\n",
    "\n",
    "    trstr = var_df[var_df[score] > 0]\n",
    "    gs[score + '_parks'] = trstr.groupby('Grid_No')['gridpark_no'].count()\n",
    "\n",
    "    # Add the routes as a dissolved line_geom\n",
    "    gs[score + '_routes'] = gpd.GeoDataFrame(trstr[['Grid_No','geometry_x']],\n",
    "                                                  geometry = 'geometry_x', crs = 4326).dissolve('Grid_No')\n",
    "\n",
    "    # Add parks which grids have access to with its closest access point\n",
    "    gs[score+'Park:entry'] = trstr[trstr['Park_No'] >=0].groupby('Grid_No')['Park_No'].apply(list).astype(str\n",
    "    ) + ':' + trstr[trstr['Park_entry_No'] >=0].groupby('Grid_No')['Park_entry_No'].apply(list).astype(str)\n",
    "                \n",
    "    # determine the thresholds category-score. \n",
    "    # High >= threshold (perfect score to one park), medium is above half perfect, \n",
    "    # low is below this and no is no access to a park for a certain grid within the threshold given\n",
    "    gs[score+'_access'] = np.select([gs[score] >= t, (gs[score] < t) & (\n",
    "    gs[score]>= t/2), (gs[score] < t/2) & (gs[score]> 0), gs[score] <= 0],\n",
    "          ['1 high','2 medium','3 low','4 no'])\n",
    "    gs = gs.join(pop_grid['population'], how = 'outer')\n",
    "            \n",
    "    gs = gpd.GeoDataFrame(gs, geometry = score + '_routes', crs = 4326)\n",
    "            \n",
    "    if not os.path.exists('D:Dumps/Scores output WP2-OSM/'+str(grid_size)+'m grids local/Grid_lines/'):\n",
    "        os.makedirs('D:Dumps/Scores output WP2-OSM/'+str(grid_size)+'m grids local/Grid_lines/')\n",
    "                \n",
    "    gs.to_file('D:Dumps/Scores output WP2-OSM/'+str(grid_size)+'m grids local/Grid_lines/gridscore_'+ var_abbr + '_' + str2 + '_' + city + '.gpkg')\n",
    "            \n",
    "    gsc = gs.loc[:,~gs.columns.isin([score + '_routes'])]\n",
    "\n",
    "    return({'grid_score':gsc,'score_w_route':gs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26fd5a77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23fd6369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a9824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7d0f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a73fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
