{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "675eb1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import libpysal\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import time\n",
    "import os\n",
    "from shapely import geometry\n",
    "from shapely.geometry import Point, MultiLineString, LineString, Polygon, MultiPolygon\n",
    "from shapely.ops import nearest_points, polygonize\n",
    "import shapely\n",
    "from itertools import product, combinations\n",
    "import math\n",
    "import warnings\n",
    "import socket\n",
    "from wpgpDownload.utils.dl import wpFtp\n",
    "from wpgpDownload.utils.isos import Countries\n",
    "from wpgpDownload.utils.convenience_functions import download_country_covariates as dl\n",
    "from wpgpDownload.utils.wpcsv import Product\n",
    "import georasters as gr\n",
    "from wpgpDownload.utils.convenience_functions import refresh_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50e92f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 0 cities and assumptions\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "cities = ['Tel Aviv']\n",
    "\n",
    "# idea to convert to dask-pandas and dask-geopandas\n",
    "# https://towardsdatascience.com/pandas-with-dask-for-an-ultra-fast-notebook-e2621c3769f\n",
    "# Or with Koalas (Spark-like pandas)\n",
    "\n",
    "# Assumptions\n",
    "thresholds = [300, 600, 1000] # route threshold in metres. WHO guideline speaks of access within 300m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d841a73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if prefer dwnl from terminal: \n",
      "wpgpDownload download -i ISR --id 5089\n",
      " \n",
      "downloaded:\n",
      "ISR downloaded 0.01 mns\n"
     ]
    }
   ],
   "source": [
    "# 1. Required preprocess for information extraction\n",
    "\n",
    "# Let's ignore depreciation warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Get the city boundaries\n",
    "bound_df = ox.geocoder.geocode_to_gdf(cities) # gets city boundaries from OSM\n",
    "\n",
    "# Get unique iso-codes of selected cities (only load country raster once)\n",
    "unique_iso = iso_countries(bound_df, # Finding the country of the bounded city\n",
    "                           cities)\n",
    "print(' ')\n",
    "\n",
    "print('downloaded:')\n",
    "# Get raster of countries (if automatic download is preferred (standard))\n",
    "raster = countries_grids(unique_iso,\n",
    "                         r'D:\\Dumps\\WorldPoP_Grids') # custom path, where grid files can be stored without downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e396ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100m resolution grids extraction\n",
      "Tel Aviv 0.03 mns\n",
      " \n",
      "get road networks from OSM\n",
      "Tel Aviv done 0.5 mns\n",
      " \n",
      "get urban greenspaces from OSM\n",
      "Tel Aviv done\n"
     ]
    }
   ],
   "source": [
    "# 2. Information extraction\n",
    "\n",
    "# Clip cities from countries, format population grids\n",
    "population_grids = city_grids_format(bound_df, # city boundaries\n",
    "                                     unique_iso,\n",
    "                                     raster, # country raster\n",
    "                                     cities, \n",
    "                                     grid_size = 100)\n",
    "print(' ')\n",
    "\n",
    "# Get road networks\n",
    "road_network = road_networks(cities, # Get 'all' (drive,walk,bike) network\n",
    "                                 thresholds,\n",
    "                                 undirected = True)\n",
    "\n",
    "\n",
    "print(' ')\n",
    "# Extracting UGS\n",
    "UGS = urban_greenspace(cities, \n",
    "                       thresholds,\n",
    "                       one_UGS_buf = 25, # buffer at which UGS is seen as one\n",
    "                       min_UGS_size = 400) # WHO sees this as minimum UGS size (400m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb027bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get fake UGS entry points\n",
      "Tel Aviv 0.0 % done 0.0  mns\n",
      "Tel Aviv 12.7 % done 0.09  mns\n",
      "Tel Aviv 25.3 % done 0.18  mns\n",
      "Tel Aviv 38.0 % done 0.26  mns\n",
      "Tel Aviv 50.6 % done 0.34  mns\n",
      "Tel Aviv 63.3 % done 0.42  mns\n",
      "Tel Aviv 75.9 % done 0.5  mns\n",
      "Tel Aviv 88.6 % done 0.58  mns\n",
      "Tel Aviv 100 % done 0.69  mns\n",
      " \n",
      "get potential (Euclidean) suitible combinations\n",
      "Tel Aviv\n",
      "in chunk 1 / 4 221868 suitible comb.\n",
      "in chunk 2 / 4 258024 suitible comb.\n",
      "in chunk 3 / 4 263214 suitible comb.\n",
      "in chunk 4 / 4 284885 suitible comb.\n",
      "total combinations within distance 1027991\n",
      "0.0 % gridentry done 0.0  mns\n",
      "24.3 % gridentry done 0.37  mns\n",
      "48.6 % gridentry done 0.75  mns\n",
      "73.0 % gridentry done 1.13  mns\n",
      "97.3 % gridentry done 1.5  mns\n",
      "100 % gridentry done 2.67  mns\n",
      " \n",
      "Check grids within UGS\n",
      "0 0.0  mns\n",
      "100 0.07  mns\n",
      "200 0.13  mns\n",
      "300 0.19  mns\n"
     ]
    }
   ],
   "source": [
    "# 3. Preprocess information for route finding\n",
    "\n",
    "# Get fake entry points (between UGS and buffer limits)\n",
    "UGS_entry = UGS_fake_entry(UGS, \n",
    "                           road_network['nodes'], \n",
    "                           cities, \n",
    "                           UGS_entry_buf = 25, # road nodes within 25 meters are seen as fake entry points\n",
    "                           walk_radius = 500, # assume that the average person only views a UGS up to 500m in radius\n",
    "                                                # more attractive\n",
    "                           entry_point_merge = 0) # merges closeby fake UGS entry points within X meters \n",
    "                                                    # what may be done for performance\n",
    "print(' ')\n",
    "# Checks all potential suitible combinations (points that fall within max threshold Euclidean distance from the ego)\n",
    "suitible = suitible_combinations(UGS_entry, \n",
    "                                 population_grids, \n",
    "                                 road_network['nodes'], # For finding nearest grid entry points\n",
    "                                 thresholds,\n",
    "                                 cities,\n",
    "                                 chunk_size = 10000000) # calculating per chunk of num UGS entry points * num pop_grids\n",
    "                                                        # Preventing normal PC meltdown, set lower if PC gets stuck\n",
    "print(' ')\n",
    "# Checks if grids are already in a UGS\n",
    "suitible_InOut_UGS = grids_in_UGS (suitible, UGS, population_grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "608690df",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = list()\n",
    "st.append(suitible_InOut_UGS[0].iloc[180000:220000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40c30628",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tel Aviv 1 / 4 range 0 - 250000\n",
      "0.0 % done 0.01 mns\n",
      "1.01 % done 0.3 mns\n",
      "2.02 % done 0.59 mns\n",
      "3.04 % done 0.8 mns\n",
      "4.05 % done 0.96 mns\n",
      "5.06 % done 1.15 mns\n",
      "6.07 % done 1.3 mns\n",
      "7.09 % done 1.45 mns\n",
      "8.1 % done 1.59 mns\n",
      "9.11 % done 1.73 mns\n",
      "10.12 % done 1.87 mns\n",
      "11.14 % done 2.05 mns\n",
      "12.15 % done 2.28 mns\n",
      "13.16 % done 2.5 mns\n",
      "14.17 % done 2.67 mns\n",
      "15.19 % done 2.86 mns\n",
      "16.2 % done 3.03 mns\n",
      "17.21 % done 3.23 mns\n",
      "18.22 % done 3.42 mns\n",
      "19.24 % done 3.59 mns\n",
      "20.25 % done 3.87 mns\n",
      "21.26 % done 4.38 mns\n",
      "22.27 % done 4.63 mns\n",
      "23.29 % done 4.76 mns\n",
      "24.3 % done 4.9 mns\n",
      "for 228 routes nearest nodes found\n",
      "25.31 % pathfinding done 5.03 mns\n",
      "formatting done 6.58 mns\n",
      "dissolving done 7.96 mns\n",
      "dissolving done 7.96 mns\n",
      "Tel Aviv 2 / 4 range 250000 - 500000\n",
      "25.31 % done 7.96 mns\n",
      "26.32 % done 8.1 mns\n",
      "27.33 % done 8.26 mns\n",
      "28.35 % done 8.42 mns\n",
      "29.36 % done 8.57 mns\n",
      "30.37 % done 8.73 mns\n",
      "31.38 % done 8.89 mns\n",
      "32.4 % done 9.03 mns\n",
      "33.41 % done 9.18 mns\n",
      "34.42 % done 9.33 mns\n",
      "35.43 % done 9.49 mns\n",
      "36.45 % done 9.64 mns\n",
      "37.46 % done 9.8 mns\n",
      "38.47 % done 9.95 mns\n",
      "39.48 % done 10.13 mns\n",
      "40.5 % done 10.3 mns\n",
      "41.51 % done 10.45 mns\n",
      "42.52 % done 10.59 mns\n",
      "43.53 % done 10.74 mns\n",
      "44.55 % done 10.87 mns\n",
      "45.56 % done 11.49 mns\n",
      "46.57 % done 11.69 mns\n",
      "47.58 % done 11.84 mns\n",
      "48.6 % done 12.0 mns\n",
      "49.61 % done 12.16 mns\n",
      "for 173 routes nearest nodes found\n",
      "50.62 % pathfinding done 12.32 mns\n",
      "formatting done 13.84 mns\n",
      "dissolving done 15.21 mns\n",
      "dissolving done 15.21 mns\n",
      "Tel Aviv 3 / 4 range 500000 - 750000\n",
      "50.62 % done 15.22 mns\n",
      "51.63 % done 15.37 mns\n",
      "52.64 % done 15.53 mns\n",
      "53.66 % done 15.67 mns\n",
      "54.67 % done 15.81 mns\n",
      "55.68 % done 15.94 mns\n",
      "56.69 % done 16.07 mns\n",
      "57.71 % done 16.23 mns\n",
      "58.72 % done 21.88 mns\n",
      "59.73 % done 22.04 mns\n",
      "60.74 % done 22.29 mns\n",
      "61.76 % done 22.49 mns\n",
      "62.77 % done 22.63 mns\n",
      "63.78 % done 22.82 mns\n",
      "64.79 % done 23.0 mns\n",
      "65.81 % done 23.22 mns\n",
      "66.82 % done 23.45 mns\n",
      "67.83 % done 23.67 mns\n",
      "68.84 % done 23.84 mns\n",
      "69.86 % done 24.02 mns\n",
      "70.87 % done 24.22 mns\n",
      "71.88 % done 24.41 mns\n",
      "72.89 % done 24.57 mns\n",
      "73.91 % done 24.75 mns\n",
      "74.92 % done 24.96 mns\n",
      "for 513 routes nearest nodes found\n",
      "75.93 % pathfinding done 25.17 mns\n",
      "formatting done 26.7 mns\n",
      "dissolving done 28.09 mns\n",
      "dissolving done 28.09 mns\n",
      "Tel Aviv 4 / 4 range 750000 - 987751\n",
      "75.93 % done 28.09 mns\n",
      "76.94 % done 28.3 mns\n",
      "77.95 % done 28.5 mns\n",
      "78.97 % done 28.69 mns\n",
      "79.98 % done 28.88 mns\n",
      "80.99 % done 29.09 mns\n",
      "82.0 % done 29.35 mns\n",
      "83.02 % done 29.85 mns\n",
      "84.03 % done 30.03 mns\n",
      "85.04 % done 30.18 mns\n",
      "86.05 % done 30.32 mns\n",
      "87.07 % done 30.55 mns\n",
      "88.08 % done 30.73 mns\n",
      "89.09 % done 30.88 mns\n",
      "90.1 % done 31.03 mns\n",
      "91.12 % done 31.21 mns\n",
      "92.13 % done 31.36 mns\n",
      "93.14 % done 31.55 mns\n",
      "94.15 % done 31.75 mns\n",
      "95.17 % done 31.94 mns\n",
      "96.18 % done 32.18 mns\n",
      "97.19 % done 32.38 mns\n",
      "98.2 % done 32.58 mns\n",
      "99.22 % done 32.8 mns\n",
      "for 198 routes nearest nodes found\n",
      "100.0 % pathfinding done 32.99 mns\n",
      "formatting done 34.4 mns\n",
      "dissolving done 35.66 mns\n",
      "dissolving done 35.66 mns\n"
     ]
    }
   ],
   "source": [
    "# 4. Finding shortest routes.\n",
    "Routes = route_finding (road_network['graphs'], # graphs of the road networks\n",
    "               suitible_InOut_UGS, # potential suitible routes with grid-UGS comb. separated in or out UGS.\n",
    "               road_network['nodes'], \n",
    "               road_network['edges'], \n",
    "               cities, \n",
    "               block_size = 250000, # Chunk to spread dataload.\n",
    "               nn_iter = 10) # max amount of nearest nodes to be found (both for UGS entry and grid-centroid road entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a4868fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>way-id</th>\n",
       "      <th>realG_osmid</th>\n",
       "      <th>realP_osmid</th>\n",
       "      <th>way_calc</th>\n",
       "      <th>route_cost</th>\n",
       "      <th>steps</th>\n",
       "      <th>Grid_No</th>\n",
       "      <th>grid_osm</th>\n",
       "      <th>Park_No</th>\n",
       "      <th>Park_entry_No</th>\n",
       "      <th>Parkroad_osmid</th>\n",
       "      <th>Grid_m_centroid</th>\n",
       "      <th>walk_area_m2</th>\n",
       "      <th>Euclidean</th>\n",
       "      <th>geometry_m</th>\n",
       "      <th>real_G-entry</th>\n",
       "      <th>Tcost</th>\n",
       "      <th>gridpark_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MULTILINESTRING ((34.80809 32.04141, 34.80787 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5666571855</td>\n",
       "      <td>563991156</td>\n",
       "      <td>normal way</td>\n",
       "      <td>1015.637</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>5666571855</td>\n",
       "      <td>53</td>\n",
       "      <td>1157</td>\n",
       "      <td>563991156</td>\n",
       "      <td>POINT (3567928.019 4027457.737)</td>\n",
       "      <td>298158.324382</td>\n",
       "      <td>731.171505</td>\n",
       "      <td>POINT (3567932.613 4027643.260)</td>\n",
       "      <td>185.580</td>\n",
       "      <td>1201.217</td>\n",
       "      <td>2130-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MULTILINESTRING ((34.80809 32.04141, 34.80787 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5666571855</td>\n",
       "      <td>563991159</td>\n",
       "      <td>normal way</td>\n",
       "      <td>817.385</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1989</td>\n",
       "      <td>5666571855</td>\n",
       "      <td>53</td>\n",
       "      <td>1158</td>\n",
       "      <td>563991159</td>\n",
       "      <td>POINT (3567946.944 4027681.489)</td>\n",
       "      <td>288786.071310</td>\n",
       "      <td>593.594564</td>\n",
       "      <td>POINT (3567932.613 4027643.260)</td>\n",
       "      <td>40.826</td>\n",
       "      <td>858.211</td>\n",
       "      <td>1989-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MULTILINESTRING ((34.80809 32.04141, 34.80787 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5666571855</td>\n",
       "      <td>563991159</td>\n",
       "      <td>normal way</td>\n",
       "      <td>817.385</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2061</td>\n",
       "      <td>5666571855</td>\n",
       "      <td>53</td>\n",
       "      <td>1158</td>\n",
       "      <td>563991159</td>\n",
       "      <td>POINT (3567895.698 4027555.848)</td>\n",
       "      <td>288786.071310</td>\n",
       "      <td>573.679028</td>\n",
       "      <td>POINT (3567932.613 4027643.260)</td>\n",
       "      <td>94.888</td>\n",
       "      <td>912.273</td>\n",
       "      <td>2061-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MULTILINESTRING ((34.80809 32.04141, 34.80787 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5666571855</td>\n",
       "      <td>563991159</td>\n",
       "      <td>normal way</td>\n",
       "      <td>817.385</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2062</td>\n",
       "      <td>5666571855</td>\n",
       "      <td>53</td>\n",
       "      <td>1158</td>\n",
       "      <td>563991159</td>\n",
       "      <td>POINT (3567979.266 4027583.378)</td>\n",
       "      <td>288786.071310</td>\n",
       "      <td>644.745752</td>\n",
       "      <td>POINT (3567932.613 4027643.260)</td>\n",
       "      <td>75.910</td>\n",
       "      <td>893.295</td>\n",
       "      <td>2062-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MULTILINESTRING ((34.80809 32.04141, 34.80787 ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5666571855</td>\n",
       "      <td>563991159</td>\n",
       "      <td>normal way</td>\n",
       "      <td>817.385</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>5666571855</td>\n",
       "      <td>53</td>\n",
       "      <td>1158</td>\n",
       "      <td>563991159</td>\n",
       "      <td>POINT (3567928.019 4027457.737)</td>\n",
       "      <td>288786.071310</td>\n",
       "      <td>643.264282</td>\n",
       "      <td>POINT (3567932.613 4027643.260)</td>\n",
       "      <td>185.580</td>\n",
       "      <td>1002.965</td>\n",
       "      <td>2130-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>POINT (34.77480 32.04010)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1575610986</td>\n",
       "      <td>1575611068</td>\n",
       "      <td>grid in UGS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2101</td>\n",
       "      <td>1575611068</td>\n",
       "      <td>208</td>\n",
       "      <td>2564</td>\n",
       "      <td>1575610986</td>\n",
       "      <td>POINT (3564585.433 4026357.320)</td>\n",
       "      <td>88595.652375</td>\n",
       "      <td>214.622949</td>\n",
       "      <td>POINT (3564644.477 4026390.264)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2101-208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>POINT (34.77480 32.04010)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1575611010</td>\n",
       "      <td>1575611068</td>\n",
       "      <td>grid in UGS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2101</td>\n",
       "      <td>1575611068</td>\n",
       "      <td>208</td>\n",
       "      <td>2565</td>\n",
       "      <td>1575611010</td>\n",
       "      <td>POINT (3564585.433 4026357.320)</td>\n",
       "      <td>88236.893190</td>\n",
       "      <td>472.888938</td>\n",
       "      <td>POINT (3564644.477 4026390.264)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2101-208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>POINT (34.77480 32.04010)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1575611030</td>\n",
       "      <td>1575611068</td>\n",
       "      <td>grid in UGS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2101</td>\n",
       "      <td>1575611068</td>\n",
       "      <td>208</td>\n",
       "      <td>2566</td>\n",
       "      <td>1575611030</td>\n",
       "      <td>POINT (3564585.433 4026357.320)</td>\n",
       "      <td>88595.652375</td>\n",
       "      <td>315.272612</td>\n",
       "      <td>POINT (3564644.477 4026390.264)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2101-208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>POINT (34.77480 32.04010)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1575611073</td>\n",
       "      <td>1575611068</td>\n",
       "      <td>grid in UGS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2101</td>\n",
       "      <td>1575611068</td>\n",
       "      <td>208</td>\n",
       "      <td>2567</td>\n",
       "      <td>1575611073</td>\n",
       "      <td>POINT (3564585.433 4026357.320)</td>\n",
       "      <td>88182.982440</td>\n",
       "      <td>474.423637</td>\n",
       "      <td>POINT (3564644.477 4026390.264)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2101-208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>POINT (34.77480 32.04010)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2707379285</td>\n",
       "      <td>1575611068</td>\n",
       "      <td>grid in UGS</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2101</td>\n",
       "      <td>1575611068</td>\n",
       "      <td>208</td>\n",
       "      <td>2568</td>\n",
       "      <td>2707379285</td>\n",
       "      <td>POINT (3564585.433 4026357.320)</td>\n",
       "      <td>88595.652375</td>\n",
       "      <td>316.007196</td>\n",
       "      <td>POINT (3564644.477 4026390.264)</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2101-208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               geometry  way-id  realG_osmid  \\\n",
       "0     MULTILINESTRING ((34.80809 32.04141, 34.80787 ...     1.0   5666571855   \n",
       "1     MULTILINESTRING ((34.80809 32.04141, 34.80787 ...     1.0   5666571855   \n",
       "2     MULTILINESTRING ((34.80809 32.04141, 34.80787 ...     1.0   5666571855   \n",
       "3     MULTILINESTRING ((34.80809 32.04141, 34.80787 ...     1.0   5666571855   \n",
       "4     MULTILINESTRING ((34.80809 32.04141, 34.80787 ...     1.0   5666571855   \n",
       "...                                                 ...     ...          ...   \n",
       "9995                          POINT (34.77480 32.04010)     0.0   1575610986   \n",
       "9996                          POINT (34.77480 32.04010)     0.0   1575611010   \n",
       "9997                          POINT (34.77480 32.04010)     0.0   1575611030   \n",
       "9998                          POINT (34.77480 32.04010)     0.0   1575611073   \n",
       "9999                          POINT (34.77480 32.04010)     0.0   2707379285   \n",
       "\n",
       "      realP_osmid     way_calc  route_cost  steps  Grid_No    grid_osm  \\\n",
       "0       563991156   normal way    1015.637    9.0     2130  5666571855   \n",
       "1       563991159   normal way     817.385    7.0     1989  5666571855   \n",
       "2       563991159   normal way     817.385    7.0     2061  5666571855   \n",
       "3       563991159   normal way     817.385    7.0     2062  5666571855   \n",
       "4       563991159   normal way     817.385    7.0     2130  5666571855   \n",
       "...           ...          ...         ...    ...      ...         ...   \n",
       "9995   1575611068  grid in UGS       0.000    0.0     2101  1575611068   \n",
       "9996   1575611068  grid in UGS       0.000    0.0     2101  1575611068   \n",
       "9997   1575611068  grid in UGS       0.000    0.0     2101  1575611068   \n",
       "9998   1575611068  grid in UGS       0.000    0.0     2101  1575611068   \n",
       "9999   1575611068  grid in UGS       0.000    0.0     2101  1575611068   \n",
       "\n",
       "      Park_No  Park_entry_No  Parkroad_osmid                  Grid_m_centroid  \\\n",
       "0          53           1157       563991156  POINT (3567928.019 4027457.737)   \n",
       "1          53           1158       563991159  POINT (3567946.944 4027681.489)   \n",
       "2          53           1158       563991159  POINT (3567895.698 4027555.848)   \n",
       "3          53           1158       563991159  POINT (3567979.266 4027583.378)   \n",
       "4          53           1158       563991159  POINT (3567928.019 4027457.737)   \n",
       "...       ...            ...             ...                              ...   \n",
       "9995      208           2564      1575610986  POINT (3564585.433 4026357.320)   \n",
       "9996      208           2565      1575611010  POINT (3564585.433 4026357.320)   \n",
       "9997      208           2566      1575611030  POINT (3564585.433 4026357.320)   \n",
       "9998      208           2567      1575611073  POINT (3564585.433 4026357.320)   \n",
       "9999      208           2568      2707379285  POINT (3564585.433 4026357.320)   \n",
       "\n",
       "       walk_area_m2   Euclidean                       geometry_m  \\\n",
       "0     298158.324382  731.171505  POINT (3567932.613 4027643.260)   \n",
       "1     288786.071310  593.594564  POINT (3567932.613 4027643.260)   \n",
       "2     288786.071310  573.679028  POINT (3567932.613 4027643.260)   \n",
       "3     288786.071310  644.745752  POINT (3567932.613 4027643.260)   \n",
       "4     288786.071310  643.264282  POINT (3567932.613 4027643.260)   \n",
       "...             ...         ...                              ...   \n",
       "9995   88595.652375  214.622949  POINT (3564644.477 4026390.264)   \n",
       "9996   88236.893190  472.888938  POINT (3564644.477 4026390.264)   \n",
       "9997   88595.652375  315.272612  POINT (3564644.477 4026390.264)   \n",
       "9998   88182.982440  474.423637  POINT (3564644.477 4026390.264)   \n",
       "9999   88595.652375  316.007196  POINT (3564644.477 4026390.264)   \n",
       "\n",
       "      real_G-entry     Tcost gridpark_no  \n",
       "0          185.580  1201.217     2130-53  \n",
       "1           40.826   858.211     1989-53  \n",
       "2           94.888   912.273     2061-53  \n",
       "3           75.910   893.295     2062-53  \n",
       "4          185.580  1002.965     2130-53  \n",
       "...            ...       ...         ...  \n",
       "9995         0.000     0.000    2101-208  \n",
       "9996         0.000     0.000    2101-208  \n",
       "9997         0.000     0.000    2101-208  \n",
       "9998         0.000     0.000    2101-208  \n",
       "9999         0.000     0.000    2101-208  \n",
       "\n",
       "[10000 rows x 19 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Routes['route summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08decce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 Tel Aviv\n",
      "600 Tel Aviv\n",
      "1000 Tel Aviv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tel Aviv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>395,909.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 300</th>\n",
       "      <td>23.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 300</th>\n",
       "      <td>115.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 300</th>\n",
       "      <td>224,950.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 300</th>\n",
       "      <td>15.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 300</th>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 600</th>\n",
       "      <td>23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 600</th>\n",
       "      <td>288.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 600</th>\n",
       "      <td>194,484.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 600</th>\n",
       "      <td>9.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 600</th>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-access 1000</th>\n",
       "      <td>23.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-dist 1000</th>\n",
       "      <td>511.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-area 1000</th>\n",
       "      <td>142,535.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M-supply 1000</th>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sc-norm 1000</th>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Tel Aviv\n",
       "population               395,909.00\n",
       "Sc-access 300                 23.02\n",
       "M-dist 300                   115.62\n",
       "M-area 300               224,950.32\n",
       "M-supply 300                  15.59\n",
       "Sc-norm 300                    0.56\n",
       "Sc-access 600                 23.51\n",
       "M-dist 600                   288.68\n",
       "M-area 600               194,484.13\n",
       "M-supply 600                   9.34\n",
       "Sc-norm 600                    0.53\n",
       "Sc-access 1000                23.36\n",
       "M-dist 1000                  511.32\n",
       "M-area 1000              142,535.83\n",
       "M-supply 1000                  5.26\n",
       "Sc-norm 1000                   0.51"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. summarize scores\n",
    "min_gridUGS = min_gridUGS_comb (Routes, population_grids, UGS)\n",
    "\n",
    "E2SCFA_score = E2SCFA_scores(min_gridUGS, population_grids, thresholds, cities)\n",
    "\n",
    "E2SCFA_score['score summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7c8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iso_countries(bounds, cities):\n",
    "    # bound_df = ox.geocoder.geocode_to_gdf(cities)\n",
    "    # The 'Countries' is a list of iso-countries and descriptions from the package wpgpDownload.utils.isos\n",
    "    C = pd.DataFrame(Countries)\n",
    "    start_time = time.time()\n",
    "    iso_countries = []\n",
    "    print('if prefer dwnl from terminal: ')\n",
    "    \n",
    "    # Check the display name in the city boundaries to get the country name (enabling only specifying city in front)\n",
    "    for i in bounds['display_name']:\n",
    "        country = i.rsplit(',')[-1][1:]\n",
    "        iso = C[C['name'] == country].iloc[0,1]\n",
    "        # Get unique ISO countries, so all country-grids are only loaded once\n",
    "        if iso not in iso_countries:\n",
    "            iso_countries.append(iso)\n",
    "            \n",
    "            # List data and extract raster file download string with 2020 population (if download manually is preferred)\n",
    "            products = Product(iso)\n",
    "            Results = products.description_contains('people per grid-cell 2020')\n",
    "            list1 = []\n",
    "            for p in Results:\n",
    "                prints = '%s/%s\\t%s\\t%s' % (p.idx, p.country_name,p.dataset_name,p.path)\n",
    "                list1.append(prints)\n",
    "            print('wpgpDownload download -i',iso,'--id',list1[0].split(\"\\t\")[0].split('/')[0])\n",
    "    \n",
    "    return(iso_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68fbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countries_grids(iso_countries, download_dir = ' '):\n",
    "    start_time = time.time()\n",
    "    blocks = []\n",
    "    for iso in iso_countries:\n",
    "        # Check if raster files already exist on the system path or a manually specified path\n",
    "        path1 = os.getcwd() +'\\\\'+ iso.lower() + '_ppp_2020.tif'\n",
    "        path2 = download_dir +'\\\\'+ iso.lower() + '_ppp_2020.tif'\n",
    "        # First check the manual path\n",
    "        if os.path.exists(path2): \n",
    "            block = gr.from_file(path2)\n",
    "            blocks.append(block)\n",
    "        else:\n",
    "            # Then the system path\n",
    "            if os.path.exists(path1): \n",
    "                block = gr.from_file(path1)\n",
    "                blocks.append(block)\n",
    "            else:\n",
    "                # Otherwise run a suprocess (spr.run) command to download via the terminal in notebook.\n",
    "                runstr = 'wpgpDownload download -i '+ iso+ ' -f people --datasets'\n",
    "                p1 = spr.run('wpgpDownload download -i '+ iso+ ' -f people --datasets', \n",
    "                                    shell = True, \n",
    "                                    capture_output = True)\n",
    "                # decode the output to a list of available datasets from WorldPoP\n",
    "                datasets = p1.stdout.decode().rsplit('\\n')\n",
    "\n",
    "                # The first population raster grid (id-sorted) is the general one, without specifying to demographic groups\n",
    "                for i in enumerate(datasets):\n",
    "                    if '2020' in i[1]:\n",
    "                        ds = datasets[i[0]].rsplit('\\t')[0]\n",
    "                        print(ds)\n",
    "                        # if we found the file, we can stop the loop (we don't need the demograhically specified files)\n",
    "                        break\n",
    "                # Construct the download string\n",
    "                dwnl = 'wpgpDownload download -i '+iso+' --id '+str(ds)\n",
    "                # Get the specified file (terminal)\n",
    "                spr.run(dwnl, shell = True)\n",
    "                # Extract the file\n",
    "                block = gr.from_file(path1)\n",
    "                blocks.append(block)\n",
    "        print(iso,'downloaded', round((time.time() - start_time)/60,2),'mns')\n",
    "    return(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44b205a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Block 2 population grids extraction\n",
    "def city_grids_format(bounds, iso_countries, country_grids, cities, grid_size = 100):\n",
    "    start_time = time.time()\n",
    "    grids = []\n",
    "    print(str(grid_size) + 'm resolution grids extraction')\n",
    "    for i in range(len(cities)):\n",
    "        C = pd.DataFrame(Countries)\n",
    "        iso = C[bounds['display_name'][i].rsplit(',')[-1][1:] == C['name']].iloc[0,1]\n",
    "        contains = [j for j, x in enumerate(iso_countries) if x == iso][0]\n",
    "\n",
    "        # Clip the city from the country\n",
    "        clipped = country_grids[contains].clip(bounds['geometry'][i])\n",
    "        clipped = clipped[0].to_geopandas()\n",
    "\n",
    "        # Get dissolvement_key for dissolvement. \n",
    "        clipped['row3'] = np.floor(clipped['row']/(grid_size/100)).astype(int)\n",
    "        clipped['col3'] = np.floor(clipped['col']/(grid_size/100)).astype(int)\n",
    "        clipped['dissolve_key'] = clipped['row3'].astype(str) +'-'+ clipped['col3'].astype(str)\n",
    "\n",
    "        # Dissolve into block by block grids\n",
    "        popgrid = clipped[['dissolve_key','geometry','row3','col3']].dissolve('dissolve_key')\n",
    "\n",
    "        # Get those grids populations and area. Only blocks with population and full blocks\n",
    "        popgrid['population'] = round(clipped.groupby('dissolve_key')['value'].sum()).astype(int)\n",
    "        popgrid['area_m'] = round(gpd.GeoSeries(popgrid['geometry'], crs = 4326).to_crs(3043).area).astype(int)\n",
    "        popgrid = popgrid[popgrid['population'] > 0]\n",
    "        popgrid = popgrid[popgrid['area_m'] / popgrid['area_m'].max() > 0.95]\n",
    "\n",
    "        # Get centroids and coords\n",
    "        popgrid['centroid'] = popgrid['geometry'].centroid\n",
    "        popgrid['centroid_m'] = gpd.GeoSeries(popgrid['centroid'], crs = 4326).to_crs(3043)\n",
    "        popgrid['grid_lon'] = popgrid['centroid_m'].x\n",
    "        popgrid['grid_lat'] = popgrid['centroid_m'].y\n",
    "        popgrid = popgrid.reset_index()\n",
    "\n",
    "        minx = popgrid.bounds['minx']\n",
    "        maxx = popgrid.bounds['maxx']\n",
    "        miny = popgrid.bounds['miny']\n",
    "        maxy = popgrid.bounds['maxy']\n",
    "\n",
    "        # Some geometries result in a multipolygon when dissolving (like i.e. 0.05 meters) which is in my mind an coords error\n",
    "        # I therefore create one polygon\n",
    "        Poly = []\n",
    "        for k in range(len(popgrid)):\n",
    "            Poly.append(Polygon([(minx[k],maxy[k]),(maxx[k],maxy[k]),(maxx[k],miny[k]),(minx[k],miny[k])]))\n",
    "        popgrid['geometry'] = Poly\n",
    "\n",
    "        grids.append(popgrid)\n",
    "\n",
    "        print(cities[i].rsplit(',')[0], round((time.time() - start_time)/60,2),'mns')\n",
    "    return(grids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc1aa68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Block 3 Road networks\n",
    "def road_networks (cities, thresholds, undirected = False):\n",
    "    print('get road networks from OSM')\n",
    "    start_time = time.time()\n",
    "    graphs = list()\n",
    "    road_nodes = list()\n",
    "    road_edges = list()\n",
    "    road_conn = list()\n",
    "\n",
    "    for i in cities:\n",
    "        # Get graph, road nodes and edges\n",
    "        graph = ox.graph_from_place(i, network_type = \"all\", buffer_dist = (np.max(thresholds)+1000))\n",
    "        #graphs.append(graph)\n",
    "\n",
    "        road_node, road_edge = ox.graph_to_gdfs(graph)\n",
    "\n",
    "        # Road nodes format\n",
    "        road_node = road_node.to_crs(4326)\n",
    "        road_node['geometry_m'] = gpd.GeoSeries(road_node['geometry'], crs = 4326).to_crs(3043)\n",
    "        road_node['osmid_var'] = road_node.index\n",
    "        road_node = gpd.GeoDataFrame(road_node, geometry = 'geometry', crs = 4326)\n",
    "\n",
    "        # format road edges\n",
    "        road_edge = road_edge.to_crs(4326)\n",
    "        road_edge['geometry_m'] = gpd.GeoSeries(road_edge['geometry'], crs = 4326).to_crs(3043)\n",
    "        road_edge = road_edge.reset_index()\n",
    "        road_edge.rename(columns={'u':'from', 'v':'to', 'key':'keys'}, inplace=True)\n",
    "        road_edge['key'] = road_edge['from'].astype(str) + '-' + road_edge['to'].astype(str)\n",
    "        \n",
    "        if undirected == True:\n",
    "            # Apply one-directional to both for walking\n",
    "            both = road_edge[road_edge['oneway'] == False]\n",
    "            one = road_edge[road_edge['oneway'] == True]\n",
    "            rev = pd.DataFrame()\n",
    "            rev[['from','to']] = one[['to','from']]\n",
    "            rev = pd.concat([rev,one.iloc[:,2:]],axis = 1)\n",
    "            edge_bidir = pd.concat([both, one, rev])\n",
    "            edge_bidir = edge_bidir.reset_index()\n",
    "            edge_bidir['oneway'] = False\n",
    "        else:\n",
    "            edge_bidir = road_edge\n",
    "\n",
    "        # Exclude highways and ramps on edges    \n",
    "        edge_filter = edge_bidir[(edge_bidir['highway'].str.contains('motorway') | \n",
    "              (edge_bidir['highway'].str.contains('trunk') & \n",
    "               edge_bidir['maxspeed'].astype(str).str.contains(\n",
    "                   '40 mph|45 mph|50 mph|55 mph|60 mph|65|70|75|80|85|90|95|100|110|120|130|140'))) == False]\n",
    "        road_edges.append(edge_filter)\n",
    "\n",
    "        # Exclude isolated nodes\n",
    "        fltrnodes = pd.Series(list(edge_filter['from']) + list(edge_filter['to'])).unique()\n",
    "        newnodes = road_node[road_node['osmid_var'].isin(fltrnodes)]\n",
    "        road_nodes.append(newnodes)\n",
    "\n",
    "        # Get only necessary road connections columns for network performance\n",
    "        road_con = edge_filter[['osmid','key','length','geometry']]\n",
    "        road_con = road_con.set_index('key')\n",
    "\n",
    "        road_conn.append(road_con)\n",
    "\n",
    "        # formatting to graph again.\n",
    "        newnodes = newnodes.loc[:, ~newnodes.columns.isin(['geometry_m', 'osmid_var'])]\n",
    "        edge_filter = edge_filter.set_index(['from','to','keys'])\n",
    "        edge_filter = edge_filter.loc[:, ~edge_filter.columns.isin(['geometry_m', 'key'])]\n",
    "\n",
    "        graph2 = ox.graph_from_gdfs(newnodes, edge_filter)\n",
    "\n",
    "        graphs.append(graph2)\n",
    "        print(i.rsplit(',')[0], 'done', round((time.time() - start_time) / 60,2),'mns')\n",
    "    return({'graphs':graphs,'nodes':road_nodes,'edges':road_conn,'edges long':road_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d3ceef5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Block 4 city greenspace\n",
    "def urban_greenspace (cities, thresholds, one_UGS_buf = 25, min_UGS_size = 400):\n",
    "    print('get urban greenspaces from OSM')\n",
    "    parks_in_range = list()\n",
    "    for i in cities:\n",
    "        gdf = ox.geometries_from_place(i, tags={'leisure':'park'}, buffer_dist = np.max(thresholds))\n",
    "        gdf = gdf[(gdf.geom_type == 'Polygon') | (gdf.geom_type == 'MultiPolygon')]\n",
    "        greenspace = gdf.reset_index()    \n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        green_buffer = gpd.GeoDataFrame(geometry = greenspace.to_crs(3043).buffer(one_UGS_buf).to_crs(4326))\n",
    "        greenspace['geometry_w_buffer'] = green_buffer\n",
    "        greenspace['geometry_w_buffer'] = gpd.GeoSeries(greenspace['geometry_w_buffer'], crs = 4326)\n",
    "        greenspace['geom buffer diff'] = greenspace['geometry_w_buffer'].difference(greenspace['geometry'])\n",
    "\n",
    "        # This function group components in itself that overlap (with the buffer set of 25 metres)\n",
    "        # https://stackoverflow.com/questions/68036051/geopandas-self-intersection-grouping\n",
    "        W = libpysal.weights.fuzzy_contiguity(greenspace['geometry_w_buffer'])\n",
    "        greenspace['components'] = W.component_labels\n",
    "        parks = greenspace.dissolve('components')\n",
    "\n",
    "        # Exclude parks below 0.04 ha.\n",
    "        parks = parks[parks.to_crs(3043).area > min_UGS_size]\n",
    "        print(i, 'done')\n",
    "        parks = parks.reset_index()\n",
    "        parks['geometry_m'] = parks['geometry'].to_crs(3043)\n",
    "        parks['park_area'] = parks['geometry_m'].area\n",
    "        parks_in_range.append(parks)\n",
    "    return(parks_in_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdc51e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5 park entry points\n",
    "def UGS_fake_entry(UGS, road_nodes, cities, UGS_entry_buf = 25, walk_radius = 500, entry_point_merge = 0):\n",
    "    print('get fake UGS entry points')\n",
    "    start_time = time.time()\n",
    "    ParkRoads = list()\n",
    "    for j in range(len(cities)):\n",
    "        ParkRoad = pd.DataFrame()\n",
    "        mat = list()\n",
    "        # For all\n",
    "        for i in range(len(UGS[j])):\n",
    "            dist = road_nodes[j]['geometry'].to_crs(3043).distance(UGS[j]['geometry'].to_crs(\n",
    "                3043)[i])\n",
    "            buf_nodes = road_nodes[j][(dist < UGS_entry_buf) & (dist > 0)]\n",
    "            mat.append(list(np.repeat(i, len(buf_nodes))))\n",
    "            ParkRoad = pd.concat([ParkRoad, buf_nodes])\n",
    "            if i % 50 == 0: print(cities[j].rsplit(',')[0], round(i/len(UGS[j])*100,1),'% done', \n",
    "                                  round((time.time() - start_time) / 60,2),' mns')\n",
    "        # Park no list conversion\n",
    "        mat_u = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat) for i in b]\n",
    "\n",
    "        # Format\n",
    "        ParkRoad['Park_No'] = mat_u\n",
    "        ParkRoad = ParkRoad.reset_index()\n",
    "        ParkRoad['park_lon'] = ParkRoad['geometry_m'].x\n",
    "        ParkRoad['park_lat'] = ParkRoad['geometry_m'].y\n",
    "        \n",
    "        # Get the road nodes intersecting with the parks' buffer\n",
    "        ParkRoad = pd.merge(ParkRoad, UGS[j][['geometry','park_area']], left_on = 'Park_No', right_index = True)\n",
    "\n",
    "        # Get the walkable park size\n",
    "        ParkRoad['park_size_walkable'] = ParkRoad['geometry_m'].buffer(walk_radius).to_crs(4326).intersection(ParkRoad['geometry_y'])\n",
    "        ParkRoad['walk_area'] = ParkRoad['park_size_walkable'].to_crs(3043).area\n",
    "        #ParkRoad['park_area'] = ParkRoad['geometry_y'].to_crs(3043).area\n",
    "        ParkRoad['share_walked'] = ParkRoad['walk_area'] / ParkRoad['park_area']\n",
    "                \n",
    "        # Merge fake UGS entry points if within X meters of each other for better system performance\n",
    "        # Standard no merging\n",
    "        ParkRoad = simplify_UGS_entry(ParkRoad, entry_point_merge = 0)\n",
    "                \n",
    "        ParkRoads.append(ParkRoad)\n",
    "\n",
    "        print(cities[j].rsplit(',')[0],'100 % done', \n",
    "                                  round((time.time() - start_time) / 60,2),' mns')\n",
    "    return(ParkRoads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af76feed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 5.5 (not in use, buffer is 0, thus retains all the park entry points as is)\n",
    "def simplify_UGS_entry(fake_UGS_entry, entry_point_merge = 0):\n",
    "    # Get buffer of nodes close to each other.\n",
    "    # Get the buffer\n",
    "    ParkComb = fake_UGS_entry\n",
    "    ParkComb['geometry_m_buffer'] = ParkComb['geometry_m'].buffer(entry_point_merge)\n",
    "\n",
    "    # Get and merge components\n",
    "    M = libpysal.weights.fuzzy_contiguity(ParkComb['geometry_m_buffer'])\n",
    "    ParkComb['components'] = M.component_labels\n",
    "\n",
    "    # Take centroid of merged components\n",
    "    centr = gpd.GeoDataFrame(ParkComb, geometry = 'geometry_x', crs = 4326).dissolve('components')['geometry_x'].centroid\n",
    "    centr = gpd.GeoDataFrame(centr)\n",
    "    centr.columns = ['comp_centroid']\n",
    "\n",
    "    # Get node closest to the centroid of all merged nodes, which accesses the road network.\n",
    "    ParkComb = pd.merge(ParkComb, centr, left_on = 'components', right_index = True)\n",
    "    ParkComb['centr_dist'] = ParkComb['geometry_x'].distance(ParkComb['comp_centroid'])\n",
    "    ParkComb = ParkComb.iloc[ParkComb.groupby('components')['centr_dist'].idxmin()]\n",
    "    return(ParkComb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19711d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 6 grid-parkentry combinations within euclidean threshold distance\n",
    "def suitible_combinations(UGS_entry, pop_grids, road_nodes, thresholds, cities, chunk_size = 10000000):\n",
    "    print('get potential (Euclidean) suitible combinations')\n",
    "    start_time = time.time()\n",
    "    RoadComb = list()\n",
    "    for l in range(len(cities)):\n",
    "        #blockA = block_combinations\n",
    "        print(cities[l])\n",
    "        len1 = len(pop_grids[l])\n",
    "        len2 = len(UGS_entry[l])\n",
    "\n",
    "        # Reduce the size of combinations per iteration\n",
    "        len4 = 1\n",
    "        len5 = len1 * len2\n",
    "        blockC = len5\n",
    "        while blockC > chunk_size:\n",
    "            blockC = len5 / len4\n",
    "            #print(blockC, len4)\n",
    "            len4 = len4+1\n",
    "\n",
    "        # Amount of grids taken per iteration block\n",
    "        block = round(len1 / len4)\n",
    "\n",
    "        output = pd.DataFrame()\n",
    "        # Checking all the combinations at once is too performance intensive, it is broken down per 1000 (or what you want)\n",
    "        for i in range(len4):\n",
    "            # Check all grid-park combinations per block\n",
    "            l1, l2 = range(i*block,(i+1)*block), range(0,len2)\n",
    "            listed = pd.DataFrame(list(product(l1, l2)))\n",
    "\n",
    "            # Merge grid and park information\n",
    "            grid_merged = pd.merge(listed, \n",
    "                                   pop_grids[l][['grid_lon','grid_lat','centroid','centroid_m']],\n",
    "                                   left_on = 0, right_index = True)\n",
    "            node_merged = pd.merge(grid_merged, \n",
    "                                   UGS_entry[l][['Park_No','osmid','geometry_x','geometry_y','geometry_m','park_lon','park_lat',\n",
    "                                       'share_walked','park_area','walk_area']], \n",
    "                                   left_on = 1, right_index = True)\n",
    "\n",
    "            # Preset index for merging\n",
    "            node_merged['key'] = range(0,len(node_merged))\n",
    "            node_merged = node_merged.set_index('key')\n",
    "            node_merged = node_merged.loc[:, ~node_merged.columns.isin(['index'])]\n",
    "\n",
    "            # Create lists for better computational performance\n",
    "            glon = list(node_merged['grid_lon'])\n",
    "            glat = list(node_merged['grid_lat'])\n",
    "            plon = list(node_merged['park_lon'])\n",
    "            plat = list(node_merged['park_lat'])\n",
    "\n",
    "            # Get the euclidean distances\n",
    "            mat = list()\n",
    "            for j in range(len(node_merged)):\n",
    "                mat.append(math.sqrt(abs(plon[j] - glon[j])**2 + abs(plat[j] - glat[j])**2))\n",
    "\n",
    "            # Check if distances are within 1000m and join remaining info and concat in master df per 1000.\n",
    "            mat_df = pd.DataFrame(mat)[(np.array(mat) <= np.max(thresholds))]\n",
    "\n",
    "            # join the other gravity euclidean scores and other information\n",
    "            mat_df.columns = ['Euclidean']    \n",
    "            mat_df = mat_df.join(node_merged)\n",
    "\n",
    "            output = pd.concat([output, mat_df])\n",
    "\n",
    "            print('in chunk',(i+1),'/',len4,len(mat_df),'suitible comb.')\n",
    "        # Renaming columns\n",
    "        print('total combinations within distance',len(output))\n",
    "\n",
    "        output.columns = ['Euclidean','Grid_No','Park_entry_No','grid_lon','grid_lat','Grid_coords_centroid','Grid_m_centroid',\n",
    "                      'Park_No','Parkroad_osmid','Park_geom','Parkroad_coords_centroid','Parkroad_m_centroid','park_lon',\n",
    "                      'park_lat','parkshare_walked','park_area','walk_area_m2']\n",
    "\n",
    "        output = output[['Euclidean','Grid_No','Park_entry_No','Grid_coords_centroid','Grid_m_centroid','walk_area_m2',\n",
    "                     'Park_No','Parkroad_osmid','Park_geom','Parkroad_coords_centroid','Parkroad_m_centroid','park_area']]\n",
    "\n",
    "        # Reinstate geographic elements\n",
    "        output = gpd.GeoDataFrame(output, geometry = 'Grid_coords_centroid', crs = 4326)\n",
    "        output['Grid_m_centroid'] = gpd.GeoSeries(output['Grid_m_centroid'], crs = 3043)\n",
    "        output['Parkroad_coords_centroid'] = gpd.GeoSeries(output['Parkroad_coords_centroid'], crs = 4326)\n",
    "        output['Parkroad_m_centroid'] = gpd.GeoSeries(output['Parkroad_m_centroid'], crs = 3043)\n",
    "\n",
    "        # Get the nearest entrance point for the grid centroids\n",
    "        output = gridroad_entry(output, road_nodes[l])\n",
    "\n",
    "        print('100 % gridentry done', round((time.time() - start_time) / 60,2),' mns')\n",
    "        RoadComb.append(output)\n",
    "    return (RoadComb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d2c955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridroad_entry (suitible_comb, road_nodes):    \n",
    "    start_time = time.time()\n",
    "    mat5 = list()\n",
    "    for i in range(len(suitible_comb)):\n",
    "        try:\n",
    "            nearest = int(road_nodes['geometry'].sindex.nearest(suitible_comb['Grid_coords_centroid'].iloc[i])[1])\n",
    "            mat5.append(road_nodes['osmid_var'].iloc[nearest])\n",
    "        except: \n",
    "            # sometimes two nodes are the exact same distance, then the first in the list is taken.\n",
    "            nearest = int(road_nodes['geometry'].sindex.nearest(suitible_comb['Grid_coords_centroid'].iloc[i])[1][0])\n",
    "            mat5.append(road_nodes['osmid_var'].iloc[nearest])\n",
    "        if i % 250000 == 0: print(round(i/len(suitible_comb)*100,1),'% gridentry done', round((time.time() - start_time) / 60,2),' mns')\n",
    "    # format resulting dataframe\n",
    "    suitible_comb['grid_osm'] = mat5\n",
    "    suitible_comb = pd.merge(suitible_comb, road_nodes['geometry'], left_on = 'grid_osm', right_index = True)\n",
    "    suitible_comb['geometry_m'] = gpd.GeoSeries(suitible_comb['geometry'], crs = 4326).to_crs(3043)\n",
    "    suitible_comb = suitible_comb.reset_index()\n",
    "    return(suitible_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8f10468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check grids in or out of UGS\n",
    "def grids_in_UGS (suitible_comb, UGS, pop_grid): \n",
    "    start_time = time.time()\n",
    "    RoadInOut = list()\n",
    "    for i in range(len(suitible_comb)):\n",
    "        UGS_geoms = UGS[i]['geometry']\n",
    "        grid = pop_grid[i]['centroid']\n",
    "        lst = list()\n",
    "        print('Check grids within UGS')\n",
    "        for l in enumerate(UGS_geoms):\n",
    "            lst.append(grid.intersection(l[1]).is_empty == False)\n",
    "            if l[0] % 100 == 0: print(l[0], round((time.time() - start_time) / 60,2),' mns')\n",
    "\n",
    "        dfGrUGS = pd.DataFrame(pd.DataFrame(np.array(lst)).unstack())\n",
    "        dfGrUGS.columns = ['in_out_UGS']\n",
    "        merged = pd.merge(suitible_comb[i], dfGrUGS, left_on = ['Grid_No','Park_No'], right_index = True, how = 'left')\n",
    "        RoadInOut.append(merged)\n",
    "    return(RoadInOut)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28bf4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKS\n",
    "\n",
    "# Block 7 calculate route networks of all grid-parkentry combinations within euclidean threshold distance\n",
    "def route_finding (graphs, combinations, road_nodes, road_edges, cities, block_size = 250000, nn_iter = 10):\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    Routes = list()\n",
    "    for j in range(len(cities)):\n",
    "        Graph = graphs[j]\n",
    "        suit_raw = combinations[j] # iloc to test the iteration speed.\n",
    "        nodes = road_nodes[j]\n",
    "\n",
    "        In_UGS = suit_raw[suit_raw['in_out_UGS'] == True] # Check if a grid centroid is in an UGS\n",
    "        suitible = suit_raw[suit_raw['in_out_UGS'] == False].reset_index(drop = True) # recreate a subsequential index\n",
    "\n",
    "        block = block_size\n",
    "\n",
    "        Route_parts = pd.DataFrame()\n",
    "        len2 = int(np.ceil(len(suitible)/block))\n",
    "        # Divide in chunks of block for computational load\n",
    "        for k in range(len2):    \n",
    "            suitible_chunk = suitible.iloc[k*block:k*block+block]\n",
    "\n",
    "            parknode = list(suitible_chunk['Parkroad_osmid'])\n",
    "            gridnode = list(suitible_chunk['grid_osm'])\n",
    "\n",
    "            s_mat = list([])\n",
    "            s_mat1 = list([])\n",
    "            s_mat2 = list([])\n",
    "            s_mat3 = list([])\n",
    "            s_mat4 = list([])\n",
    "            s_mat5 = list([])\n",
    "            mat_nn = []\n",
    "            len1 = len(suitible_chunk)\n",
    "\n",
    "            print(cities[j].rsplit(',')[0], k+1,'/',len2,'range',k*block,'-',k*block+np.where(k*block+block >= len1,len1,block))\n",
    "            for i in range(len(suitible_chunk)):\n",
    "                try:\n",
    "                    shortest = nx.shortest_path(Graph, gridnode[i], parknode[i], 'travel_dist', method = 'dijkstra')\n",
    "                    s_mat.append(shortest)\n",
    "                    shortest_to = list(shortest[1:len(shortest)])\n",
    "                    shortest_to.append(-1)\n",
    "                    s_mat1.append(shortest_to)\n",
    "                    s_mat2.append(list(np.repeat(i+block*k, len(shortest))))\n",
    "                    s_mat3.append(list(np.arange(0, len(shortest))))\n",
    "                    s_mat4.append('normal way')\n",
    "                    s_mat5.append(1)\n",
    "                except:\n",
    "                    try:\n",
    "                        # Check the reverse\n",
    "                        shortest = nx.shortest_path(Graph, parknode[i], gridnode[i], 'travel_dist', method = 'dijkstra')\n",
    "                        s_mat.append(shortest)\n",
    "                        shortest_to = list(shortest[1:len(shortest)])\n",
    "                        shortest_to.append(-1)\n",
    "                        s_mat1.append(shortest_to)\n",
    "                        s_mat2.append(list(np.repeat(i+block*k, len(shortest))))\n",
    "                        s_mat3.append(list(np.arange(0, len(shortest))))\n",
    "                        s_mat4.append('reverse way')\n",
    "                        s_mat5.append(0)\n",
    "                    except:\n",
    "                        # Otherwise the nearest node is taken, which is iterated X times at max, check assumptions, block #0 \n",
    "                        # Order in route for nearest node:\n",
    "                        # 1. gridnode to nearest to the original failed parknode\n",
    "                        # 2. The reverse of 1.\n",
    "                        # 3. nearest gridnode to the failed one and route to park\n",
    "                        # 4. The reverse of 3.\n",
    "\n",
    "                        len3 = 0\n",
    "                        alt_route = list([])\n",
    "                        while len3 < nn_iter and len(alt_route) < 1:\n",
    "\n",
    "                            len3 = len3 +1\n",
    "                            #def (suitible_chunk, nodes, nn_i): \n",
    "                            # Grid nearest\n",
    "                            g_geom = nodes[nodes['osmid_var'] == int(suitible_chunk.iloc[i:i+1]['grid_osm'])]['geometry']\n",
    "                            g_nearest = pd.DataFrame((abs(float(g_geom.x) - nodes['geometry'].x)**2\n",
    "                            +abs(float(g_geom.y) - nodes['geometry'].y)**2)**(1/2)\n",
    "                                                    ).join(nodes['osmid_var']).sort_values(0)\n",
    "\n",
    "                            g_grid = g_nearest.iloc[len3,1]\n",
    "                            g_park = suitible_chunk.iloc[i]['Parkroad_osmid']\n",
    "\n",
    "                            p_geom = nodes[nodes['osmid_var'] == int(suitible_chunk.iloc[i:i+1]['Parkroad_osmid'])]['geometry']\n",
    "                            p_nearest = pd.DataFrame((abs(float(p_geom.x) - nodes['geometry'].x)**2\n",
    "                            +abs(float(p_geom.y) - nodes['geometry'].y)**2)**(1/2)\n",
    "                                                    ).join(nodes['osmid_var']).sort_values(0)\n",
    "\n",
    "                            p_grid = suitible_chunk.iloc[i]['grid_osm']\n",
    "                            p_park = p_nearest.iloc[len3,1]\n",
    "\n",
    "                            try:\n",
    "                                alt_route.append(nx.shortest_path(Graph, p_grid, p_park, \n",
    "                                                                  'travel_dist', method = 'dijkstra'))\n",
    "                                s_mat4.append(str(len3)+'grid > n-park')\n",
    "                                s_mat5.append(1)\n",
    "                            except:\n",
    "                                try:\n",
    "                                    alt_route.append(nx.shortest_path(Graph, p_park, p_grid, \n",
    "                                                                      'travel_dist', method = 'dijkstra'))\n",
    "                                    s_mat4.append(str(len3)+'n-park > grid')\n",
    "                                    s_mat5.append(0)\n",
    "                                except:\n",
    "                                    try:\n",
    "                                        alt_route.append(nx.shortest_path(Graph, g_grid, g_park, \n",
    "                                                                          'travel_dist', method = 'dijkstra'))\n",
    "                                        s_mat4.append(str(len3)+'n-grid > park')\n",
    "                                        s_mat5.append(1)\n",
    "                                    except:\n",
    "                                        try:\n",
    "                                            alt_route.append(nx.shortest_path(Graph, g_grid, g_park, \n",
    "                                                                              'travel_dist', method = 'dijkstra'))\n",
    "                                            s_mat4.append(str(len3)+'park > n-grid')\n",
    "                                            s_mat5.append(0)\n",
    "                                        except:\n",
    "                                            if len3 == nn_iter:\n",
    "                                                #print(i+block*k,i+block*k,\n",
    "                                                #      'No route between grid and park-entry and their both 10 alternatives')\n",
    "                                                pass\n",
    "                                            pass\n",
    "                        #print(len(alt_route))\n",
    "                        if len(alt_route) == 0: \n",
    "                            alt = alt_route \n",
    "                        else: \n",
    "                            alt = alt_route[0]\n",
    "                        len4 = len(alt)\n",
    "                        #print(len4)\n",
    "                        #mat_nn = []\n",
    "                        if len4 > 0:\n",
    "                            #print('for index',i+block*k,'nearest node found between', \n",
    "                            #                       alt[0],'and',alt[-1])\n",
    "                            mat_nn.append(i+block*k)\n",
    "                            s_mat.append(alt)\n",
    "                            shortest_to = list(alt[1:len(alt)])\n",
    "                            shortest_to.append(-1)\n",
    "                            s_mat1.append(shortest_to)\n",
    "                            s_mat2.append(list(np.repeat(i+block*k,len4)))\n",
    "                            s_mat3.append(list(np.arange(0, len4)))\n",
    "                        else:\n",
    "                            s_mat.append(-1)\n",
    "                            s_mat1.append(-1)\n",
    "                            s_mat2.append(i+block*k)\n",
    "                            s_mat3.append(-1)\n",
    "                            s_mat4.append('no way')\n",
    "                            s_mat5.append(2)\n",
    "                            print(i+block*k,'No route',nn_iter)\n",
    "\n",
    "                if i % 10000 == 0: print(round((i+block*k)/len(suitible)*100,2),'% done',\n",
    "                                         round((time.time() - start_time) / 60,2),'mns')\n",
    "            print('for', len(mat_nn),'routes nearest nodes found')\n",
    "\n",
    "            print(round((i+block*k)/len(suitible)*100,2),'% pathfinding done', round((time.time() - start_time) / 60,2),'mns')\n",
    "\n",
    "            # Formats route information by route and step (detailed)\n",
    "            routes = route_formatting(s_mat, s_mat1, s_mat2, s_mat3, road_edges[j])\n",
    "            print('formatting done', round((time.time() - start_time) / 60,2), 'mns')\n",
    "            \n",
    "            # Summarizes information by route\n",
    "            routes2 = route_summarization(routes, suitible_chunk, road_nodes[j], s_mat4, s_mat5)\n",
    "            print('dissolving done', round((time.time() - start_time) / 60,2), 'mns')\n",
    "            \n",
    "            print('dissolving done', round((time.time() - start_time) / 60,2), 'mns')\n",
    "            Route_parts = pd.concat([Route_parts, routes2])\n",
    "\n",
    "        # Format grids in UGS to enable smooth df concat\n",
    "        In_UGS = In_UGS.set_geometry(In_UGS['Grid_coords_centroid'])\n",
    "        In_UGS = In_UGS[['geometry','Grid_No','grid_osm','Park_No','Park_entry_No','Parkroad_osmid',\n",
    "                                   'Grid_m_centroid','walk_area_m2',\n",
    "                                   'Euclidean','geometry_m']]\n",
    "\n",
    "        In_UGS['realG_osmid'] = suit_raw['Parkroad_osmid']\n",
    "        In_UGS['realP_osmid'] = suit_raw['grid_osm']\n",
    "        In_UGS['way_calc'] = 'grid in UGS'\n",
    "\n",
    "        Route_parts = pd.concat([Route_parts,In_UGS])\n",
    "        Route_parts = Route_parts.reset_index(drop = True)\n",
    "\n",
    "        Route_parts['gridpark_no'] = Route_parts['Grid_No'].astype(str) +'-'+ Route_parts['Park_No'].astype(str)\n",
    "\n",
    "        # All fill value 0 because no routes are calculated for grid centroids in UGSs\n",
    "        to_fill = ['way-id','route_cost','steps','real_G-entry','Tcost']                                   \n",
    "        Route_parts[to_fill] = Route_parts[to_fill].fillna(0)  \n",
    "            \n",
    "        Routes.append(Route_parts)\n",
    "    return(Routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b44555aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 7 calculate route networks of all grid-parkentry combinations within euclidean threshold distance\n",
    "def route_finding (graphs, combinations, road_nodes, road_edges, cities, block_size = 250000, nn_iter = 10):\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    Routes = list()\n",
    "    for j in range(len(cities)):\n",
    "        Graph = graphs[j]\n",
    "        suit_raw = combinations[j] # iloc to test the iteration speed.\n",
    "        nodes = road_nodes[j]\n",
    "\n",
    "        In_UGS = suit_raw[suit_raw['in_out_UGS'] == True] # Check if a grid centroid is in an UGS\n",
    "        suitible = suit_raw[suit_raw['in_out_UGS'] == False].reset_index(drop = True) # recreate a subsequential index\n",
    "\n",
    "        block = block_size\n",
    "\n",
    "        Route_parts = pd.DataFrame()\n",
    "        len2 = int(np.ceil(len(suitible)/block))\n",
    "        # Divide in chunks of block for computational load\n",
    "        for k in range(len2):    \n",
    "            suitible_chunk = suitible.iloc[k*block:k*block+block]\n",
    "\n",
    "            parknode = list(suitible_chunk['Parkroad_osmid'])\n",
    "            gridnode = list(suitible_chunk['grid_osm'])\n",
    "\n",
    "            s_mat = list([])\n",
    "            s_mat1 = list([])\n",
    "            s_mat2 = list([])\n",
    "            s_mat3 = list([])\n",
    "            s_mat4 = list([])\n",
    "            s_mat5 = list([])\n",
    "            mat_nn = []\n",
    "            len1 = len(suitible_chunk)\n",
    "\n",
    "            print(cities[j].rsplit(',')[0], k+1,'/',len2,'range',k*block,'-',k*block+np.where(k*block+block >= len1,len1,block))\n",
    "            for i in range(len(suitible_chunk)):\n",
    "                try:\n",
    "                    shortest = nx.shortest_path(Graph, gridnode[i], parknode[i], 'travel_dist', method = 'dijkstra')\n",
    "                    s_mat.append(shortest)\n",
    "                    shortest_to = list(shortest[1:len(shortest)])\n",
    "                    shortest_to.append(-1)\n",
    "                    s_mat1.append(shortest_to)\n",
    "                    s_mat2.append(list(np.repeat(i+block*k, len(shortest))))\n",
    "                    s_mat3.append(list(np.arange(0, len(shortest))))\n",
    "                    s_mat4.append('normal way')\n",
    "                    s_mat5.append(1)\n",
    "                except:\n",
    "                    try:\n",
    "                        # Check the reverse\n",
    "                        shortest = nx.shortest_path(Graph, parknode[i], gridnode[i], 'travel_dist', method = 'dijkstra')\n",
    "                        s_mat.append(shortest)\n",
    "                        shortest_to = list(shortest[1:len(shortest)])\n",
    "                        shortest_to.append(-1)\n",
    "                        s_mat1.append(shortest_to)\n",
    "                        s_mat2.append(list(np.repeat(i+block*k, len(shortest))))\n",
    "                        s_mat3.append(list(np.arange(0, len(shortest))))\n",
    "                        s_mat4.append('reverse way')\n",
    "                        s_mat5.append(0)\n",
    "                    except:\n",
    "                        # Otherwise the nearest node is taken, which is iterated X times at max, check assumptions, block #0 \n",
    "                        nn_route_finding(Graph, suitible_chunk, nodes, s_mat, s_mat1, s_mat2, s_mat3\n",
    "                                             s_mat4, s_mat5, i, block, k, nn_iter)\n",
    "                        \n",
    "                if i % 10000 == 0: print(round((i+block*k)/len(suitible)*100,2),'% done',\n",
    "                                         round((time.time() - start_time) / 60,2),'mns')\n",
    "            print('for', len(mat_nn),'routes nearest nodes found')\n",
    "\n",
    "            print(round((i+block*k)/len(suitible)*100,2),'% pathfinding done', round((time.time() - start_time) / 60,2),'mns')\n",
    "\n",
    "            # Formats route information by route and step (detailed)\n",
    "            routes = route_formatting(s_mat, s_mat1, s_mat2, s_mat3, road_edges[j])\n",
    "            print('formatting done', round((time.time() - start_time) / 60,2), 'mns')\n",
    "            \n",
    "            # Summarizes information by route\n",
    "            routes2 = route_summarization(routes, suitible_chunk, road_nodes[j], s_mat4, s_mat5)\n",
    "            print('dissolving done', round((time.time() - start_time) / 60,2), 'mns')\n",
    "            \n",
    "            print('dissolving done', round((time.time() - start_time) / 60,2), 'mns')\n",
    "            Route_parts = pd.concat([Route_parts, routes2])\n",
    "\n",
    "        # Format grids in UGS to enable smooth df concat\n",
    "        In_UGS = In_UGS.set_geometry(In_UGS['Grid_coords_centroid'])\n",
    "        In_UGS = In_UGS[['geometry','Grid_No','grid_osm','Park_No','Park_entry_No','Parkroad_osmid',\n",
    "                                   'Grid_m_centroid','walk_area_m2',\n",
    "                                   'Euclidean','geometry_m']]\n",
    "\n",
    "        In_UGS['realG_osmid'] = suit_raw['Parkroad_osmid']\n",
    "        In_UGS['realP_osmid'] = suit_raw['grid_osm']\n",
    "        In_UGS['way_calc'] = 'grid in UGS'\n",
    "\n",
    "        Route_parts = pd.concat([Route_parts,In_UGS])\n",
    "        Route_parts = Route_parts.reset_index(drop = True)\n",
    "\n",
    "        Route_parts['gridpark_no'] = Route_parts['Grid_No'].astype(str) +'-'+ Route_parts['Park_No'].astype(str)\n",
    "\n",
    "        # All fill value 0 because no routes are calculated for grid centroids in UGSs\n",
    "        to_fill = ['way-id','route_cost','steps','real_G-entry','Tcost']                                   \n",
    "        Route_parts[to_fill] = Route_parts[to_fill].fillna(0)  \n",
    "            \n",
    "        Routes.append(Route_parts)\n",
    "    return(Routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a680b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_route_finding(graph, suitible_chunk, nodes, mat_from, mat_to, mat_route, mat_step,\n",
    "                                             mat_way, mat_wbin, i, block, k, nn_iter):\n",
    "                        \n",
    "    # Order in route for nearest node:\n",
    "    # 1. gridnode to nearest to the original failed parknode\n",
    "    # 2. The reverse of 1.\n",
    "    # 3. nearest gridnode to the failed one and route to park\n",
    "    # 4. The reverse of 3.\n",
    "                        \n",
    "    gridosm = suitible_chunk['grid_osm']\n",
    "    UGSosm = suitible_chunk['Parkroad_osmid']\n",
    "    nodeosm = nodes['osmid_var']\n",
    "    nodegeom = nodes['geometry']\n",
    "                        \n",
    "    len3 = 0\n",
    "    alt_route = list([])\n",
    "    while len3 < nn_iter and len(alt_route) < 1:\n",
    "\n",
    "        len3 = len3 +1\n",
    "                            \n",
    "        nn = nn_finding(gridosm, UGSosm, nodeosm, nodegeom, nodes, i, len3)\n",
    "\n",
    "        nn_routing (graph, nn['currUGS'], nn['nearUGS'], nn['currgrid'], nn['neargrid'], \n",
    "                                        mat_way, mat_wbin, len3, alt_route)\n",
    "    if len(alt_route) == 0: \n",
    "        alt = alt_route \n",
    "    else: \n",
    "        alt = alt_route[0]\n",
    "    len4 = len(alt)\n",
    "    if len4 > 0:\n",
    "        mat_nn.append(i+block*k)\n",
    "        mat_from.append(alt)\n",
    "        shortest_to = list(alt[1:len(alt)])\n",
    "        shortest_to.append(-1)\n",
    "        mat_to.append(shortest_to)\n",
    "        mat_route.append(list(np.repeat(i+block*k,len4)))\n",
    "        mat_step.append(list(np.arange(0, len4)))\n",
    "    else:\n",
    "        mat_from.append(-1)\n",
    "        mat_to.append(-1)\n",
    "        mat_route.append(i+block*k)\n",
    "        mat_step.append(-1)\n",
    "        mat_way.append('no way')\n",
    "        mat_wbin.append(2)\n",
    "        print(i+block*k,'No route',nn_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "695e9681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_finding (gridosm, UGSosm, nodeosm, nodegeom, nodes, i, nn_i): \n",
    "    # Grid nearest\n",
    "    g_geom = nodegeom[nodeosm == int(gridosm[i:i+1])]\n",
    "    g_nearest = pd.DataFrame((abs(float(g_geom.x) - nodegeom.x)**2\n",
    "    +abs(float(g_geom.y) - nodegeom.y)**2)**(1/2)\n",
    "                            ).join(nodeosm).sort_values(0)\n",
    "\n",
    "    g_grid = g_nearest.iloc[nn_i,1]\n",
    "    g_park = list(UGSosm)[i]\n",
    "        \n",
    "    p_geom = nodegeom[nodeosm == int(UGSosm[i:i+1])]\n",
    "    p_nearest = pd.DataFrame((abs(float(p_geom.x) - nodegeom.x)**2\n",
    "    +abs(float(p_geom.y) - nodegeom.y)**2)**(1/2)\n",
    "                            ).join(nodeosm).sort_values(0)\n",
    "\n",
    "    p_grid = list(gridosm)[i]\n",
    "    p_park = p_nearest.iloc[nn_i,1]\n",
    "    return({'currUGS':p_grid, 'nearUGS':p_park,'currgrid':g_park, 'neargrid':g_grid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "65f7c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_routing (graph, curr_UGS, near_UGS, curr_grid, near_grid, mat_way, mat_wbin, nn_i, found_route):\n",
    "    try:\n",
    "        found_route.append(nx.shortest_path(graph, curr_UGS, near_UGS, \n",
    "                                          'travel_dist', method = 'dijkstra'))\n",
    "        mat_way.append(str(nn_i)+'grid > n-park')\n",
    "        mat_wbin.append(1)\n",
    "    except:\n",
    "        try:\n",
    "            found_route.append(nx.shortest_path(graph, near_UGS, curr_UGS, \n",
    "                                              'travel_dist', method = 'dijkstra'))\n",
    "            mat_way.append(str(nn_i)+'n-park > grid')\n",
    "            mat_wbin.append(0)\n",
    "        except:\n",
    "            try:\n",
    "                found_route.append(nx.shortest_path(graph, curr_grid, near_grid, \n",
    "                                                  'travel_dist', method = 'dijkstra'))\n",
    "                mat_way.append(str(nn_i)+'n-grid > park')\n",
    "                mat_wbin.append(1)\n",
    "            except:\n",
    "                try:\n",
    "                    found_route.append(nx.shortest_path(graph, near_grid, curr_grid, \n",
    "                                                      'travel_dist', method = 'dijkstra'))\n",
    "                    mat_way.append(str(nn_i)+'park > n-grid')\n",
    "                    mat_wbin.append(0)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dd0bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_formatting(mat_from, mat_to, mat_route, mat_step, road_edges):\n",
    "    # Unpack lists\n",
    "    s_mat_u = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat_from) for i in b]\n",
    "    s_mat_u1 = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat_to) for i in b]\n",
    "    s_mat_u2 = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat_route) for i in b]\n",
    "    s_mat_u3 = [i for b in map(lambda x:[x] if not isinstance(x, list) else x, mat_step) for i in b]\n",
    "\n",
    "    # Format df\n",
    "    routes = pd.DataFrame([s_mat_u,s_mat_u1,s_mat_u2,s_mat_u3]).transpose()\n",
    "    routes.columns = ['from','to','route','step']\n",
    "    mat_key = list([])\n",
    "    for n in range(len(routes)):\n",
    "        mat_key.append(str(int(s_mat_u[n])) + '-' + str(int(s_mat_u1[n])))\n",
    "    routes['key'] = mat_key\n",
    "    routes = routes.set_index('key')\n",
    "\n",
    "    # Add route information\n",
    "    routes = routes.join(road_edges, how = 'left')\n",
    "    routes = gpd.GeoDataFrame(routes, geometry = 'geometry', crs = 4326)\n",
    "    routes = routes.sort_values(by = ['route','step'])\n",
    "    return(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84241ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_summarization(routes, suitible_comb, road_nodes, mat_way, mat_wbin):\n",
    "    # dissolve route\n",
    "    routes2 = routes[['route','geometry']].dissolve('route')\n",
    "\n",
    "    # get used grid- and parkosm. Differs at NN-route.\n",
    "    route_reset = routes.reset_index()\n",
    "    origin = route_reset['from'].iloc[list(route_reset.groupby('route')['step'].idxmin()),]\n",
    "    origin = origin.reset_index().iloc[:,-1]\n",
    "    dest = route_reset['from'].iloc[list(route_reset.groupby('route')['step'].idxmax()),]\n",
    "    dest = dest.reset_index().iloc[:,-1]\n",
    "\n",
    "    # grid > park = 1, park > grid = 0, no way = 2, detailed way in way_calc.\n",
    "    routes2['way-id'] = mat_wbin\n",
    "    routes2['realG_osmid'] = np.where(routes2['way-id'] == 1, origin, dest)\n",
    "    routes2['realP_osmid'] = np.where(routes2['way-id'] == 1, dest, origin)\n",
    "    routes2['way_calc'] = mat_way\n",
    "\n",
    "    # get route cost, steps, additional information.\n",
    "    routes2['route_cost'] = routes.groupby('route')['length'].sum()\n",
    "    routes2['steps'] = routes.groupby('route')['step'].max()\n",
    "    routes2['index'] = suitible_comb.index\n",
    "    routes2 = routes2.set_index(['index'])\n",
    "    routes2.index = routes2.index.astype(int)\n",
    "    routes2 = pd.merge(routes2, suitible_comb[['Grid_No','grid_osm','Park_No','Park_entry_No','Parkroad_osmid',\n",
    "                                          'Grid_m_centroid','walk_area_m2','Euclidean']],\n",
    "                                            left_index = True, right_index = True)\n",
    "    routes2 = pd.merge(routes2, road_nodes['geometry_m'], how = 'left', left_on = 'realG_osmid', right_index = True)\n",
    "    # calculate distance of used road-entry for grid-centroid.\n",
    "    routes2['real_G-entry'] = round(gpd.GeoSeries(routes2['Grid_m_centroid'], crs = 3043).distance(routes2['geometry_m']),3)\n",
    "                                    \n",
    "    # Calculcate total route cost for the four gravity variants\n",
    "    routes2['Tcost'] = routes2['route_cost'] + routes2['real_G-entry']\n",
    "    return(routes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e355b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_gridUGS_comb (routes, grids, UGS):\n",
    "    gp_nearest = []\n",
    "    for i in range(len(routes)):\n",
    "        gp_nn = routes[i][routes[i]['Tcost'] <= max(thresholds)]\n",
    "        gp_nn = pd.merge(gp_nn, grids[i]['population'], left_on='Grid_No', right_index = True)\n",
    "        gp_nn = pd.merge(gp_nn, UGS[i]['park_area'], left_on = 'Park_No', right_index = True)\n",
    "        gp_nn = gp_nn.reset_index()\n",
    "\n",
    "        gp_nn = gp_nn.iloc[gp_nn.groupby('gridpark_no')['Tcost'].idxmin()]\n",
    "        gp_nn.index.name = 'idx'\n",
    "        gp_nn = gp_nn.sort_values('idx')\n",
    "        gp_nn = gp_nn.reset_index()\n",
    "        gp_nearest.append(gp_nn)\n",
    "    gp_nearest[0].sort_values('Grid_No')\n",
    "    return(gp_nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebb4c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E2SCFA_scores(min_gridUGS_comb, grids, thresholds, cities):\n",
    "    pd.options.display.float_format = '{:20,.2f}'.format\n",
    "    E2SFCA_cities = []\n",
    "    E2SFCA_summary = pd.DataFrame()\n",
    "    for i in range(len(cities)):\n",
    "        E2SFCA_score = grids[i][['population','geometry']]\n",
    "        for j in range(len(thresholds)):\n",
    "            subset = min_gridUGS_comb[i][min_gridUGS_comb[i]['Tcost'] <= thresholds[j]]\n",
    "\n",
    "            # use gussian distribution: let v= 923325, then the weight for 800m is 0.5\n",
    "            v = -thresholds[j]**2/np.log(0.5)\n",
    "\n",
    "            # add a column of weight: apply the decay function on distance\n",
    "            subset['weight'] = np.exp(-(subset['Tcost']**2/v)).astype(float)\n",
    "            subset['pop_weight'] = subset['weight'] * subset['population']\n",
    "\n",
    "            # get the sum of weighted population each green space has to serve.\n",
    "            s_w_p = pd.DataFrame(subset.groupby('Park_No').sum('pop_weight')['pop_weight'])\n",
    "\n",
    "            # delete other columns, because they are useless after groupby\n",
    "            s_w_p = s_w_p.rename({'pop_weight':'pop_weight_sum'},axis = 1)\n",
    "            middle = pd.merge(subset,s_w_p, how = 'left', on = 'Park_No' )\n",
    "\n",
    "            # calculate the supply-demand ratio for each green space\n",
    "            middle['green_supply'] = middle['park_area']/middle['pop_weight_sum']\n",
    "\n",
    "            # caculate the accessbility score for each green space that each population grid cell could reach\n",
    "            middle['Sc-access'] = middle['weight'] * middle['green_supply']\n",
    "            # add the scores for each population grid cell\n",
    "            pop_score_df = pd.DataFrame(middle.groupby('Grid_No').sum('Sc-access')['Sc-access'])\n",
    "\n",
    "            # calculate the mean distance of all the green space each population grid cell could reach\n",
    "            mean_dist = middle.groupby('Grid_No').mean('Tcost')['Tcost']\n",
    "            pop_score_df['M-dist'] = mean_dist\n",
    "\n",
    "            # calculate the mean area of all the green space each population grid cell could reach\n",
    "            mean_area = middle.groupby('Grid_No').mean('park_area')['park_area']\n",
    "            pop_score_df['M-area'] = mean_area\n",
    "\n",
    "            # calculate the mean supply_demand ratio of all the green space each population grid cell could reach\n",
    "            mean_supply = middle.groupby('Grid_No').mean('green_supply')['green_supply']\n",
    "            pop_score_df['M-supply'] = mean_supply\n",
    "\n",
    "            pop_score = pop_score_df\n",
    "\n",
    "            pop_score_df = pop_score_df.join(grids[i]['population'], how = 'right')\n",
    "            pop_score_df['Sc-norm'] = pop_score_df['Sc-access'] / pop_score_df['population']\n",
    "\n",
    "            pop_score_df = pop_score_df.loc[:, pop_score_df.columns != 'population']\n",
    "            pop_score_df = pop_score_df.add_suffix(' '+str(thresholds[j]))\n",
    "            E2SFCA_score = E2SFCA_score.join(pop_score_df, how = 'left')\n",
    "\n",
    "            print(thresholds[j], cities[i])\n",
    "\n",
    "        E2SFCA_score = E2SFCA_score.fillna(0)\n",
    "        pop_sum = pd.Series(E2SFCA_score['population'].sum()).astype(int)\n",
    "        pop_sum.index = ['population']\n",
    "        mean_metrics = E2SFCA_score.loc[:, E2SFCA_score.columns != 'population'].mean()\n",
    "        E2SFCA_sum = pd.concat([pop_sum, mean_metrics])\n",
    "        E2SFCA_summary = pd.concat([E2SFCA_summary, E2SFCA_sum], axis = 1)\n",
    "        E2SFCA_cities.append(E2SFCA_score)\n",
    "        E2SFCA_score.loc[:, E2SFCA_score.columns != 'geometry'].to_csv('D:/Dumps/M2SFCA-OD/Scores/'+cities[i]+'.csv')\n",
    "    E2SFCA_summary.columns = cities\n",
    "    E2SFCA_summary.to_csv('D:/Dumps/M2SFCA-OD/Scores/all_cities.csv')\n",
    "    E2SFCA_summary\n",
    "    return({'score summary':E2SFCA_summary,'score detail':E2SFCA_cities})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26fd5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranked_route_scoring (routes, UGS_entry, cities, var_abbr, ranks):\n",
    "    start_time = time.time()\n",
    "    ranked_routes = list()\n",
    "    for k in range(len(cities)):\n",
    "        str1 = var_abbr+'_Tcost'\n",
    "        # Get the size to meters\n",
    "        UGS_entry[k]['park_size_walkable_m'] = UGS_entry[k]['park_size_walkable'].to_crs(3043)\n",
    "\n",
    "        # Drop 'no way' routes\n",
    "        Rclean = routes[k][routes[k]['way_calc'] != 'no way'].reset_index(drop = True)\n",
    "\n",
    "        # Create a rank per grid-UGS combination which (fake) entry is the closest\n",
    "        Rclean['rank'] = Rclean.groupby('gridpark_no')[var_abbr+'_Tcost'].rank(method = 'first').astype(int)\n",
    "\n",
    "        # Get the UGS walkable radius (standard on 500m from the fake entrance)\n",
    "        mercl = pd.merge(Rclean, UGS_entry[k]['park_size_walkable_m'], left_on = 'Park_entry_No', right_index = True)\n",
    "\n",
    "        # Sort for slightly better performance\n",
    "        mercl = mercl.sort_values(['rank','gridpark_no'])\n",
    "                                                                    # Radii are walkable area, max distance by entry point.\n",
    "        # Get a df with unique grid-park combinations as index       # ranks = by grid-UGS comb. rank entry points by route cost\n",
    "        df = pd.DataFrame(index = Rclean['gridpark_no'].sort_values().unique()) # dissolved UGS radii of current and previous ranks\n",
    "        df2 = pd.DataFrame(index = Rclean['gridpark_no'].sort_values().unique()) # inflation factor over raw route total cost\n",
    "        df3 = pd.DataFrame(index = Rclean['gridpark_no'].sort_values().unique()) # radii of ranks\n",
    "        df4 = pd.DataFrame(index = Rclean['gridpark_no'].sort_values().unique()) # clipped UGS radii from previous (clipped) ranks\n",
    "        maxrank = max(Rclean['rank'])\n",
    "\n",
    "        # Enter info for the first rank.\n",
    "        df[1] = mercl[['gridpark_no','park_size_walkable_m']].set_geometry('park_size_walkable_m').dissolve(by = 'gridpark_no')\n",
    "        df3[1] = mercl[mercl['rank'] == 1][['gridpark_no','park_size_walkable_m']].set_index('gridpark_no')\n",
    "        df4[1] = df[1]\n",
    "        df2[1] = None\n",
    "\n",
    "        if ranks <= maxrank: iterations = ranks\n",
    "        else: iterations = maxrank\n",
    "        print('rank',1,round((time.time() - start_time) / 60,2), 'mns ('+str(len(df))+' routes)')\n",
    "\n",
    "        for i in range(1,iterations):\n",
    "            ranked = mercl[mercl['rank'] == i+1][['gridpark_no','park_size_walkable_m']] # Get current rank\n",
    "            ranked = ranked.sort_values('gridpark_no').set_geometry('park_size_walkable_m')\n",
    "            ranked = ranked.set_index('gridpark_no')\n",
    "            df3[i+1] = ranked['park_size_walkable_m']\n",
    "\n",
    "            series = gpd.GeoSeries(df[i]).difference(gpd.GeoSeries(df3[i+1])) # Gets difference of dissolved radii and current \n",
    "            df[i+1] = only_polygons(series) # removes linestrings                 walkable UGS area\n",
    "            series1 = gpd.GeoSeries(only_polygons(df[i+1]))\n",
    "            clipped = only_polygons(series1.clip(ranked)) # Get the area not yet served.\n",
    "            df2[i+1] = clipped.area / UGS_entry[k]['walk_area'].median() # Get the inflation factor by comparing it against\n",
    "            df4[i+1] = clipped                                           # the median UGS size used earlier.\n",
    "            print('rank',i+1, round((time.time() - start_time) / 60,2), 'mns ('+str(len(ranked))+' routes)')\n",
    "\n",
    "        # Apply inflation factors to route cost.\n",
    "        df2_unstacked = pd.DataFrame(df2.fillna(0).unstack())\n",
    "        mercl = pd.merge(mercl,df2_unstacked, left_on = ['rank','gridpark_no'], right_index = True)\n",
    "        mercl['grav2_Tcost'] = np.where(mercl['rank'] == 1,mercl['grav2_Tcost'],mercl['raw_Tcost'] / (mercl[0] ** (1/2)))\n",
    "        mercl['grav3_Tcost'] = np.where(mercl['rank'] == 1,mercl['grav3_Tcost'],mercl['raw_Tcost'] / (mercl[0] ** (1/3)))\n",
    "        mercl['grav5_Tcost'] = np.where(mercl['rank'] == 1,mercl['grav5_Tcost'],mercl['raw_Tcost'] / (mercl[0] ** (1/5)))\n",
    "\n",
    "        mercl = mercl[mercl.columns[mercl.columns != 0]]\n",
    "        ranked_routes.append(mercl)\n",
    "    return(ranked_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23fd6369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_polygons (geoseries):\n",
    "    geom_df = series[series.geom_type == 'GeometryCollection']\n",
    "    non_geom_df = series[series.geom_type != 'GeometryCollection']\n",
    "    l2 = list()\n",
    "    for j in range(len(geom_df)):\n",
    "        l1 = list()\n",
    "        for i in geom_df[j]: \n",
    "            if ((i.geom_type == 'Polygon') |\n",
    "            (i.geom_type == 'MultiPolygon')):\n",
    "                l1.append(i)\n",
    "        l2.append(MultiPolygon(l1))\n",
    "    done_df = gpd.GeoSeries(l2)\n",
    "    done_df.index = geom_df.index\n",
    "    done_df = gpd.GeoSeries(pd.concat([non_geom_df, done_df]))\n",
    "    return(done_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d90c64ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 mns\n"
     ]
    }
   ],
   "source": [
    "print(round((time.time() - start) / 60,2),'mns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a9824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82686f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
